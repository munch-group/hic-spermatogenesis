[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Søren’s MSc project about Hi-C and spermatogenesis",
    "section": "",
    "text": "Project",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project</span>"
    ]
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Søren’s MSc project about Hi-C and spermatogenesis",
    "section": "Outline",
    "text": "Outline\nHi-C data is often generated for whole-genome sequencing (WGS) and the assembly of genomes due to its ability to capture the three-dimensional organization of the genome. This spatial information helps in correctly assembling contigs into chromosomes by providing contacts between distant genomic regions, thus resolving ambiguities in the linear sequence data. Thus, Hi-C data is often available, and leveraging this existing data can provide valuable insights to other areas without the need for additional sequencing. The aim of this project is to analyze chromatin compartments on the X chromosome during spermatogenesis in baboons, macaques, and humans using Hi-C data. The project involves generating interaction maps and identifying PC1 compartments. A key objective is to compare transition zones with regions undergoing positive selection to uncover how chromatin architecture reflects evolutionary pressures. The ultimate goal is to deepen our understanding of chromatin organization and the conservation of non-advantageous alleles, providing insights into the role of selfish genes in shaping genome evolution.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project</span>"
    ]
  },
  {
    "objectID": "index.html#notes-on-litterature-as-i-read-it",
    "href": "index.html#notes-on-litterature-as-i-read-it",
    "title": "Søren’s MSc project about Hi-C and spermatogenesis",
    "section": "Notes on litterature as I read it",
    "text": "Notes on litterature as I read it\n(Wang et al. 2019) Macaque/Mouse Hi-C paper. They use HiC-Pro and incorporates RNAseq data analyzed by TopHat and CuffLinks. Introduce small-scale in situ Hi-C (sisHi-C). They analyze both A/B compartments and TADs. Also introduce ‘Refined A/B compartments’ with ‘Local PCA’. They cite (Servant et al. 2015) for their PCA method.\n(Servant et al. 2015) describes the software HiC-Pro. Is a pipeline for all the steps until analysis of the contact maps. Includes (iterative correction) normalization steps, which is also available as standalone hiclib/iced tool. They refer to (aiden2009comprehensivemappinglongrange?) for PCA method.\n(lieberman_aiden_comprehensive_2009?) Introduces the Hi-C method and some ways of analyzing the data. E.g. the eigenvector (PCA) method, where they refer back to (Price et al. 2006)\n(Price et al. 2006) use PCA to account for stratification in GWAS. The paper was cited by the Hi-C paper (2009) which was cited by the HiC-Pro paper as their PCA method. No real use for this paper, and they also refer back to a general guide on PCA from 2003. End of citation chain.\n(Zuo et al. 2021) Stage-resolved Hi-C analysis in mouse spermatogenesis, using mm10 reference genome. They use hiclib (now replaced by distiller) and cooler/cooltools from mirnylab. They focus on genome-wide chromatin structure, especially the weakening of TADs in prophase I (pachytene stage) while there is persistent CTCF binding (loops). They suggest that chromosome organization may provide an infrastructure for the modulation of meiotic recombination in higher eukaryotes.\n\nQ: Could alterations in TAD organization during specific meiotic stages create opportunities for selfish genes to proliferate or influence transmission?\n\n(Batra et al. 2020) Baboon paper. They announce a new de novo-assembled reference genome, Panubis1.0, more accurate than the previous Panu3.0, which was a highly fragmented assembly based on short-read seq-tech and reference guided assembly (ref: rhesus macaque). They made the de novo assembly by combining 10x Genomics (physically linked short-reads) with Nanopore long-reads, and finally ordering and orienting the reads with Hi-C seq. They state no specific conclusions about the Hi-C data separate from the assemmbly.\n(Shami et al. 2020) Divergent features of mammalian spermatogenesis. They use scRNA-seq to study spermatogenesis in human, macaque, mice. They compare conserved and divergent features of spermatogenesis across species. Spermatogonia, spermatocytes, spermatids. Identified a gene TSPAN33 that was expressed in primate spermatogonia populations, but not in mice. They found both conserved patterns across species and species-specific patterns, notably in genes involved in immune system and blood-testis barrier, also including signalling pathways. Identify a genetic region that may be of interest, but otherwise I don’t know how to use this paper, unless they have Hi-C data they can send us.\n(Chakraborty, Wang, and Ay 2022) dcHiC paper/dcHiC tool. Differential compartments analysis. Utilize a multivariate distance measure, Mahalanobis (opposed to only pairwise comparisons) to identify and analyze changes across multiple Hi-C maps. They found compartmental changes in regions containing genes involved in cell identity (regulating pluripottency, cell adhesion, signaling pathways) during neuronal development. dcHiC can also identify sub-compartmental changes, and integrate compartmentalization data from other datasets (gene expression, histone modification, replication timing). Multivariata seems to be a better way of considering the Hi-C data.\n(Bicciato and Ferrari 2022) Book on Hi-C data analysis. Might use to find conventional use of thresholds, etc. Might follow a couple of these pipelines if they are not already outdated.\n(Skov et al. 2023) Paper from Munch-group. Cautiously hypothesize that meiotic drive on X chr could be responsible for their observations. Examining the selective sweeps in the context of (primate) spermatogenesis could be insightful. Integrating gene expression and Hi-C maps during spermatogenesis, could potentially uncover if the sweeps preferentially affect active elements/gene during spermatogenesis at i.e. specific stages.\n(Bravo Núñez, Nuckolls, and Zanders 2018). Paper on Genetic Villains/meiotic drivers. Describes the difficulty of detecting drive, and different types of drive. Killer-Target, Poison-Antidote. They have nice illustrations of meiotic drive.\n(Gong et al. 2021) Most recent paper I could find on Hi-C in human. But it is about cancer and other omics than Hi-C.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project</span>"
    ]
  },
  {
    "objectID": "index.html#schedule-work-plan",
    "href": "index.html#schedule-work-plan",
    "title": "Søren’s MSc project about Hi-C and spermatogenesis",
    "section": "Schedule / Work plan",
    "text": "Schedule / Work plan\nSemester: Monday, Aug 26th – Wednesday, Jan 15th (Week 35-3)\nHand-in: Wednesday, Jan 15th (Week 3)\nHoliday: Wednesday, Oct 23rd – Monday, Oct 28th (Week 43)\nChristmas Holidays: Monday, Dec 23rd – Friday, Jan 3rd (Week 52-1)\n\nWeek 35-36 (Aug 26 - Sep 7):\nConduct a literature review on chromatin architecture, Hi-C methodology, and the concept of selfish genes. Get an overview of (and obtain) data sets to be used.\nWeek 37-38 (Sep 9 - Sep 21):\nAssess the status of existing Hi-C data (raw or QC’ed). If necessary, perform initial quality control. Align reads to reference genomes.\nWeek 39-40 (Sep 23 - Oct 5):\nProcess Hi-C interaction data. Perform quality assessment.\nWeek 41-42 (Oct 7 - Oct 19):\nGenerate and normalize interaction matrices for the X chromosome.\nWeek 43 (Oct 21 - Oct 26):\nHoliday from Wednesday (no major activities planned). Tidy notes and do some writing.\nWeek 44-45 (Oct 28 - Nov 9):\nPerform PCA to obtain PC1 compartments. Visualize results.\nWeek 46-47 (Nov 11 - Nov 23):\nIdentify A/B compartment transitions. Overlay with positive selection regions.\nWeek 48-49 (Nov 25 - Dec 7):\nConduct cross-species analysis by converting genomic coordinates.\nWeek 50 (Dec 9 - Dec 14):\nFinish analyses. Compare results.\nWeek 51 (Dec 16 - Dec 21):\nFinalize analyses and begin writing initial thesis draft, incorporating analysis results and discussions.\nWeek 52 (Dec 23 - Dec 28):\nChristmas holidays (no major activities planned). Will work a couple of days Dec 27-29.\nWeek 1 (Dec 30 - Jan 4):\nChristmas holidays until Jan 2 (just performing modifications to analyses, etc.).\nWeek 2 (Jan 6 - Jan 11):\nRevise thesis draft based on feedback. Continue refinement of analyses if necessary.\nWeek 3 (Jan 13 - Jan 15):\nFinal revisions and hand-in on Wednesday, January 15th.\n\n\n\n\nBatra, Sanjit Singh, Michal Levy-Sakin, Jacqueline Robinson, Joseph Guillory, Steffen Durinck, Tauras P Vilgalys, Pui-Yan Kwok, et al. 2020. “Accurate Assembly of the Olive Baboon ( Papio Anubis ) Genome Using Long-Read and Hi-C Data.” GigaScience 9 (12): giaa134. https://doi.org/10.1093/gigascience/giaa134.\n\n\nBicciato, Silvio, and Francesco Ferrari, eds. 2022. Hi-C Data Analysis: Methods and Protocols. Vol. 2301. Methods in Molecular Biology. New York, NY: Springer US. https://doi.org/10.1007/978-1-0716-1390-0.\n\n\nBravo Núñez, María Angélica, Nicole L. Nuckolls, and Sarah E. Zanders. 2018. “Genetic Villains: Killer Meiotic Drivers.” Trends in Genetics 34 (6): 424–33. https://doi.org/10.1016/j.tig.2018.02.003.\n\n\nChakraborty, Abhijit, Jeffrey G. Wang, and Ferhat Ay. 2022. “dcHiC Detects Differential Compartments Across Multiple Hi-C Datasets.” Nature Communications 13 (1): 6827. https://doi.org/10.1038/s41467-022-34626-6.\n\n\nGong, Haiyan, Yi Yang, Sichen Zhang, Minghong Li, and Xiaotong Zhang. 2021. “Application of Hi-C and Other Omics Data Analysis in Human Cancer and Cell Differentiation Research.” Computational and Structural Biotechnology Journal 19: 2070–83. https://doi.org/10.1016/j.csbj.2021.04.016.\n\n\nPrice, Alkes L, Nick J Patterson, Robert M Plenge, Michael E Weinblatt, Nancy A Shadick, and David Reich. 2006. “Principal Components Analysis Corrects for Stratification in Genome-Wide Association Studies.” Nature Genetics 38 (8): 904–9. https://doi.org/10.1038/ng1847.\n\n\nServant, Nicolas, Nelle Varoquaux, Bryan R. Lajoie, Eric Viara, Chong-Jian Chen, Jean-Philippe Vert, Edith Heard, Job Dekker, and Emmanuel Barillot. 2015. “HiC-Pro: An Optimized and Flexible Pipeline for Hi-C Data Processing.” Genome Biology 16 (1): 259. https://doi.org/10.1186/s13059-015-0831-x.\n\n\nShami, Adrienne Niederriter, Xianing Zheng, Sarah K. Munyoki, Qianyi Ma, Gabriel L. Manske, Christopher D. Green, Meena Sukhwani, Kyle E. Orwig, Jun Z. Li, and Saher Sue Hammoud. 2020. “Single-Cell RNA Sequencing of Human, Macaque, and Mouse Testes Uncovers Conserved and Divergent Features of Mammalian Spermatogenesis.” Developmental Cell 54 (4): 529–547.e12. https://doi.org/10.1016/j.devcel.2020.05.010.\n\n\nSkov, Laurits, Moisès Coll Macià, Elise Anne Lucotte, Maria Izabel Alves Cavassim, David Castellano, Mikkel Heide Schierup, and Kasper Munch. 2023. “Extraordinary Selection on the Human X Chromosome Associated with Archaic Admixture.” Cell Genomics 3 (3): 100274. https://doi.org/10.1016/j.xgen.2023.100274.\n\n\nWang, Yao, Hanben Wang, Yu Zhang, Zhenhai Du, Wei Si, Suixing Fan, Dongdong Qin, et al. 2019. “Reprogramming of Meiotic Chromatin Architecture During Spermatogenesis.” Molecular Cell 73 (3): 547–561.e6. https://doi.org/10.1016/j.molcel.2018.11.019.\n\n\nZuo, Wu, Guangming Chen, Zhimei Gao, Shuai Li, Yanyan Chen, Chenhui Huang, Juan Chen, Zhengjun Chen, Ming Lei, and Qian Bian. 2021. “Stage-Resolved Hi-C Analyses Reveal Meiotic Chromosome Organizational Features Influencing Homolog Alignment.” Nature Communications 12 (1): 5827. https://doi.org/10.1038/s41467-021-26033-0.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html",
    "href": "notebooks/01_hicexplorer.html",
    "title": "HiCExplorer using macaque data",
    "section": "",
    "text": "Reality check",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#reality-check",
    "href": "notebooks/01_hicexplorer.html#reality-check",
    "title": "HiCExplorer using macaque data",
    "section": "",
    "text": "Conda environment\nThe notebook must be launched from the hic environment.\nCheck with the cell magic %conda info where the shell escape (! or %%bash) looks.\n\n\nKernel\nBefore using this notebook, make sure to use the ‘hic’ kernel.\nI might change the env into a seperate HiC env for each of the tools, such as HICExplorer, Cooler/cooltools, etc.\nAs of this version, there is only one environment in the repo, and it contains both Python, R, and CLI tools for use in HI-C data analysis.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#getting-started-with-an-overview",
    "href": "notebooks/01_hicexplorer.html#getting-started-with-an-overview",
    "title": "HiCExplorer using macaque data",
    "section": "Getting started with an overview",
    "text": "Getting started with an overview\nIn this notebook, we will use HiCExplorer to analysis Hi-C reads from macaque monkeys. We will follow an example from the HiCExplorer documentation.\nFirst, let’s look at the files we have. They are from SRA, and are Hi-C sequencing data from macaque fibroblasts. The data is generated for the Wang2019 paper.\n\n%%bash \n\ntree ../data/links/macaque_fastq\n\ntree ../../../../data/macaque_raw/downloaded/\n\ndu -ha ../../../../data/macaque_raw/downloaded/*.gz\n\n../data/links/macaque_fastq\n├── SRR6502335_1.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502335_1.fastq.gz\n├── SRR6502335_2.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502335_2.fastq.gz\n├── SRR6502336_1.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502336_1.fastq.gz\n├── SRR6502336_2.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502336_2.fastq.gz\n├── SRR6502337_1.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502337_1.fastq.gz\n├── SRR6502337_2.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502337_2.fastq.gz\n├── SRR6502338_1.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502338_1.fastq.gz\n├── SRR6502338_2.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502338_2.fastq.gz\n├── SRR6502339_1.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502339_1.fastq.gz\n└── SRR6502339_2.fastq.gz -&gt; ../../../../../../data/macaque_raw/downloaded/SRR6502339_2.fastq.gz\n\n0 directories, 10 files\n../../../../data/macaque_raw/downloaded/\n├── rheMac10_Mmul10.zip\n├── SraRunTable.txt\n├── SRR6502335_1.fastq.gz\n├── SRR6502335_2.fastq.gz\n├── SRR6502336_1.fastq.gz\n├── SRR6502336_2.fastq.gz\n├── SRR6502337_1.fastq.gz\n├── SRR6502337_2.fastq.gz\n├── SRR6502338_1.fastq.gz\n├── SRR6502338_2.fastq.gz\n├── SRR6502339_1.fastq.gz\n└── SRR6502339_2.fastq.gz\n\n0 directories, 12 files\n20G ../../../../data/macaque_raw/downloaded/SRR6502335_1.fastq.gz\n23G ../../../../data/macaque_raw/downloaded/SRR6502335_2.fastq.gz\n16G ../../../../data/macaque_raw/downloaded/SRR6502336_1.fastq.gz\n17G ../../../../data/macaque_raw/downloaded/SRR6502336_2.fastq.gz\n14G ../../../../data/macaque_raw/downloaded/SRR6502337_1.fastq.gz\n17G ../../../../data/macaque_raw/downloaded/SRR6502337_2.fastq.gz\n14G ../../../../data/macaque_raw/downloaded/SRR6502338_1.fastq.gz\n17G ../../../../data/macaque_raw/downloaded/SRR6502338_2.fastq.gz\n7.0G    ../../../../data/macaque_raw/downloaded/SRR6502339_1.fastq.gz\n7.6G    ../../../../data/macaque_raw/downloaded/SRR6502339_2.fastq.gz\n\n\n\nAn overview of the sequences\nWe can see summary statistics for our sequences in the SraRunTable.txt\n\nimport pandas as pd\n\nsra_runtable = pd.read_csv(\"../../../../data/macaque_raw/downloaded/SraRunTable.txt\")\nsra_runtable[['Run', 'Bases', 'Bytes', 'source_name']]\n\n\n\nTable 2.1: The samples chosen for initial data exploration with HiCExplorer. From NCBI SRA Portal.\n\n\n\n\n\n\n\n\n\n\nRun\nBases\nBytes\nsource_name\n\n\n\n\n0\nSRR6502335\n73201141800\n31966430779\nfibroblast\n\n\n1\nSRR6502336\n65119970100\n24433383054\nfibroblast\n\n\n2\nSRR6502337\n52769196300\n23015357755\nfibroblast\n\n\n3\nSRR6502338\n52378949100\n22999581685\nfibroblast\n\n\n4\nSRR6502339\n28885941600\n10960123150\nfibroblast\n\n\n\n\n\n\n\n\n\n\n\n\nPreparation of the .fastq files\nThe .fastq files were all prepared using this workflow. Briefly, it does three things on the reference genome (Mmul_10/rheMac10):\n\nindexing with bwa index\n\nindexing with samtools faidx\nindexing of restriction sites of the used restriction enzyme used (hicFindRestSites)\n\nThen, it maps all the .fastq files (each mate individually) back to the reference genome with bwa mem.\nFinally, it builds the .h5 Hi-C matrix with hicBuildMatrix, which includes some quality control of the Hi-C library. The results from the quality control can be viewed here.\nBut also, they are located in the steps/ folder as a log, so let’s read it into view:",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#functions-that-are-also-moved-into-hicstuff.py-script-for-import",
    "href": "notebooks/01_hicexplorer.html#functions-that-are-also-moved-into-hicstuff.py-script-for-import",
    "title": "HiCExplorer using macaque data",
    "section": "Functions that are also moved into hicstuff.py script for import",
    "text": "Functions that are also moved into hicstuff.py script for import\n\n# First, we will make a function to read the `.log` file into a `pandas` df. \n\nimport pandas as pd\nimport glob\n\n# All the files can be assigned to a list with glob.glob:\n# logs = glob.glob(\"../results/SRR*/*.log\")\n# they can be read with a for loop, but it's too messy to show. \n\n# The .log file is a tab-separated file with 4 tables, so we have to make our own function to read it\n# I wrapped it in a class to save all tables from each log in a single variable. \nclass HiCQCLog(): \n    def __init__(self, logfile):\n        reader = pd.read_csv(logfile, sep=\"\\t\", header=None, iterator=True)\n        t1 = reader.get_chunk(4).dropna(axis=1)\n        t1.columns=t1.iloc[0]\n        self.t1 = t1.drop(0).reset_index()\n\n        t2 = reader.get_chunk(6).dropna(axis=1)\n        t2.columns=t2.iloc[0]\n        self.t2 = t2.drop(4).reset_index()\n\n        t3 = reader.get_chunk(7) .dropna(axis=1)\n        t3.columns=t3.iloc[0]\n        self.t3 = t3.drop(10).reset_index()\n\n        t4 = reader.get_chunk(7).dropna(axis=1)\n        t4.columns=t4.iloc[0]\n        self.t4 = t4.drop(17).reset_index()\n        \n    def view(self):\n        display(self.t1, self.t2, self.t3, self.t4)\n  \n\n\n# Make a function to plot .pngs with matplotlib\n\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef plot_pngs_in_grid(image_folder, suffix=\".png\", ncol=3):\n    \"\"\"\n    Plots all PNG images from a specified folder in a grid.\n    \n    Parameters:\n    image_folder (str): Path to the folder containing the PNG files.\n    num_cols (int): Number of columns in the grid layout. Default is 3.\n    \n    Returns:\n    None\n    \"\"\"\n    # Find all .png files in the folder\n    # with a specified suffix (default: .png)\n    print(f\"Plotting all images in '{os.path.join(image_folder, f'*{suffix}')}'\")\n    image_files = glob.glob(os.path.join(image_folder, f'*{suffix}'))\n\n    # If no images found, print a message and return\n    if not image_files:\n        print(f\"No PNG files found in {image_folder}.\")\n        return\n    \n    # Calculate the number of rows needed\n    num_cols = ncol\n    num_images = len(image_files)\n    num_rows = (num_images + num_cols - 1) // num_cols  # Ceiling division\n\n    # Create a matplotlib figure\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n\n    # Flatten axes in case the grid is not a perfect rectangle\n    axes = axes.flatten()\n\n    # Loop through image files and plot them\n    for i, image_file in enumerate(image_files):\n        img = Image.open(image_file)  # Open the image file\n        axes[i].imshow(img)\n        axes[i].axis('off')  # Turn off axis labels\n        axes[i].set_title(os.path.basename(image_file))  # Set image title (filename)\n\n    # Hide any remaining empty subplots if the number of images is not a perfect fit for the grid\n    for j in range(i + 1, len(axes)):\n        axes[j].axis('off')\n\n    # Adjust layout to fit images and titles nicely\n    plt.tight_layout()\n    plt.show()\n\n\nglob.glob(os.path.join(\"../steps/bwa/QC_all_samples/\", f'*.png'))\n\n['../steps/bwa/QC_all_samples/read_orientation.png',\n '../steps/bwa/QC_all_samples/distance.png',\n '../steps/bwa/QC_all_samples/pairs_discarded.png',\n '../steps/bwa/QC_all_samples/unmappable_and_non_unique.png',\n '../steps/bwa/QC_all_samples/pairs_sequenced.png']",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#results-from-bwa",
    "href": "notebooks/01_hicexplorer.html#results-from-bwa",
    "title": "HiCExplorer using macaque data",
    "section": "Results from bwa",
    "text": "Results from bwa\n\nSRR35 = HiCQCLog(\"../results/SRR6502335_QC/QC.log\")\nSRR35.view()\n\n\n!hicQC --logfiles $(echo ../results/*_QC/QC.log) --labels \"SRR35\" \"SRR36\" \"SRR37\" \"SRR38\" \"SRR39\" --outputFolder ../steps/bwa/QC_all_samples\n\n\nplot_pngs_in_grid(\"../steps/bwa/QC_all_samples/\", ncol=2)\n\nPlotting all images in '../steps/bwa/QC_all_samples/*.png'\n\n\n\n\n\n\n\n\n\n\nNormalize matrices\n\n%%bash \n\nhicNormalize -m ../steps/SRR6502335_matrix.h5 --normalize norm_range -o SRR6502335_norm0_1.h5\n\n\n\nCreate a diagnostic plot\n\n#! hicexplorer\n! hicCorrectMatrix diagnostic_plot --help\n#! hicCorrectMatrix correct --help\n\nusage: hicCorrectMatrix diagnostic_plot --matrix hic_matrix.h5 -o file.png\n\noptions:\n  -h, --help            show this help message and exit\n\nRequired arguments:\n  --matrix MATRIX, -m MATRIX\n                        Name of the Hi-C matrix to correct in .h5 format.\n                        (default: None)\n  --plotName PLOTNAME, -o PLOTNAME\n                        File name to save the diagnostic plot. (default: None)\n\nOptional arguments:\n  --chromosomes CHROMOSOMES [CHROMOSOMES ...]\n                        List of chromosomes to be included in the iterative\n                        correction. The order of the given chromosomes will be\n                        then kept for the resulting corrected matrix.\n                        (default: None)\n  --xMax XMAX           Max value for the x-axis in counts per bin. (default:\n                        None)\n  --perchr              Compute histogram per chromosome. For samples from\n                        cells with uneven number of chromosomes and/or\n                        translocations it is advisable to check the histograms\n                        per chromosome to find the most conservative\n                        `filterThreshold`. (default: False)\n  --verbose             Print processing status. (default: False)\n\n\nLet’s make a loop that produce a diagnostic plot for all matrices in the folder:\n\n%%bash \n\nfor FILE in ../steps/*.h5\ndo\necho $(basename $FILE _matrix.h5)_diag_plot.png\nhicCorrectMatrix diagnostic_plot -m $FILE -o ../figures/$(basename $FILE _matrix.h5)_diag_plot.png\ndone\n\nSRR6502335_diag_plot.png\n\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 7859 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.5428248511904763\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot SRR6502335_diag_plot.png\n\n\n\nSRR6502336_diag_plot.png\n\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 7966 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.406856232876712\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot SRR6502336_diag_plot.png\n\n\n\nSRR6502337_diag_plot.png\n\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 8187 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.5774256637168143\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot SRR6502337_diag_plot.png\n\n\n\nSRR6502338_diag_plot.png\n\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 8172 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.689724621848739\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot SRR6502338_diag_plot.png\n\n\n\nSRR6502339_diag_plot.png\n\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 8969 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.698\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot SRR6502339_diag_plot.png\n\n\n\n\nplot_pngs_in_grid(\"../figures/bwa\", suffix=\"diag_plot.png\")\n\nPlotting all images in '../figures/bwa/*diag_plot.png'\n\n\n\n\n\n\n\n\n\n\n!hicCorrectMatrix diagnostic_plot -m SRR6502335_norm0_1.h5 -o diag_plot_norm.png\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 13359 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.0545956094919804\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot diag_plot_norm.png\n\n\n\n\n\nCorrect the matrices\nAnd do the correction with the suggested values and ICE. We are going to produce a corrected matrix for both with and without --perchr (per chromosome) option\n\n%%bash \n\nhicCorrectMatrix correct -m SRR6502335_norm0_1.h5 -o ./SRR6502335_norm0_1_corrected.h5 \\\n    --correctionMethod ICE \\\n    --filterThreshold -2 5\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 13359 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:matrix contains 21229234 data points. Sparsity 0.000.\nINFO:hicexplorer.hicCorrectMatrix:filtering by z-score\nINFO:hicexplorer.iterativeCorrection:starting iterative correction\nINFO:hicexplorer.iterativeCorrection:pass 5 Estimated time 0:2:29\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.909566849589952 \nINFO:hicexplorer.iterativeCorrection:pass 10 Estimated time 0:2:27\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 8.186419342166413 \nINFO:hicexplorer.iterativeCorrection:pass 15 Estimated time 0:2:24\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8938109193741166 \nINFO:hicexplorer.iterativeCorrection:pass 20 Estimated time 0:2:23\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 7.228200439559446 \nINFO:hicexplorer.iterativeCorrection:pass 25 Estimated time 0:2:22\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8790910335275449 \nINFO:hicexplorer.iterativeCorrection:pass 30 Estimated time 0:2:21\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 6.4417019516824885 \nINFO:hicexplorer.iterativeCorrection:pass 35 Estimated time 0:2:19\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8650482568145657 \nINFO:hicexplorer.iterativeCorrection:pass 40 Estimated time 0:2:18\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 5.79991880945091 \nINFO:hicexplorer.iterativeCorrection:pass 45 Estimated time 0:2:16\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8515610325149747 \nINFO:hicexplorer.iterativeCorrection:pass 50 Estimated time 0:2:15\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 5.270362519101916 \nINFO:hicexplorer.iterativeCorrection:pass 55 Estimated time 0:2:13\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8385658927762115 \nINFO:hicexplorer.iterativeCorrection:pass 60 Estimated time 0:2:12\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 4.827433615502592 \nINFO:hicexplorer.iterativeCorrection:pass 65 Estimated time 0:2:10\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8260196439783102 \nINFO:hicexplorer.iterativeCorrection:pass 70 Estimated time 0:2:9\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 4.452080477161172 \nINFO:hicexplorer.iterativeCorrection:pass 75 Estimated time 0:2:7\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8138884899499492 \nINFO:hicexplorer.iterativeCorrection:pass 80 Estimated time 0:2:6\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 4.130200536278638 \nINFO:hicexplorer.iterativeCorrection:pass 85 Estimated time 0:2:4\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.8021442447614385 \nINFO:hicexplorer.iterativeCorrection:pass 90 Estimated time 0:2:3\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 3.8512580422883165 \nINFO:hicexplorer.iterativeCorrection:pass 95 Estimated time 0:2:1\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7907626732591944 \nINFO:hicexplorer.iterativeCorrection:pass 100 Estimated time 0:2:0\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 3.6072719429655127 \nINFO:hicexplorer.iterativeCorrection:pass 105 Estimated time 0:1:58\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7797225650077778 \nINFO:hicexplorer.iterativeCorrection:pass 110 Estimated time 0:1:57\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 3.3921051862474654 \nINFO:hicexplorer.iterativeCorrection:pass 115 Estimated time 0:1:56\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7690051179967097 \nINFO:hicexplorer.iterativeCorrection:pass 120 Estimated time 0:1:54\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 3.200969091836857 \nINFO:hicexplorer.iterativeCorrection:pass 125 Estimated time 0:1:52\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7585934895900657 \nINFO:hicexplorer.iterativeCorrection:pass 130 Estimated time 0:1:51\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 3.0300755016903764 \nINFO:hicexplorer.iterativeCorrection:pass 135 Estimated time 0:1:50\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7484724565014031 \nINFO:hicexplorer.iterativeCorrection:pass 140 Estimated time 0:1:48\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.876389735422809 \nINFO:hicexplorer.iterativeCorrection:pass 145 Estimated time 0:1:46\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7386281528121921 \nINFO:hicexplorer.iterativeCorrection:pass 150 Estimated time 0:1:45\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.7374526645210087 \nINFO:hicexplorer.iterativeCorrection:pass 155 Estimated time 0:1:43\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7290478657442472 \nINFO:hicexplorer.iterativeCorrection:pass 160 Estimated time 0:1:42\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.61125069105262 \nINFO:hicexplorer.iterativeCorrection:pass 165 Estimated time 0:1:40\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7197198745758879 \nINFO:hicexplorer.iterativeCorrection:pass 170 Estimated time 0:1:39\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.4961193680916445 \nINFO:hicexplorer.iterativeCorrection:pass 175 Estimated time 0:1:37\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7106333219153745 \nINFO:hicexplorer.iterativeCorrection:pass 180 Estimated time 0:1:36\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.3906709792194154 \nINFO:hicexplorer.iterativeCorrection:pass 185 Estimated time 0:1:34\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.7017781093737747 \nINFO:hicexplorer.iterativeCorrection:pass 190 Estimated time 0:1:33\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.2937394223838408 \nINFO:hicexplorer.iterativeCorrection:pass 195 Estimated time 0:1:31\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6931448117980591 \nINFO:hicexplorer.iterativeCorrection:pass 200 Estimated time 0:1:30\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.2043377628045153 \nINFO:hicexplorer.iterativeCorrection:pass 205 Estimated time 0:1:28\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6847246057914107 \nINFO:hicexplorer.iterativeCorrection:pass 210 Estimated time 0:1:27\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.1216251819423557 \nINFO:hicexplorer.iterativeCorrection:pass 215 Estimated time 0:1:25\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6765092093873197 \nINFO:hicexplorer.iterativeCorrection:pass 220 Estimated time 0:1:24\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 2.0448809803593457 \nINFO:hicexplorer.iterativeCorrection:pass 225 Estimated time 0:1:22\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.668490830563762 \nINFO:hicexplorer.iterativeCorrection:pass 230 Estimated time 0:1:21\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.9734839366586194 \nINFO:hicexplorer.iterativeCorrection:pass 235 Estimated time 0:1:19\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6606621228701033 \nINFO:hicexplorer.iterativeCorrection:pass 240 Estimated time 0:1:18\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.9068957766214418 \nINFO:hicexplorer.iterativeCorrection:pass 245 Estimated time 0:1:16\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6530161468589186 \nINFO:hicexplorer.iterativeCorrection:pass 250 Estimated time 0:1:15\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.844647827663914 \nINFO:hicexplorer.iterativeCorrection:pass 255 Estimated time 0:1:13\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.645546336316785 \nINFO:hicexplorer.iterativeCorrection:pass 260 Estimated time 0:1:12\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.7863301645435703 \nINFO:hicexplorer.iterativeCorrection:pass 265 Estimated time 0:1:10\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6382464685075324 \nINFO:hicexplorer.iterativeCorrection:pass 270 Estimated time 0:1:9\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.7315827201333889 \nINFO:hicexplorer.iterativeCorrection:pass 275 Estimated time 0:1:7\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6311106378031317 \nINFO:hicexplorer.iterativeCorrection:pass 280 Estimated time 0:1:6\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.680087958547833 \nINFO:hicexplorer.iterativeCorrection:pass 285 Estimated time 0:1:4\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6241332321985289 \nINFO:hicexplorer.iterativeCorrection:pass 290 Estimated time 0:1:3\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.6315647996490972 \nINFO:hicexplorer.iterativeCorrection:pass 295 Estimated time 0:1:1\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6173089122990445 \nINFO:hicexplorer.iterativeCorrection:pass 300 Estimated time 0:0:60\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.585763552799874 \nINFO:hicexplorer.iterativeCorrection:pass 305 Estimated time 0:0:58\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.6106325924406156 \nINFO:hicexplorer.iterativeCorrection:pass 310 Estimated time 0:0:57\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.542461669855522 \nINFO:hicexplorer.iterativeCorrection:pass 315 Estimated time 0:0:55\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.604099423659678 \nINFO:hicexplorer.iterativeCorrection:pass 320 Estimated time 0:0:54\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.501460167201333 \nINFO:hicexplorer.iterativeCorrection:pass 325 Estimated time 0:0:52\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5977047782747636 \nINFO:hicexplorer.iterativeCorrection:pass 330 Estimated time 0:0:51\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.4625805972958585 \nINFO:hicexplorer.iterativeCorrection:pass 335 Estimated time 0:0:49\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5914442358786719 \nINFO:hicexplorer.iterativeCorrection:pass 340 Estimated time 0:0:48\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.4256624739653576 \nINFO:hicexplorer.iterativeCorrection:pass 345 Estimated time 0:0:46\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5853135705702154 \nINFO:hicexplorer.iterativeCorrection:pass 350 Estimated time 0:0:45\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.3905610742802716 \nINFO:hicexplorer.iterativeCorrection:pass 355 Estimated time 0:0:43\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5793087392795395 \nINFO:hicexplorer.iterativeCorrection:pass 360 Estimated time 0:0:42\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.357145554466836 \nINFO:hicexplorer.iterativeCorrection:pass 365 Estimated time 0:0:40\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5734258710618427 \nINFO:hicexplorer.iterativeCorrection:pass 370 Estimated time 0:0:39\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.325297328884087 \nINFO:hicexplorer.iterativeCorrection:pass 375 Estimated time 0:0:37\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5676612572517955 \nINFO:hicexplorer.iterativeCorrection:pass 380 Estimated time 0:0:36\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.2949086703183554 \nINFO:hicexplorer.iterativeCorrection:pass 385 Estimated time 0:0:34\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5620113423856818 \nINFO:hicexplorer.iterativeCorrection:pass 390 Estimated time 0:0:33\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.2658814972347767 \nINFO:hicexplorer.iterativeCorrection:pass 395 Estimated time 0:0:31\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5564727158107357 \nINFO:hicexplorer.iterativeCorrection:pass 400 Estimated time 0:0:30\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.2381263195753522 \nINFO:hicexplorer.iterativeCorrection:pass 405 Estimated time 0:0:28\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5510421039116955 \nINFO:hicexplorer.iterativeCorrection:pass 410 Estimated time 0:0:27\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.2115613195100305 \nINFO:hicexplorer.iterativeCorrection:pass 415 Estimated time 0:0:25\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5457163628935884 \nINFO:hicexplorer.iterativeCorrection:pass 420 Estimated time 0:0:24\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.1861115474657904 \nINFO:hicexplorer.iterativeCorrection:pass 425 Estimated time 0:0:22\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5404924720673956 \nINFO:hicexplorer.iterativeCorrection:pass 430 Estimated time 0:0:21\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.1617082169612458 \nINFO:hicexplorer.iterativeCorrection:pass 435 Estimated time 0:0:19\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5353675275918063 \nINFO:hicexplorer.iterativeCorrection:pass 440 Estimated time 0:0:18\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.138288084403169 \nINFO:hicexplorer.iterativeCorrection:pass 445 Estimated time 0:0:16\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5303387366298477 \nINFO:hicexplorer.iterativeCorrection:pass 450 Estimated time 0:0:15\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.115792902168486 \nINFO:hicexplorer.iterativeCorrection:pass 455 Estimated time 0:0:13\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5254034118840032 \nINFO:hicexplorer.iterativeCorrection:pass 460 Estimated time 0:0:12\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.0941689350888613 \nINFO:hicexplorer.iterativeCorrection:pass 465 Estimated time 0:0:10\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5205589664775546 \nINFO:hicexplorer.iterativeCorrection:pass 470 Estimated time 0:0:9\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.073366531945267 \nINFO:hicexplorer.iterativeCorrection:pass 475 Estimated time 0:0:7\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5158029091534628 \nINFO:hicexplorer.iterativeCorrection:pass 480 Estimated time 0:0:6\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.05333974482263 \nINFO:hicexplorer.iterativeCorrection:pass 485 Estimated time 0:0:4\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5111328397651806 \nINFO:hicexplorer.iterativeCorrection:pass 490 Estimated time 0:0:3\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.0340459902146093 \nINFO:hicexplorer.iterativeCorrection:pass 495 Estimated time 0:0:1\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 0.5065464450364833 \nINFO:hicexplorer.iterativeCorrection:pass 500 Estimated time 0:0:0\nINFO:hicexplorer.iterativeCorrection:max delta - 1 = 1.0154457466418232 \n\n\n\n!hicInfo -m SRR6502335_norm0_1_corrected.h5\n\n# Matrix information file. Created with HiCExplorer's hicInfo version 3.7.5\nFile:   SRR6502335_norm0_1_corrected.h5\nSize:   298,615\nBin_length: 10000\nSum of matrix:  12588.40042256422\nChromosomes:length: NC_041754.1: 223616942 bp; NW_021160094.1: 26680 bp; NW_021160095.1: 32580 bp; NW_021160096.1: 33548 bp; NW_021160097.1: 37051 bp; NW_021160098.1: 39993 bp; NW_021160099.1: 40438 bp; NW_021160100.1: 43990 bp; NW_021160101.1: 48895 bp; NW_021160102.1: 50188 bp; NW_021160103.1: 51363 bp; NW_021160104.1: 35879 bp; NW_021160105.1: 54860 bp; NW_021160106.1: 55541 bp; NW_021160107.1: 55582 bp; NW_021160108.1: 59940 bp; NW_021160109.1: 82305 bp; NW_021160110.1: 118135 bp; NW_021160111.1: 133025 bp; NW_021160112.1: 52076 bp; NW_021160113.1: 116334 bp; NW_021160114.1: 65914 bp; NC_041755.1: 196197964 bp; NW_021160115.1: 30586 bp; NW_021160116.1: 35391 bp; NW_021160117.1: 40656 bp; NW_021160118.1: 51074 bp; NW_021160119.1: 48342 bp; NW_021160120.1: 52951 bp; NW_021160121.1: 86201 bp; NW_021160122.1: 92040 bp; NW_021160123.1: 52934 bp; NW_021160124.1: 54780 bp; NC_041756.1: 185288947 bp; NW_021160125.1: 25300 bp; NW_021160126.1: 29349 bp; NW_021160127.1: 29445 bp; NW_021160128.1: 29713 bp; NW_021160129.1: 36488 bp; NW_021160130.1: 29788 bp; NW_021160131.1: 42544 bp; NW_021160132.1: 43837 bp; NW_021160133.1: 51062 bp; NW_021160134.1: 54307 bp; NW_021160135.1: 54760 bp; NW_021160136.1: 59741 bp; NW_021160137.1: 70296 bp; NW_021160138.1: 72641 bp; NW_021160139.1: 94715 bp; NW_021160140.1: 130268 bp; NW_021160141.1: 134158 bp; NW_021160142.1: 47814 bp; NW_021160143.1: 30503 bp; NW_021160144.1: 1229889 bp; NC_041757.1: 169963040 bp; NW_021160145.1: 26875 bp; NW_021160146.1: 27011 bp; NW_021160147.1: 30037 bp; NW_021160148.1: 34319 bp; NW_021160149.1: 36085 bp; NW_021160150.1: 37498 bp; NW_021160151.1: 45706 bp; NW_021160152.1: 47138 bp; NW_021160153.1: 52252 bp; NW_021160154.1: 54371 bp; NW_021160155.1: 54530 bp; NW_021160156.1: 54679 bp; NW_021160157.1: 60005 bp; NW_021160158.1: 75365 bp; NW_021160159.1: 85793 bp; NW_021160160.1: 90302 bp; NW_021160161.1: 738392 bp; NC_041758.1: 187317192 bp; NW_021160162.1: 26685 bp; NW_021160163.1: 29791 bp; NW_021160164.1: 32640 bp; NW_021160165.1: 34222 bp; NW_021160166.1: 35517 bp; NW_021160167.1: 37838 bp; NW_021160168.1: 41651 bp; NW_021160169.1: 41841 bp; NW_021160170.1: 36351 bp; NW_021160171.1: 48938 bp; NW_021160172.1: 56442 bp; NW_021160173.1: 68769 bp; NW_021160174.1: 103593 bp; NW_021160175.1: 185143 bp; NW_021160176.1: 39093 bp; NC_041759.1: 179085566 bp; NW_021160177.1: 27603 bp; NW_021160178.1: 28241 bp; NW_021160179.1: 38876 bp; NW_021160180.1: 39393 bp; NW_021160181.1: 47332 bp; NW_021160182.1: 58084 bp; NW_021160183.1: 57998 bp; NW_021160184.1: 61300 bp; NW_021160185.1: 62126 bp; NW_021160186.1: 64491 bp; NW_021160187.1: 76406 bp; NW_021160188.1: 82950 bp; NW_021160189.1: 101334 bp; NW_021160190.1: 35732 bp; NC_041760.1: 169868564 bp; NW_021160191.1: 27859 bp; NW_021160192.1: 28798 bp; NW_021160193.1: 31162 bp; NW_021160194.1: 35826 bp; NW_021160195.1: 41366 bp; NW_021160196.1: 46105 bp; NW_021160197.1: 51812 bp; NW_021160198.1: 53832 bp; NW_021160199.1: 55920 bp; NW_021160200.1: 58999 bp; NW_021160201.1: 61446 bp; NW_021160202.1: 65479 bp; NW_021160203.1: 72206 bp; NW_021160204.1: 72836 bp; NW_021160205.1: 73247 bp; NW_021160206.1: 83758 bp; NW_021160207.1: 98820 bp; NW_021160208.1: 31768 bp; NC_041761.1: 145679320 bp; NW_021160209.1: 669983 bp; NW_021160210.1: 32194 bp; NW_021160211.1: 133312 bp; NW_021160212.1: 35273 bp; NW_021160213.1: 35782 bp; NW_021160214.1: 36168 bp; NW_021160215.1: 38408 bp; NW_021160216.1: 28604 bp; NW_021160217.1: 45844 bp; NW_021160218.1: 54299 bp; NW_021160219.1: 59871 bp; NW_021160220.1: 66719 bp; NW_021160221.1: 70864 bp; NW_021160222.1: 76376 bp; NW_021160223.1: 83314 bp; NW_021160224.1: 29721 bp; NW_021160225.1: 53832 bp; NC_041762.1: 134124166 bp; NW_021160226.1: 36031 bp; NW_021160227.1: 39733 bp; NW_021160228.1: 47833 bp; NW_021160229.1: 47980 bp; NW_021160230.1: 52082 bp; NW_021160231.1: 54497 bp; NW_021160232.1: 56716 bp; NW_021160233.1: 64642 bp; NW_021160234.1: 65546 bp; NW_021160235.1: 66711 bp; NW_021160236.1: 77799 bp; NW_021160237.1: 85724 bp; NW_021160238.1: 104447 bp; NW_021160239.1: 29162 bp; NW_021160240.1: 47554 bp; NC_041763.1: 99517758 bp; NW_021160241.1: 29490 bp; NW_021160242.1: 29551 bp; NW_021160243.1: 31521 bp; NW_021160244.1: 35220 bp; NW_021160245.1: 43762 bp; NW_021160246.1: 43668 bp; NW_021160247.1: 45264 bp; NW_021160248.1: 74751 bp; NW_021160249.1: 75692 bp; NW_021160250.1: 64301 bp; NW_021160251.1: 84426 bp; NW_021160252.1: 88635 bp; NW_021160253.1: 115549 bp; NW_021160254.1: 31739 bp; NC_041764.1: 133066086 bp; NW_021160255.1: 28076 bp; NW_021160256.1: 30974 bp; NW_021160257.1: 34094 bp; NW_021160258.1: 35836 bp; NW_021160259.1: 36993 bp; NW_021160260.1: 42603 bp; NW_021160261.1: 44793 bp; NW_021160262.1: 36901 bp; NW_021160263.1: 52625 bp; NW_021160264.1: 65186 bp; NW_021160265.1: 70089 bp; NW_021160266.1: 75026 bp; NW_021160267.1: 86584 bp; NW_021160268.1: 67726 bp; NC_041765.1: 130043856 bp; NW_021160269.1: 30461 bp; NW_021160270.1: 34828 bp; NW_021160271.1: 34758 bp; NW_021160272.1: 34993 bp; NW_021160273.1: 40200 bp; NW_021160274.1: 35195 bp; NW_021160275.1: 39160 bp; NC_041766.1: 108737130 bp; NW_021160276.1: 53508 bp; NW_021160277.1: 44853 bp; NW_021160278.1: 55639 bp; NW_021160279.1: 65990 bp; NW_021160280.1: 57542 bp; NW_021160281.1: 89870 bp; NW_021160282.1: 123715 bp; NC_041767.1: 128056306 bp; NW_021160283.1: 32550 bp; NW_021160284.1: 34793 bp; NW_021160285.1: 44605 bp; NW_021160286.1: 36893 bp; NW_021160287.1: 37575 bp; NW_021160288.1: 37831 bp; NW_021160289.1: 37661 bp; NW_021160290.1: 44420 bp; NW_021160291.1: 45281 bp; NW_021160292.1: 46256 bp; NW_021160293.1: 52830 bp; NW_021160294.1: 79630 bp; NW_021160295.1: 82543 bp; NW_021160296.1: 51233 bp; NW_021160297.1: 56227 bp; NW_021160298.1: 27245 bp; NW_021160299.1: 29900 bp; NW_021160300.1: 62273 bp; NC_041768.1: 113283604 bp; NW_021160301.1: 35411 bp; NW_021160302.1: 36170 bp; NW_021160303.1: 38712 bp; NW_021160304.1: 39777 bp; NW_021160305.1: 40306 bp; NW_021160306.1: 39466 bp; NW_021160307.1: 52687 bp; NW_021160308.1: 53925 bp; NW_021160309.1: 53926 bp; NW_021160310.1: 58262 bp; NW_021160311.1: 78748 bp; NW_021160312.1: 88419 bp; NW_021160313.1: 94627 bp; NW_021160314.1: 27791 bp; NC_041769.1: 79627064 bp; NW_021160315.1: 28177 bp; NW_021160316.1: 33884 bp; NW_021160317.1: 34745 bp; NW_021160318.1: 50438 bp; NW_021160319.1: 43437 bp; NW_021160320.1: 52552 bp; NW_021160321.1: 54058 bp; NW_021160322.1: 54071 bp; NW_021160323.1: 54349 bp; NW_021160324.1: 63611 bp; NW_021160325.1: 65150 bp; NW_021160326.1: 65140 bp; NW_021160327.1: 65979 bp; NW_021160328.1: 63325 bp; NW_021160329.1: 53701 bp; NW_021160330.1: 27229 bp; NC_041770.1: 95433459 bp; NW_021160331.1: 25947 bp; NW_021160332.1: 181889 bp; NW_021160333.1: 31091 bp; NW_021160334.1: 31166 bp; NW_021160335.1: 31184 bp; NW_021160336.1: 31250 bp; NW_021160337.1: 43610 bp; NW_021160338.1: 37523 bp; NW_021160339.1: 38541 bp; NW_021160340.1: 45093 bp; NW_021160341.1: 46306 bp; NW_021160342.1: 46347 bp; NW_021160343.1: 50375 bp; NW_021160344.1: 59026 bp; NW_021160345.1: 61686 bp; NW_021160346.1: 61907 bp; NW_021160347.1: 165269 bp; NW_021160348.1: 27125 bp; NW_021160349.1: 15354 bp; NC_041771.1: 74474043 bp; NW_021160350.1: 32300 bp; NW_021160351.1: 37145 bp; NW_021160352.1: 37664 bp; NW_021160353.1: 41176 bp; NW_021160354.1: 41974 bp; NW_021160355.1: 55554 bp; NW_021160356.1: 76316 bp; NC_041772.1: 58315233 bp; NW_021160357.1: 30450 bp; NW_021160358.1: 39455 bp; NW_021160359.1: 41056 bp; NW_021160360.1: 44182 bp; NW_021160361.1: 47076 bp; NW_021160362.1: 53667 bp; NW_021160363.1: 60928 bp; NW_021160364.1: 61817 bp; NW_021160365.1: 66433 bp; NW_021160366.1: 71257 bp; NW_021160367.1: 76390 bp; NW_021160368.1: 78939 bp; NW_021160369.1: 81779 bp; NW_021160370.1: 89493 bp; NW_021160371.1: 90411 bp; NW_021160372.1: 134439 bp; NW_021160373.1: 58152 bp; NW_021160374.1: 124323 bp; NW_021160375.1: 183828 bp; NW_021160376.1: 862827 bp; NC_041773.1: 77137495 bp; NW_021160377.1: 26276 bp; NW_021160378.1: 34752 bp; NW_021160379.1: 36919 bp; NW_021160380.1: 64383 bp; NC_041774.1: 153388924 bp; NW_021160381.1: 48696 bp; NW_021160382.1: 50511 bp; NW_021160383.1: 68997 bp; NW_021160384.1: 79627 bp; NC_027914.1: 11753682 bp; NW_021160385.1: 16018 bp; NW_021160386.1: 16072 bp; NW_021160387.1: 15993 bp; NW_021160388.1: 16197 bp; NW_021160389.1: 16074 bp; NW_021160390.1: 16042 bp; NW_021160391.1: 16077 bp; NW_021160392.1: 15853 bp; NW_021160393.1: 15981 bp; NW_021160394.1: 16244 bp; NW_021160395.1: 32289 bp; NW_021160396.1: 16160 bp; NW_021160397.1: 16187 bp; NW_021160398.1: 16363 bp; NW_021160399.1: 16120 bp; NW_021160400.1: 16055 bp; NW_021160401.1: 16274 bp; NW_021160402.1: 16364 bp; NW_021160403.1: 16225 bp; NW_021160404.1: 16356 bp; NW_021160405.1: 16255 bp; NW_021160406.1: 27321 bp; NW_021160407.1: 16236 bp; NW_021160408.1: 16356 bp; NW_021160409.1: 16461 bp; NW_021160410.1: 16455 bp; NW_021160411.1: 16383 bp; NW_021160412.1: 16352 bp; NW_021160413.1: 15013 bp; NW_021160414.1: 16280 bp; NW_021160415.1: 16551 bp; NW_021160416.1: 16444 bp; NW_021160417.1: 56609 bp; NW_021160418.1: 16439 bp; NW_021160419.1: 16412 bp; NW_021160420.1: 16632 bp; NW_021160421.1: 16299 bp; NW_021160422.1: 16406 bp; NW_021160423.1: 16596 bp; NW_021160424.1: 16436 bp; NW_021160425.1: 16779 bp; NW_021160426.1: 16773 bp; NW_021160427.1: 13224 bp; NW_021160428.1: 14311 bp; NW_021160429.1: 16475 bp; NW_021160430.1: 16734 bp; NW_021160431.1: 15042 bp; NW_021160432.1: 16653 bp; NW_021160433.1: 16729 bp; NW_021160434.1: 16730 bp; NW_021160435.1: 16370 bp; NW_021160436.1: 16749 bp; NW_021160437.1: 16651 bp; NW_021160438.1: 16692 bp; NW_021160439.1: 24869 bp; NW_021160440.1: 16634 bp; NW_021160441.1: 16844 bp; NW_021160442.1: 16892 bp; NW_021160443.1: 16406 bp; NW_021160444.1: 16960 bp; NW_021160445.1: 16925 bp; NW_021160446.1: 16946 bp; NW_021160447.1: 17035 bp; NW_021160448.1: 16874 bp; NW_021160449.1: 16960 bp; NW_021160450.1: 15132 bp; NW_021160451.1: 17048 bp; NW_021160452.1: 16930 bp; NW_021160453.1: 16900 bp; NW_021160454.1: 16782 bp; NW_021160455.1: 16399 bp; NW_021160456.1: 17005 bp; NW_021160457.1: 16760 bp; NW_021160458.1: 16880 bp; NW_021160459.1: 16975 bp; NW_021160460.1: 13066 bp; NW_021160461.1: 17407 bp; NW_021160462.1: 17041 bp; NW_021160463.1: 17431 bp; NW_021160464.1: 17069 bp; NW_021160465.1: 17372 bp; NW_021160466.1: 25112 bp; NW_021160467.1: 16450 bp; NW_021160468.1: 16857 bp; NW_021160469.1: 17184 bp; NW_021160470.1: 17258 bp; NW_021160471.1: 17214 bp; NW_021160472.1: 14066 bp; NW_021160473.1: 17331 bp; NW_021160474.1: 17274 bp; NW_021160475.1: 17243 bp; NW_021160476.1: 17185 bp; NW_021160477.1: 16695 bp; NW_021160478.1: 17197 bp; NW_021160479.1: 17342 bp; NW_021160480.1: 17231 bp; NW_021160481.1: 17498 bp; NW_021160482.1: 17275 bp; NW_021160483.1: 29983 bp; NW_021160484.1: 17398 bp; NW_021160485.1: 17418 bp; NW_021160486.1: 17582 bp; NW_021160487.1: 17409 bp; NW_021160488.1: 17349 bp; NW_021160489.1: 17478 bp; NW_021160490.1: 17439 bp; NW_021160491.1: 17634 bp; NW_021160492.1: 17843 bp; NW_021160493.1: 17802 bp; NW_021160494.1: 31063 bp; NW_021160495.1: 823856 bp; NW_021160496.1: 17707 bp; NW_021160497.1: 9903 bp; NW_021160498.1: 17583 bp; NW_021160499.1: 17715 bp; NW_021160500.1: 17761 bp; NW_021160501.1: 17739 bp; NW_021160502.1: 17822 bp; NW_021160503.1: 17886 bp; NW_021160504.1: 17447 bp; NW_021160505.1: 17932 bp; NW_021160506.1: 37152 bp; NW_021160507.1: 17654 bp; NW_021160508.1: 17964 bp; NW_021160509.1: 17871 bp; NW_021160510.1: 17895 bp; NW_021160511.1: 18023 bp; NW_021160512.1: 17833 bp; NW_021160513.1: 17917 bp; NW_021160514.1: 18018 bp; NW_021160515.1: 17912 bp; NW_021160516.1: 17825 bp; NW_021160517.1: 45053 bp; NW_021160518.1: 17844 bp; NW_021160519.1: 25372 bp; NW_021160520.1: 17956 bp; NW_021160521.1: 18075 bp; NW_021160522.1: 17870 bp; NW_021160523.1: 18079 bp; NW_021160524.1: 18166 bp; NW_021160525.1: 18142 bp; NW_021160526.1: 18128 bp; NW_021160527.1: 18335 bp; NW_021160528.1: 30841 bp; NW_021160529.1: 18029 bp; NW_021160530.1: 18339 bp; NW_021160531.1: 18298 bp; NW_021160532.1: 17970 bp; NW_021160533.1: 4886 bp; NW_021160534.1: 17870 bp; NW_021160535.1: 18327 bp; NW_021160536.1: 18353 bp; NW_021160537.1: 18435 bp; NW_021160538.1: 18512 bp; NW_021160539.1: 21919 bp; NW_021160540.1: 18498 bp; NW_021160541.1: 18217 bp; NW_021160542.1: 18414 bp; NW_021160543.1: 18158 bp; NW_021160544.1: 18591 bp; NW_021160545.1: 18512 bp; NW_021160546.1: 18667 bp; NW_021160547.1: 18610 bp; NW_021160548.1: 18647 bp; NW_021160549.1: 18566 bp; NW_021160550.1: 13685 bp; NW_021160551.1: 17982 bp; NW_021160552.1: 18464 bp; NW_021160553.1: 18792 bp; NW_021160554.1: 18592 bp; NW_021160555.1: 18898 bp; NW_021160556.1: 18723 bp; NW_021160557.1: 18775 bp; NW_021160558.1: 18888 bp; NW_021160559.1: 18851 bp; NW_021160560.1: 18781 bp; NW_021160561.1: 17329 bp; NW_021160562.1: 18779 bp; NW_021160563.1: 18436 bp; NW_021160564.1: 19001 bp; NW_021160565.1: 19096 bp; NW_021160566.1: 19092 bp; NW_021160567.1: 19055 bp; NW_021160568.1: 18522 bp; NW_021160569.1: 19175 bp; NW_021160570.1: 18878 bp; NW_021160571.1: 18966 bp; NW_021160572.1: 30668 bp; NW_021160573.1: 19035 bp; NW_021160574.1: 18898 bp; NW_021160575.1: 18602 bp; NW_021160576.1: 19066 bp; NW_021160577.1: 18466 bp; NW_021160578.1: 19017 bp; NW_021160579.1: 19182 bp; NW_021160580.1: 19023 bp; NW_021160581.1: 19094 bp; NW_021160582.1: 19115 bp; NW_021160583.1: 14050 bp; NW_021160584.1: 19074 bp; NW_021160585.1: 19199 bp; NW_021160586.1: 19104 bp; NW_021160587.1: 19229 bp; NW_021160588.1: 19321 bp; NW_021160589.1: 19224 bp; NW_021160590.1: 18933 bp; NW_021160591.1: 19468 bp; NW_021160592.1: 19333 bp; NW_021160593.1: 19521 bp; NW_021160594.1: 23168 bp; NW_021160595.1: 19531 bp; NW_021160596.1: 18714 bp; NW_021160597.1: 19321 bp; NW_021160598.1: 19626 bp; NW_021160599.1: 19589 bp; NW_021160600.1: 19477 bp; NW_021160601.1: 19413 bp; NW_021160602.1: 19316 bp; NW_021160603.1: 19921 bp; NW_021160604.1: 19279 bp; NW_021160605.1: 26327 bp; NW_021160606.1: 1005795 bp; NW_021160607.1: 19622 bp; NW_021160608.1: 19734 bp; NW_021160609.1: 19629 bp; NW_021160610.1: 19448 bp; NW_021160611.1: 19615 bp; NW_021160612.1: 19821 bp; NW_021160613.1: 19395 bp; NW_021160614.1: 19863 bp; NW_021160615.1: 19786 bp; NW_021160616.1: 19715 bp; NW_021160617.1: 45369 bp; NW_021160618.1: 19805 bp; NW_021160619.1: 20031 bp; NW_021160620.1: 19816 bp; NW_021160621.1: 19778 bp; NW_021160622.1: 20070 bp; NW_021160623.1: 19785 bp; NW_021160624.1: 19783 bp; NW_021160625.1: 19793 bp; NW_021160626.1: 19837 bp; NW_021160627.1: 18955 bp; NW_021160628.1: 17118 bp; NW_021160629.1: 19901 bp; NW_021160630.1: 20090 bp; NW_021160631.1: 20077 bp; NW_021160632.1: 19990 bp; NW_021160633.1: 19954 bp; NW_021160634.1: 20187 bp; NW_021160635.1: 20086 bp; NW_021160636.1: 20106 bp; NW_021160637.1: 20216 bp; NW_021160638.1: 20150 bp; NW_021160639.1: 31988 bp; NW_021160640.1: 20147 bp; NW_021160641.1: 20246 bp; NW_021160642.1: 20482 bp; NW_021160643.1: 20534 bp; NW_021160644.1: 20198 bp; NW_021160645.1: 20467 bp; NW_021160646.1: 20493 bp; NW_021160647.1: 20408 bp; NW_021160648.1: 20428 bp; NW_021160649.1: 20368 bp; NW_021160650.1: 16400 bp; NW_021160651.1: 20362 bp; NW_021160652.1: 20339 bp; NW_021160653.1: 20634 bp; NW_021160654.1: 20501 bp; NW_021160655.1: 20574 bp; NW_021160656.1: 20461 bp; NW_021160657.1: 20246 bp; NW_021160658.1: 20241 bp; NW_021160659.1: 20534 bp; NW_021160660.1: 21334 bp; NW_021160661.1: 36744 bp; NW_021160662.1: 20529 bp; NW_021160663.1: 20559 bp; NW_021160664.1: 20658 bp; NW_021160665.1: 20613 bp; NW_021160666.1: 20822 bp; NW_021160667.1: 20849 bp; NW_021160668.1: 20935 bp; NW_021160669.1: 20668 bp; NW_021160670.1: 20900 bp; NW_021160671.1: 20718 bp; NW_021160672.1: 30183 bp; NW_021160673.1: 20657 bp; NW_021160674.1: 20802 bp; NW_021160675.1: 20879 bp; NW_021160676.1: 21004 bp; NW_021160677.1: 20886 bp; NW_021160678.1: 20778 bp; NW_021160679.1: 20860 bp; NW_021160680.1: 20707 bp; NW_021160681.1: 21022 bp; NW_021160682.1: 20725 bp; NW_021160683.1: 23684 bp; NW_021160684.1: 20961 bp; NW_021160685.1: 21045 bp; NW_021160686.1: 20908 bp; NW_021160687.1: 20771 bp; NW_021160688.1: 20419 bp; NW_021160689.1: 20607 bp; NW_021160690.1: 21064 bp; NW_021160691.1: 20966 bp; NW_021160692.1: 20986 bp; NW_021160693.1: 20465 bp; NW_021160694.1: 22503 bp; NW_021160695.1: 21235 bp; NW_021160696.1: 21230 bp; NW_021160697.1: 21296 bp; NW_021160698.1: 21211 bp; NW_021160699.1: 21225 bp; NW_021160700.1: 21443 bp; NW_021160701.1: 21216 bp; NW_021160702.1: 20977 bp; NW_021160703.1: 21436 bp; NW_021160704.1: 21339 bp; NW_021160705.1: 23258 bp; NW_021160706.1: 21593 bp; NW_021160707.1: 21609 bp; NW_021160708.1: 21287 bp; NW_021160709.1: 21524 bp; NW_021160710.1: 21606 bp; NW_021160711.1: 21464 bp; NW_021160712.1: 21743 bp; NW_021160713.1: 21497 bp; NW_021160714.1: 21711 bp; NW_021160715.1: 21490 bp; NW_021160716.1: 63953 bp; NW_021160717.1: 21569 bp; NW_021160718.1: 21401 bp; NW_021160719.1: 21484 bp; NW_021160720.1: 21743 bp; NW_021160721.1: 21665 bp; NW_021160722.1: 21527 bp; NW_021160723.1: 21571 bp; NW_021160724.1: 21865 bp; NW_021160725.1: 21649 bp; NW_021160726.1: 21748 bp; NW_021160727.1: 23130 bp; NW_021160728.1: 21366 bp; NW_021160729.1: 21872 bp; NW_021160730.1: 21887 bp; NW_021160731.1: 21524 bp; NW_021160732.1: 21553 bp; NW_021160733.1: 21548 bp; NW_021160734.1: 21766 bp; NW_021160735.1: 21725 bp; NW_021160736.1: 21798 bp; NW_021160737.1: 21776 bp; NW_021160738.1: 25308 bp; NW_021160739.1: 21868 bp; NW_021160740.1: 19723 bp; NW_021160741.1: 22083 bp; NW_021160742.1: 21314 bp; NW_021160743.1: 22115 bp; NW_021160744.1: 22112 bp; NW_021160745.1: 22087 bp; NW_021160746.1: 15615 bp; NW_021160747.1: 22160 bp; NW_021160748.1: 22295 bp; NW_021160749.1: 41788 bp; NW_021160750.1: 12751 bp; NW_021160751.1: 22356 bp; NW_021160752.1: 22350 bp; NW_021160753.1: 21971 bp; NW_021160754.1: 22417 bp; NW_021160755.1: 22262 bp; NW_021160756.1: 22075 bp; NW_021160757.1: 22132 bp; NW_021160758.1: 21975 bp; NW_021160759.1: 22284 bp; NW_021160760.1: 29374 bp; NW_021160761.1: 22427 bp; NW_021160762.1: 22607 bp; NW_021160763.1: 22136 bp; NW_021160764.1: 22325 bp; NW_021160765.1: 22088 bp; NW_021160766.1: 22489 bp; NW_021160767.1: 21513 bp; NW_021160768.1: 22590 bp; NW_021160769.1: 22234 bp; NW_021160770.1: 22632 bp; NW_021160771.1: 23071 bp; NW_021160772.1: 22676 bp; NW_021160773.1: 22333 bp; NW_021160774.1: 22820 bp; NW_021160775.1: 21482 bp; NW_021160776.1: 22690 bp; NW_021160777.1: 22755 bp; NW_021160778.1: 22884 bp; NW_021160779.1: 23055 bp; NW_021160780.1: 22842 bp; NW_021160781.1: 22941 bp; NW_021160782.1: 18782 bp; NW_021160783.1: 23171 bp; NW_021160784.1: 22867 bp; NW_021160785.1: 22632 bp; NW_021160786.1: 22775 bp; NW_021160787.1: 23152 bp; NW_021160788.1: 22922 bp; NW_021160789.1: 22503 bp; NW_021160790.1: 23032 bp; NW_021160791.1: 23100 bp; NW_021160792.1: 20775 bp; NW_021160793.1: 19205 bp; NW_021160794.1: 23266 bp; NW_021160795.1: 23004 bp; NW_021160796.1: 21665 bp; NW_021160797.1: 22924 bp; NW_021160798.1: 23409 bp; NW_021160799.1: 23642 bp; NW_021160800.1: 23391 bp; NW_021160801.1: 22177 bp; NW_021160802.1: 23309 bp; NW_021160803.1: 23292 bp; NW_021160804.1: 42279 bp; NW_021160805.1: 23446 bp; NW_021160806.1: 23508 bp; NW_021160807.1: 23436 bp; NW_021160808.1: 23521 bp; NW_021160809.1: 23573 bp; NW_021160810.1: 25708 bp; NW_021160811.1: 23453 bp; NW_021160812.1: 23338 bp; NW_021160813.1: 23447 bp; NW_021160814.1: 23725 bp; NW_021160815.1: 68025 bp; NW_021160816.1: 23193 bp; NW_021160817.1: 24347 bp; NW_021160818.1: 25323 bp; NW_021160819.1: 23808 bp; NW_021160820.1: 24050 bp; NW_021160821.1: 23917 bp; NW_021160822.1: 24122 bp; NW_021160823.1: 24029 bp; NW_021160824.1: 23823 bp; NW_021160825.1: 23843 bp; NW_021160826.1: 51428 bp; NW_021160827.1: 733739 bp; NW_021160828.1: 24117 bp; NW_021160829.1: 24244 bp; NW_021160830.1: 24497 bp; NW_021160831.1: 24203 bp; NW_021160832.1: 24079 bp; NW_021160833.1: 23564 bp; NW_021160834.1: 24117 bp; NW_021160835.1: 16995 bp; NW_021160836.1: 23941 bp; NW_021160837.1: 22593 bp; NW_021160838.1: 25136 bp; NW_021160839.1: 24518 bp; NW_021160840.1: 23988 bp; NW_021160841.1: 23835 bp; NW_021160842.1: 24450 bp; NW_021160843.1: 23998 bp; NW_021160844.1: 24299 bp; NW_021160845.1: 24216 bp; NW_021160846.1: 24238 bp; NW_021160847.1: 22859 bp; NW_021160848.1: 24307 bp; NW_021160849.1: 12570 bp; NW_021160850.1: 24363 bp; NW_021160851.1: 24623 bp; NW_021160852.1: 24760 bp; NW_021160853.1: 24310 bp; NW_021160854.1: 24717 bp; NW_021160855.1: 24805 bp; NW_021160856.1: 24527 bp; NW_021160857.1: 24541 bp; NW_021160858.1: 24566 bp; NW_021160859.1: 24741 bp; NW_021160860.1: 39850 bp; NW_021160861.1: 24747 bp; NW_021160862.1: 24285 bp; NW_021160863.1: 24714 bp; NW_021160864.1: 24895 bp; NW_021160865.1: 24789 bp; NW_021160866.1: 24816 bp; NW_021160867.1: 24825 bp; NW_021160868.1: 24426 bp; NW_021160869.1: 24994 bp; NW_021160870.1: 24709 bp; NW_021160871.1: 46859 bp; NW_021160872.1: 24800 bp; NW_021160873.1: 24862 bp; NW_021160874.1: 24990 bp; NW_021160875.1: 25175 bp; NW_021160876.1: 24652 bp; NW_021160877.1: 25176 bp; NW_021160878.1: 25198 bp; NW_021160879.1: 25199 bp; NW_021160880.1: 25292 bp; NW_021160881.1: 25113 bp; NW_021160882.1: 18857 bp; NW_021160883.1: 25049 bp; NW_021160884.1: 25169 bp; NW_021160885.1: 25192 bp; NW_021160886.1: 25188 bp; NW_021160887.1: 25142 bp; NW_021160888.1: 25299 bp; NW_021160889.1: 24083 bp; NW_021160890.1: 25247 bp; NW_021160891.1: 25234 bp; NW_021160892.1: 25507 bp; NW_021160893.1: 32501 bp; NW_021160894.1: 25348 bp; NW_021160895.1: 25389 bp; NW_021160896.1: 25176 bp; NW_021160897.1: 25314 bp; NW_021160898.1: 25232 bp; NW_021160899.1: 25535 bp; NW_021160900.1: 25245 bp; NW_021160901.1: 25530 bp; NW_021160902.1: 25360 bp; NW_021160903.1: 26486 bp; NW_021160904.1: 2040 bp; NW_021160905.1: 25508 bp; NW_021160906.1: 25392 bp; NW_021160907.1: 25025 bp; NW_021160908.1: 25719 bp; NW_021160909.1: 25964 bp; NW_021160910.1: 25580 bp; NW_021160911.1: 25781 bp; NW_021160912.1: 25922 bp; NW_021160913.1: 25754 bp; NW_021160914.1: 28282 bp; NW_021160915.1: 25683 bp; NW_021160916.1: 25784 bp; NW_021160917.1: 25136 bp; NW_021160918.1: 25729 bp; NW_021160919.1: 26063 bp; NW_021160920.1: 25859 bp; NW_021160921.1: 26245 bp; NW_021160922.1: 25256 bp; NW_021160923.1: 26161 bp; NW_021160924.1: 23900 bp; NW_021160925.1: 26085 bp; NW_021160926.1: 26170 bp; NW_021160927.1: 26384 bp; NW_021160928.1: 26179 bp; NW_021160929.1: 26234 bp; NW_021160930.1: 23724 bp; NW_021160931.1: 26222 bp; NW_021160932.1: 26478 bp; NW_021160933.1: 25881 bp; NW_021160934.1: 26337 bp; NW_021160935.1: 1093 bp; NW_021160936.1: 26449 bp; NW_021160937.1: 26160 bp; NW_021160938.1: 26233 bp; NW_021160939.1: 26290 bp; NW_021160940.1: 26453 bp; NW_021160941.1: 26293 bp; NW_021160942.1: 25203 bp; NW_021160943.1: 25985 bp; NW_021160944.1: 26378 bp; NW_021160945.1: 1174 bp; NW_021160946.1: 26473 bp; NW_021160947.1: 6749 bp; NW_021160948.1: 26181 bp; NW_021160949.1: 18127 bp; NW_021160950.1: 26491 bp; NW_021160951.1: 26514 bp; NW_021160952.1: 26228 bp; NW_021160953.1: 26770 bp; NW_021160954.1: 26252 bp; NW_021160955.1: 26547 bp; NW_021160956.1: 1709 bp; NW_021160957.1: 26692 bp; NW_021160958.1: 26789 bp; NW_021160959.1: 26116 bp; NW_021160960.1: 26680 bp; NW_021160961.1: 26760 bp; NW_021160962.1: 26653 bp; NW_021160963.1: 26895 bp; NW_021160964.1: 26806 bp; NW_021160965.1: 1742 bp; NW_021160966.1: 26776 bp; NW_021160967.1: 26713 bp; NW_021160968.1: 26834 bp; NW_021160969.1: 26502 bp; NW_021160970.1: 27252 bp; NW_021160971.1: 27150 bp; NW_021160972.1: 27461 bp; NW_021160973.1: 27101 bp; NW_021160974.1: 1759 bp; NW_021160975.1: 27350 bp; NW_021160976.1: 27218 bp; NW_021160977.1: 27092 bp; NW_021160978.1: 27325 bp; NW_021160979.1: 27550 bp; NW_021160980.1: 27495 bp; NW_021160981.1: 27521 bp; NW_021160982.1: 27688 bp; NW_021160983.1: 27276 bp; NW_021160984.1: 16890 bp; NW_021160985.1: 1889 bp; NW_021160986.1: 27335 bp; NW_021160987.1: 27365 bp; NW_021160988.1: 27619 bp; NW_021160989.1: 27683 bp; NW_021160990.1: 27613 bp; NW_021160991.1: 27810 bp; NW_021160992.1: 27862 bp; NW_021160993.1: 26903 bp; NW_021160994.1: 27684 bp; NW_021160995.1: 1920 bp; NW_021160996.1: 27923 bp; NW_021160997.1: 27858 bp; NW_021160998.1: 27833 bp; NW_021160999.1: 28037 bp; NW_021161000.1: 27132 bp; NW_021161001.1: 27602 bp; NW_021161002.1: 27737 bp; NW_021161003.1: 26674 bp; NW_021161004.1: 27424 bp; NW_021161005.1: 2024 bp; NW_021161006.1: 28016 bp; NW_021161007.1: 28393 bp; NW_021161008.1: 27967 bp; NW_021161009.1: 27987 bp; NW_021161010.1: 28119 bp; NW_021161011.1: 27986 bp; NW_021161012.1: 10683 bp; NW_021161013.1: 28141 bp; NW_021161014.1: 2116 bp; NW_021161015.1: 28192 bp; NW_021161016.1: 28508 bp; NW_021161017.1: 28332 bp; NW_021161018.1: 28406 bp; NW_021161019.1: 28581 bp; NW_021161020.1: 28580 bp; NW_021161021.1: 28433 bp; NW_021161022.1: 28450 bp; NW_021161023.1: 28652 bp; NW_021161024.1: 2140 bp; NW_021161025.1: 28569 bp; NW_021161026.1: 27892 bp; NW_021161027.1: 28448 bp; NW_021161028.1: 26340 bp; NW_021161029.1: 27694 bp; NW_021161030.1: 28839 bp; NW_021161031.1: 28577 bp; NW_021161032.1: 28691 bp; NW_021161033.1: 28671 bp; NW_021161034.1: 29285 bp; NW_021161035.1: 2185 bp; NW_021161036.1: 28620 bp; NW_021161037.1: 29085 bp; NW_021161038.1: 27067 bp; NW_021161039.1: 28995 bp; NW_021161040.1: 29066 bp; NW_021161041.1: 28505 bp; NW_021161042.1: 28932 bp; NW_021161043.1: 29161 bp; NW_021161044.1: 29213 bp; NW_021161045.1: 2297 bp; NW_021161046.1: 29506 bp; NW_021161047.1: 28852 bp; NW_021161048.1: 29266 bp; NW_021161049.1: 29345 bp; NW_021161050.1: 29502 bp; NW_021161051.1: 29162 bp; NW_021161052.1: 28803 bp; NW_021161053.1: 29577 bp; NW_021161054.1: 2340 bp; NW_021161055.1: 28699 bp; NW_021161056.1: 28212 bp; NW_021161057.1: 29435 bp; NW_021161058.1: 29528 bp; NW_021161059.1: 29771 bp; NW_021161060.1: 29657 bp; NW_021161061.1: 29093 bp; NW_021161062.1: 29624 bp; NW_021161063.1: 2365 bp; NW_021161064.1: 29586 bp; NW_021161065.1: 29740 bp; NW_021161066.1: 29837 bp; NW_021161067.1: 29752 bp; NW_021161068.1: 29118 bp; NW_021161069.1: 29675 bp; NW_021161070.1: 29750 bp; NW_021161071.1: 29300 bp; NW_021161072.1: 2516 bp; NW_021161073.1: 29295 bp; NW_021161074.1: 29596 bp; NW_021161075.1: 30231 bp; NW_021161076.1: 30239 bp; NW_021161077.1: 29849 bp; NW_021161078.1: 29588 bp; NW_021161079.1: 29540 bp; NW_021161080.1: 30244 bp; NW_021161081.1: 30172 bp; NW_021161082.1: 2556 bp; NW_021161083.1: 30191 bp; NW_021161084.1: 23050 bp; NW_021161085.1: 29650 bp; NW_021161086.1: 29876 bp; NW_021161087.1: 29002 bp; NW_021161088.1: 30329 bp; NW_021161089.1: 30313 bp; NW_021161090.1: 30398 bp; NW_021161091.1: 30596 bp; NW_021161092.1: 30232 bp; NW_021161093.1: 2672 bp; NW_021161094.1: 30602 bp; NW_021161095.1: 30619 bp; NW_021161096.1: 30316 bp; NW_021161097.1: 30446 bp; NW_021161098.1: 30375 bp; NW_021161099.1: 30665 bp; NW_021161100.1: 20885 bp; NW_021161101.1: 30158 bp; NW_021161102.1: 30428 bp; NW_021161103.1: 2665 bp; NW_021161104.1: 30646 bp; NW_021161105.1: 30676 bp; NW_021161106.1: 30650 bp; NW_021161107.1: 30769 bp; NW_021161108.1: 29982 bp; NW_021161109.1: 30863 bp; NW_021161110.1: 26259 bp; NW_021161111.1: 30828 bp; NW_021161112.1: 2664 bp; NW_021161113.1: 33726 bp; NW_021161114.1: 30849 bp; NW_021161115.1: 30830 bp; NW_021161116.1: 31047 bp; NW_021161117.1: 31119 bp; NW_021161118.1: 30971 bp; NW_021161119.1: 31084 bp; NW_021161120.1: 30924 bp; NW_021161121.1: 31149 bp; NW_021161122.1: 3089 bp; NW_021161123.1: 31014 bp; NW_021161124.1: 31240 bp; NW_021161125.1: 30712 bp; NW_021161126.1: 31675 bp; NW_021161127.1: 30445 bp; NW_021161128.1: 10913 bp; NW_021161129.1: 31249 bp; NW_021161130.1: 31194 bp; NW_021161131.1: 31251 bp; NW_021161132.1: 3070 bp; NW_021161133.1: 148587 bp; NW_021161134.1: 31182 bp; NW_021161135.1: 31244 bp; NW_021161136.1: 31235 bp; NW_021161137.1: 31345 bp; NW_021161138.1: 31194 bp; NW_021161139.1: 29939 bp; NW_021161140.1: 31452 bp; NW_021161141.1: 2769 bp; NW_021161142.1: 31505 bp; NW_021161143.1: 31449 bp; NW_021161144.1: 31568 bp; NW_021161145.1: 31635 bp; NW_021161146.1: 31814 bp; NW_021161147.1: 31685 bp; NW_021161148.1: 31679 bp; NW_021161149.1: 31632 bp; NW_021161150.1: 31566 bp; NW_021161151.1: 2774 bp; NW_021161152.1: 31470 bp; NW_021161153.1: 22131 bp; NW_021161154.1: 31995 bp; NW_021161155.1: 30560 bp; NW_021161156.1: 31680 bp; NW_021161157.1: 31836 bp; NW_021161158.1: 31109 bp; NW_021161159.1: 31865 bp; NW_021161160.1: 31969 bp; NW_021161161.1: 32018 bp; NW_021161162.1: 2823 bp; NW_021161163.1: 31643 bp; NW_021161164.1: 32320 bp; NW_021161165.1: 32021 bp; NW_021161166.1: 32498 bp; NW_021161167.1: 29258 bp; NW_021161168.1: 30211 bp; NW_021161169.1: 32394 bp; NW_021161170.1: 32431 bp; NW_021161171.1: 32084 bp; NW_021161172.1: 2946 bp; NW_021161173.1: 32241 bp; NW_021161174.1: 32333 bp; NW_021161175.1: 32630 bp; NW_021161176.1: 32442 bp; NW_021161177.1: 32337 bp; NW_021161178.1: 32508 bp; NW_021161179.1: 32583 bp; NW_021161180.1: 32752 bp; NW_021161181.1: 3001 bp; NW_021161182.1: 32327 bp; NW_021161183.1: 32827 bp; NW_021161184.1: 29553 bp; NW_021161185.1: 31154 bp; NW_021161186.1: 32711 bp; NW_021161187.1: 32581 bp; NW_021161188.1: 33098 bp; NW_021161189.1: 3087 bp; NW_021161190.1: 31402 bp; NW_021161191.1: 32784 bp; NW_021161192.1: 33169 bp; NW_021161193.1: 32226 bp; NW_021161194.1: 32999 bp; NW_021161195.1: 32095 bp; NW_021161196.1: 32911 bp; NW_021161197.1: 32817 bp; NW_021161198.1: 36478 bp; NW_021161199.1: 3090 bp; NW_021161200.1: 32957 bp; NW_021161201.1: 33207 bp; NW_021161202.1: 27618 bp; NW_021161203.1: 32805 bp; NW_021161204.1: 33471 bp; NW_021161205.1: 33381 bp; NW_021161206.1: 33308 bp; NW_021161207.1: 32271 bp; NW_021161208.1: 33068 bp; NW_021161209.1: 33103 bp; NW_021161210.1: 3229 bp; NW_021161211.1: 33367 bp; NW_021161212.1: 27683 bp; NW_021161213.1: 33280 bp; NW_021161214.1: 33565 bp; NW_021161215.1: 33721 bp; NW_021161216.1: 33292 bp; NW_021161217.1: 33492 bp; NW_021161218.1: 33710 bp; NW_021161219.1: 33619 bp; NW_021161220.1: 3323 bp; NW_021161221.1: 33830 bp; NW_021161222.1: 32314 bp; NW_021161223.1: 33841 bp; NW_021161224.1: 33706 bp; NW_021161225.1: 33898 bp; NW_021161226.1: 33332 bp; NW_021161227.1: 34094 bp; NW_021161228.1: 33819 bp; NW_021161229.1: 34168 bp; NW_021161230.1: 3399 bp; NW_021161231.1: 33951 bp; NW_021161232.1: 34141 bp; NW_021161233.1: 34057 bp; NW_021161234.1: 34006 bp; NW_021161235.1: 34160 bp; NW_021161236.1: 34150 bp; NW_021161237.1: 34015 bp; NW_021161238.1: 3431 bp; NW_021161239.1: 28232 bp; NW_021161240.1: 19516 bp; NW_021161241.1: 34288 bp; NW_021161242.1: 34412 bp; NW_021161243.1: 16967 bp; NW_021161244.1: 34349 bp; NW_021161245.1: 34479 bp; NW_021161246.1: 34127 bp; NW_021161247.1: 34283 bp; NW_021161248.1: 3447 bp; NW_021161249.1: 34585 bp; NW_021161250.1: 34871 bp; NW_021161251.1: 29805 bp; NW_021161252.1: 34538 bp; NW_021161253.1: 34660 bp; NW_021161254.1: 34617 bp; NW_021161255.1: 34693 bp; NW_021161256.1: 35151 bp; NW_021161257.1: 3450 bp; NW_021161258.1: 34885 bp; NW_021161259.1: 34818 bp; NW_021161260.1: 34807 bp; NW_021161261.1: 34955 bp; NW_021161262.1: 26739 bp; NW_021161263.1: 34834 bp; NW_021161264.1: 35035 bp; NW_021161265.1: 35110 bp; NW_021161266.1: 3533 bp; NW_021161267.1: 35291 bp; NW_021161268.1: 34918 bp; NW_021161269.1: 35097 bp; NW_021161270.1: 35404 bp; NW_021161271.1: 33189 bp; NW_021161272.1: 35294 bp; NW_021161273.1: 35291 bp; NW_021161274.1: 34572 bp; NW_021161275.1: 34411 bp; NW_021161276.1: 3585 bp; NW_021161277.1: 25771 bp; NW_021161278.1: 35292 bp; NW_021161279.1: 35203 bp; NW_021161280.1: 35750 bp; NW_021161281.1: 35378 bp; NW_021161282.1: 38876 bp; NW_021161283.1: 3589 bp; NW_021161284.1: 35176 bp; NW_021161285.1: 35515 bp; NW_021161286.1: 35235 bp; NW_021161287.1: 35335 bp; NW_021161288.1: 35635 bp; NW_021161289.1: 35602 bp; NW_021161290.1: 34408 bp; NW_021161291.1: 35380 bp; NW_021161292.1: 35701 bp; NW_021161293.1: 35740 bp; NW_021161294.1: 3595 bp; NW_021161295.1: 9582 bp; NW_021161296.1: 11407 bp; NW_021161297.1: 35986 bp; NW_021161298.1: 29605 bp; NW_021161299.1: 35760 bp; NW_021161300.1: 35753 bp; NW_021161301.1: 3650 bp; NW_021161302.1: 35969 bp; NW_021161303.1: 35997 bp; NW_021161304.1: 36013 bp; NW_021161305.1: 36069 bp; NW_021161306.1: 36367 bp; NW_021161307.1: 26542 bp; NW_021161308.1: 36176 bp; NW_021161309.1: 34402 bp; NW_021161310.1: 44556 bp; NW_021161311.1: 3634 bp; NW_021161312.1: 35760 bp; NW_021161313.1: 35409 bp; NW_021161314.1: 35675 bp; NW_021161315.1: 36526 bp; NW_021161316.1: 36418 bp; NW_021161317.1: 36440 bp; NW_021161318.1: 36579 bp; NW_021161319.1: 3709 bp; NW_021161320.1: 98231 bp; NW_021161321.1: 36597 bp; NW_021161322.1: 37236 bp; NW_021161323.1: 36173 bp; NW_021161324.1: 36316 bp; NW_021161325.1: 37073 bp; NW_021161326.1: 36766 bp; NW_021161327.1: 36362 bp; NW_021161328.1: 36429 bp; NW_021161329.1: 36545 bp; NW_021161330.1: 3692 bp; NW_021161331.1: 36583 bp; NW_021161332.1: 36888 bp; NW_021161333.1: 36950 bp; NW_021161334.1: 35341 bp; NW_021161335.1: 37320 bp; NW_021161336.1: 36865 bp; NW_021161337.1: 37193 bp; NW_021161338.1: 37189 bp; NW_021161339.1: 3805 bp; NW_021161340.1: 36764 bp; NW_021161341.1: 37346 bp; NW_021161342.1: 37230 bp; NW_021161343.1: 36196 bp; NW_021161344.1: 37366 bp; NW_021161345.1: 35631 bp; NW_021161346.1: 47321 bp; NW_021161347.1: 3833 bp; NW_021161348.1: 37440 bp; NW_021161349.1: 37329 bp; NW_021161350.1: 37752 bp; NW_021161351.1: 37806 bp; NW_021161352.1: 38016 bp; NW_021161353.1: 38028 bp; NW_021161354.1: 3873 bp; NW_021161355.1: 38638 bp; NW_021161356.1: 37427 bp; NW_021161357.1: 38191 bp; NW_021161358.1: 37704 bp; NW_021161359.1: 38049 bp; NW_021161360.1: 37458 bp; NW_021161361.1: 38047 bp; NW_021161362.1: 3881 bp; NW_021161363.1: 37735 bp; NW_021161364.1: 38187 bp; NW_021161365.1: 38056 bp; NW_021161366.1: 38306 bp; NW_021161367.1: 37918 bp; NW_021161368.1: 37394 bp; NW_021161369.1: 38662 bp; NW_021161370.1: 38559 bp; NW_021161371.1: 38474 bp; NW_021161372.1: 35154 bp; NW_021161373.1: 3934 bp; NW_021161374.1: 38182 bp; NW_021161375.1: 38884 bp; NW_021161376.1: 38735 bp; NW_021161377.1: 39759 bp; NW_021161378.1: 39073 bp; NW_021161379.1: 38290 bp; NW_021161380.1: 31828 bp; NW_021161381.1: 38782 bp; NW_021161382.1: 3884 bp; NW_021161383.1: 39158 bp; NW_021161384.1: 38903 bp; NW_021161385.1: 38848 bp; NW_021161386.1: 38542 bp; NW_021161387.1: 38548 bp; NW_021161388.1: 38282 bp; NW_021161389.1: 39048 bp; NW_021161390.1: 3875 bp; NW_021161391.1: 39067 bp; NW_021161392.1: 39117 bp; NW_021161393.1: 30983 bp; NW_021161394.1: 38831 bp; NW_021161395.1: 26330 bp; NW_021161396.1: 39087 bp; NW_021161397.1: 39340 bp; NW_021161398.1: 39151 bp; NW_021161399.1: 21923 bp; NW_021161400.1: 39574 bp; NW_021161401.1: 3946 bp; NW_021161402.1: 39385 bp; NW_021161403.1: 39402 bp; NW_021161404.1: 39426 bp; NW_021161405.1: 37001 bp; NW_021161406.1: 38736 bp; NW_021161407.1: 39387 bp; NW_021161408.1: 39210 bp; NW_021161409.1: 39234 bp; NW_021161410.1: 3963 bp; NW_021161411.1: 39932 bp; NW_021161412.1: 40128 bp; NW_021161413.1: 39609 bp; NW_021161414.1: 39873 bp; NW_021161415.1: 40174 bp; NW_021161416.1: 39862 bp; NW_021161417.1: 34563 bp; NW_021161418.1: 38938 bp; NW_021161419.1: 4048 bp; NW_021161420.1: 40061 bp; NW_021161421.1: 39789 bp; NW_021161422.1: 39585 bp; NW_021161423.1: 39520 bp; NW_021161424.1: 40176 bp; NW_021161425.1: 40208 bp; NW_021161426.1: 39940 bp; NW_021161427.1: 40094 bp; NW_021161428.1: 40087 bp; NW_021161429.1: 3883 bp; NW_021161430.1: 40567 bp; NW_021161431.1: 39948 bp; NW_021161432.1: 40518 bp; NW_021161433.1: 40453 bp; NW_021161434.1: 36536 bp; NW_021161435.1: 40658 bp; NW_021161436.1: 40483 bp; NW_021161437.1: 30042 bp; NW_021161438.1: 4139 bp; NW_021161439.1: 33894 bp; NW_021161440.1: 40786 bp; NW_021161441.1: 40543 bp; NW_021161442.1: 40627 bp; NW_021161443.1: 39583 bp; NW_021161444.1: 40692 bp; NW_021161445.1: 26899 bp; NW_021161446.1: 40916 bp; NW_021161447.1: 40298 bp; NW_021161448.1: 4164 bp; NW_021161449.1: 40942 bp; NW_021161450.1: 40479 bp; NW_021161451.1: 41042 bp; NW_021161452.1: 40959 bp; NW_021161453.1: 9741 bp; NW_021161454.1: 41550 bp; NW_021161455.1: 41437 bp; NW_021161456.1: 4243 bp; NW_021161457.1: 41440 bp; NW_021161458.1: 41772 bp; NW_021161459.1: 41493 bp; NW_021161460.1: 41105 bp; NW_021161461.1: 34683 bp; NW_021161462.1: 41848 bp; NW_021161463.1: 41719 bp; NW_021161464.1: 41089 bp; NW_021161465.1: 4202 bp; NW_021161466.1: 41995 bp; NW_021161467.1: 42125 bp; NW_021161468.1: 41952 bp; NW_021161469.1: 41934 bp; NW_021161470.1: 41925 bp; NW_021161471.1: 42119 bp; NW_021161472.1: 41902 bp; NW_021161473.1: 39756 bp; NW_021161474.1: 4224 bp; NW_021161475.1: 42192 bp; NW_021161476.1: 42068 bp; NW_021161477.1: 42128 bp; NW_021161478.1: 40456 bp; NW_021161479.1: 41682 bp; NW_021161480.1: 37589 bp; NW_021161481.1: 38097 bp; NW_021161482.1: 41982 bp; NW_021161483.1: 42297 bp; NW_021161484.1: 4251 bp; NW_021161485.1: 42753 bp; NW_021161486.1: 42563 bp; NW_021161487.1: 26672 bp; NW_021161488.1: 42584 bp; NW_021161489.1: 42423 bp; NW_021161490.1: 42397 bp; NW_021161491.1: 42686 bp; NW_021161492.1: 42959 bp; NW_021161493.1: 4501 bp; NW_021161494.1: 42825 bp; NW_021161495.1: 43060 bp; NW_021161496.1: 21449 bp; NW_021161497.1: 42928 bp; NW_021161498.1: 42859 bp; NW_021161499.1: 40936 bp; NW_021161500.1: 43031 bp; NW_021161501.1: 42764 bp; NW_021161502.1: 42580 bp; NW_021161503.1: 4313 bp; NW_021161504.1: 43165 bp; NW_021161505.1: 43094 bp; NW_021161506.1: 43524 bp; NW_021161507.1: 43286 bp; NW_021161508.1: 43154 bp; NW_021161509.1: 46500 bp; NW_021161510.1: 43218 bp; NW_021161511.1: 43245 bp; NW_021161512.1: 43598 bp; NW_021161513.1: 4222 bp; NW_021161514.1: 43609 bp; NW_021161515.1: 43438 bp; NW_021161516.1: 43058 bp; NW_021161517.1: 43864 bp; NW_021161518.1: 40988 bp; NW_021161519.1: 43859 bp; NW_021161520.1: 43096 bp; NW_021161521.1: 43807 bp; NW_021161522.1: 4269 bp; NW_021161523.1: 43265 bp; NW_021161524.1: 2568 bp; NW_021161525.1: 44027 bp; NW_021161526.1: 44050 bp; NW_021161527.1: 42522 bp; NW_021161528.1: 29635 bp; NW_021161529.1: 44101 bp; NW_021161530.1: 44677 bp; NW_021161531.1: 4330 bp; NW_021161532.1: 44461 bp; NW_021161533.1: 44400 bp; NW_021161534.1: 44667 bp; NW_021161535.1: 44654 bp; NW_021161536.1: 14354 bp; NW_021161537.1: 44355 bp; NW_021161538.1: 43892 bp; NW_021161539.1: 30137 bp; NW_021161540.1: 4355 bp; NW_021161541.1: 44404 bp; NW_021161542.1: 32853 bp; NW_021161543.1: 44877 bp; NW_021161544.1: 44708 bp; NW_021161545.1: 44679 bp; NW_021161546.1: 44763 bp; NW_021161547.1: 43550 bp; NW_021161548.1: 45352 bp; NW_021161549.1: 45063 bp; NW_021161550.1: 4358 bp; NW_021161551.1: 45330 bp; NW_021161552.1: 42520 bp; NW_021161553.1: 43959 bp; NW_021161554.1: 45154 bp; NW_021161555.1: 43189 bp; NW_021161556.1: 45149 bp; NW_021161557.1: 45099 bp; NW_021161558.1: 4377 bp; NW_021161559.1: 45244 bp; NW_021161560.1: 45284 bp; NW_021161561.1: 45186 bp; NW_021161562.1: 45469 bp; NW_021161563.1: 44154 bp; NW_021161564.1: 45838 bp; NW_021161565.1: 45680 bp; NW_021161566.1: 45489 bp; NW_021161567.1: 45527 bp; NW_021161568.1: 4374 bp; NW_021161569.1: 43996 bp; NW_021161570.1: 45239 bp; NW_021161571.1: 46055 bp; NW_021161572.1: 45960 bp; NW_021161573.1: 45687 bp; NW_021161574.1: 45412 bp; NW_021161575.1: 40193 bp; NW_021161576.1: 49015 bp; NW_021161577.1: 4475 bp; NW_021161578.1: 45110 bp; NW_021161579.1: 45508 bp; NW_021161580.1: 46004 bp; NW_021161581.1: 39228 bp; NW_021161582.1: 45938 bp; NW_021161583.1: 46010 bp; NW_021161584.1: 46184 bp; NW_021161585.1: 46085 bp; NW_021161586.1: 45774 bp; NW_021161587.1: 4480 bp; NW_021161588.1: 46008 bp; NW_021161589.1: 46075 bp; NW_021161590.1: 46009 bp; NW_021161591.1: 46688 bp; NW_021161592.1: 38862 bp; NW_021161593.1: 46534 bp; NW_021161594.1: 35042 bp; NW_021161595.1: 4431 bp; NW_021161596.1: 539197 bp; NW_021161597.1: 47231 bp; NW_021161598.1: 47063 bp; NW_021161599.1: 46287 bp; NW_021161600.1: 39567 bp; NW_021161601.1: 47033 bp; NW_021161602.1: 47147 bp; NW_021161603.1: 44389 bp; NW_021161604.1: 47142 bp; NW_021161605.1: 46923 bp; NW_021161606.1: 4596 bp; NW_021161607.1: 47411 bp; NW_021161608.1: 46701 bp; NW_021161609.1: 47051 bp; NW_021161610.1: 47444 bp; NW_021161611.1: 47145 bp; NW_021161612.1: 46632 bp; NW_021161613.1: 42281 bp; NW_021161614.1: 47714 bp; NW_021161615.1: 4608 bp; NW_021161616.1: 47847 bp; NW_021161617.1: 48070 bp; NW_021161618.1: 47755 bp; NW_021161619.1: 48494 bp; NW_021161620.1: 48615 bp; NW_021161621.1: 48521 bp; NW_021161622.1: 48804 bp; NW_021161623.1: 4673 bp; NW_021161624.1: 49091 bp; NW_021161625.1: 48530 bp; NW_021161626.1: 48636 bp; NW_021161627.1: 33435 bp; NW_021161628.1: 43903 bp; NW_021161629.1: 49110 bp; NW_021161630.1: 26718 bp; NW_021161631.1: 4337 bp; NW_021161632.1: 49124 bp; NW_021161633.1: 49414 bp; NW_021161634.1: 49314 bp; NW_021161635.1: 49922 bp; NW_021161636.1: 49563 bp; NW_021161637.1: 49614 bp; NW_021161638.1: 49110 bp; NW_021161639.1: 49166 bp; NW_021161640.1: 4730 bp; NW_021161641.1: 49520 bp; NW_021161642.1: 49762 bp; NW_021161643.1: 49803 bp; NW_021161644.1: 62222 bp; NW_021161645.1: 50266 bp; NW_021161646.1: 49124 bp; NW_021161647.1: 50194 bp; NW_021161648.1: 50883 bp; NW_021161649.1: 4723 bp; NW_021161650.1: 50831 bp; NW_021161651.1: 10288 bp; NW_021161652.1: 41816 bp; NW_021161653.1: 44881 bp; NW_021161654.1: 45730 bp; NW_021161655.1: 50775 bp; NW_021161656.1: 51111 bp; NW_021161657.1: 51037 bp; NW_021161658.1: 4699 bp; NW_021161659.1: 50478 bp; NW_021161660.1: 51084 bp; NW_021161661.1: 50976 bp; NW_021161662.1: 59403 bp; NW_021161663.1: 51632 bp; NW_021161664.1: 50849 bp; NW_021161665.1: 51707 bp; NW_021161666.1: 49477 bp; NW_021161667.1: 4712 bp; NW_021161668.1: 51783 bp; NW_021161669.1: 52522 bp; NW_021161670.1: 51033 bp; NW_021161671.1: 51112 bp; NW_021161672.1: 31199 bp; NW_021161673.1: 44211 bp; NW_021161674.1: 51763 bp; NW_021161675.1: 51622 bp; NW_021161676.1: 52031 bp; NW_021161677.1: 4766 bp; NW_021161678.1: 52118 bp; NW_021161679.1: 52134 bp; NW_021161680.1: 51744 bp; NW_021161681.1: 52729 bp; NW_021161682.1: 51837 bp; NW_021161683.1: 1018 bp; NW_021161684.1: 52580 bp; NW_021161685.1: 4704 bp; NW_021161686.1: 135290 bp; NW_021161687.1: 45969 bp; NW_021161688.1: 50457 bp; NW_021161689.1: 47658 bp; NW_021161690.1: 52203 bp; NW_021161691.1: 52711 bp; NW_021161692.1: 4547 bp; NW_021161693.1: 47714 bp; NW_021161694.1: 45495 bp; NW_021161695.1: 53446 bp; NW_021161696.1: 53040 bp; NW_021161697.1: 53093 bp; NW_021161698.1: 53497 bp; NW_021161699.1: 48354 bp; NW_021161700.1: 53044 bp; NW_021161701.1: 4878 bp; NW_021161702.1: 54180 bp; NW_021161703.1: 53929 bp; NW_021161704.1: 53872 bp; NW_021161705.1: 54532 bp; NW_021161706.1: 54126 bp; NW_021161707.1: 4877 bp; NW_021161708.1: 47114 bp; NW_021161709.1: 53780 bp; NW_021161710.1: 54744 bp; NW_021161711.1: 54195 bp; NW_021161712.1: 37542 bp; NW_021161713.1: 53877 bp; NW_021161714.1: 4723 bp; NW_021161715.1: 54401 bp; NW_021161716.1: 54367 bp; NW_021161717.1: 55247 bp; NW_021161718.1: 54484 bp; NW_021161719.1: 55700 bp; NW_021161720.1: 54552 bp; NW_021161721.1: 4719 bp; NW_021161722.1: 54602 bp; NW_021161723.1: 54674 bp; NW_021161724.1: 52427 bp; NW_021161725.1: 31465 bp; NW_021161726.1: 52192 bp; NW_021161727.1: 55233 bp; NW_021161728.1: 54854 bp; NW_021161729.1: 54620 bp; NW_021161730.1: 4946 bp; NW_021161731.1: 55277 bp; NW_021161732.1: 55415 bp; NW_021161733.1: 55095 bp; NW_021161734.1: 54470 bp; NW_021161735.1: 5068 bp; NW_021161736.1: 49857 bp; NW_021161737.1: 55851 bp; NW_021161738.1: 55757 bp; NW_021161739.1: 55173 bp; NW_021161740.1: 55893 bp; NW_021161741.1: 52219 bp; NW_021161742.1: 56129 bp; NW_021161743.1: 55989 bp; NW_021161744.1: 30053 bp; NW_021161745.1: 5123 bp; NW_021161746.1: 55043 bp; NW_021161747.1: 56409 bp; NW_021161748.1: 56714 bp; NW_021161749.1: 50308 bp; NW_021161750.1: 56871 bp; NW_021161751.1: 56351 bp; NW_021161752.1: 56384 bp; NW_021161753.1: 57122 bp; NW_021161754.1: 57191 bp; NW_021161755.1: 5087 bp; NW_021161756.1: 57072 bp; NW_021161757.1: 57265 bp; NW_021161758.1: 56732 bp; NW_021161759.1: 57462 bp; NW_021161760.1: 57537 bp; NW_021161761.1: 56718 bp; NW_021161762.1: 56155 bp; NW_021161763.1: 56865 bp; NW_021161764.1: 57887 bp; NW_021161765.1: 58172 bp; NW_021161766.1: 5170 bp; NW_021161767.1: 102105 bp; NW_021161768.1: 57736 bp; NW_021161769.1: 57982 bp; NW_021161770.1: 58133 bp; NW_021161771.1: 55163 bp; NW_021161772.1: 73921 bp; NW_021161773.1: 57948 bp; NW_021161774.1: 50837 bp; NW_021161775.1: 5084 bp; NW_021161776.1: 57200 bp; NW_021161777.1: 59182 bp; NW_021161778.1: 48415 bp; NW_021161779.1: 58989 bp; NW_021161780.1: 59303 bp; NW_021161781.1: 47153 bp; NW_021161782.1: 59255 bp; NW_021161783.1: 60006 bp; NW_021161784.1: 5148 bp; NW_021161785.1: 59951 bp; NW_021161786.1: 63720 bp; NW_021161787.1: 52097 bp; NW_021161788.1: 60135 bp; NW_021161789.1: 40932 bp; NW_021161790.1: 60347 bp; NW_021161791.1: 5943 bp; NW_021161792.1: 59372 bp; NW_021161793.1: 59771 bp; NW_021161794.1: 60438 bp; NW_021161795.1: 60299 bp; NW_021161796.1: 60409 bp; NW_021161797.1: 60511 bp; NW_021161798.1: 47075 bp; NW_021161799.1: 61336 bp; NW_021161800.1: 60346 bp; NW_021161801.1: 61203 bp; NW_021161802.1: 5153 bp; NW_021161803.1: 60988 bp; NW_021161804.1: 53906 bp; NW_021161805.1: 61029 bp; NW_021161806.1: 52973 bp; NW_021161807.1: 61605 bp; NW_021161808.1: 58515 bp; NW_021161809.1: 60438 bp; NW_021161810.1: 65300 bp; NW_021161811.1: 5218 bp; NW_021161812.1: 59696 bp; NW_021161813.1: 47549 bp; NW_021161814.1: 60637 bp; NW_021161815.1: 61255 bp; NW_021161816.1: 62361 bp; NW_021161817.1: 5298 bp; NW_021161818.1: 58033 bp; NW_021161819.1: 62604 bp; NW_021161820.1: 62830 bp; NW_021161821.1: 63471 bp; NW_021161822.1: 62933 bp; NW_021161823.1: 56837 bp; NW_021161824.1: 62468 bp; NW_021161825.1: 62914 bp; NW_021161826.1: 63798 bp; NW_021161827.1: 5264 bp; NW_021161828.1: 63453 bp; NW_021161829.1: 63548 bp; NW_021161830.1: 44750 bp; NW_021161831.1: 58143 bp; NW_021161832.1: 63400 bp; NW_021161833.1: 63920 bp; NW_021161834.1: 65517 bp; NW_021161835.1: 60971 bp; NW_021161836.1: 64312 bp; NW_021161837.1: 5182 bp; NW_021161838.1: 64097 bp; NW_021161839.1: 64033 bp; NW_021161840.1: 65250 bp; NW_021161841.1: 69994 bp; NW_021161842.1: 65234 bp; NW_021161843.1: 65139 bp; NW_021161844.1: 5292 bp; NW_021161845.1: 65395 bp; NW_021161846.1: 64569 bp; NW_021161847.1: 65260 bp; NW_021161848.1: 61482 bp; NW_021161849.1: 5288 bp; NW_021161850.1: 1117261 bp; NW_021161851.1: 65015 bp; NW_021161852.1: 66174 bp; NW_021161853.1: 65990 bp; NW_021161854.1: 66495 bp; NW_021161855.1: 66296 bp; NW_021161856.1: 65093 bp; NW_021161857.1: 66348 bp; NW_021161858.1: 66616 bp; NW_021161859.1: 65859 bp; NW_021161860.1: 5291 bp; NW_021161861.1: 65398 bp; NW_021161862.1: 66165 bp; NW_021161863.1: 66667 bp; NW_021161864.1: 66982 bp; NW_021161865.1: 67000 bp; NW_021161866.1: 66938 bp; NW_021161867.1: 66923 bp; NW_021161868.1: 66892 bp; NW_021161869.1: 5338 bp; NW_021161870.1: 67232 bp; NW_021161871.1: 44390 bp; NW_021161872.1: 66898 bp; NW_021161873.1: 66432 bp; NW_021161874.1: 66457 bp; NW_021161875.1: 67190 bp; NW_021161876.1: 68280 bp; NW_021161877.1: 57962 bp; NW_021161878.1: 67994 bp; NW_021161879.1: 67308 bp; NW_021161880.1: 5391 bp; NW_021161881.1: 60232 bp; NW_021161882.1: 98409 bp; NW_021161883.1: 68338 bp; NW_021161884.1: 67631 bp; NW_021161885.1: 69004 bp; NW_021161886.1: 68848 bp; NW_021161887.1: 68600 bp; NW_021161888.1: 69429 bp; NW_021161889.1: 5405 bp; NW_021161890.1: 68445 bp; NW_021161891.1: 69146 bp; NW_021161892.1: 74172 bp; NW_021161893.1: 85774 bp; NW_021161894.1: 69908 bp; NW_021161895.1: 69465 bp; NW_021161896.1: 70305 bp; NW_021161897.1: 69683 bp; NW_021161898.1: 5471 bp; NW_021161899.1: 66721 bp; NW_021161900.1: 70080 bp; NW_021161901.1: 70165 bp; NW_021161902.1: 64810 bp; NW_021161903.1: 71298 bp; NW_021161904.1: 70783 bp; NW_021161905.1: 5129 bp; NW_021161906.1: 66917 bp; NW_021161907.1: 70120 bp; NW_021161908.1: 72405 bp; NW_021161909.1: 71774 bp; NW_021161910.1: 71935 bp; NW_021161911.1: 72397 bp; NW_021161912.1: 72733 bp; NW_021161913.1: 72587 bp; NW_021161914.1: 72798 bp; NW_021161915.1: 5441 bp; NW_021161916.1: 73380 bp; NW_021161917.1: 72702 bp; NW_021161918.1: 73265 bp; NW_021161919.1: 72615 bp; NW_021161920.1: 73482 bp; NW_021161921.1: 73134 bp; NW_021161922.1: 71947 bp; NW_021161923.1: 5531 bp; NW_021161924.1: 73853 bp; NW_021161925.1: 40748 bp; NW_021161926.1: 74153 bp; NW_021161927.1: 74808 bp; NW_021161928.1: 74937 bp; NW_021161929.1: 74194 bp; NW_021161930.1: 74781 bp; NW_021161931.1: 75571 bp; NW_021161932.1: 5487 bp; NW_021161933.1: 74747 bp; NW_021161934.1: 75313 bp; NW_021161935.1: 75031 bp; NW_021161936.1: 90699 bp; NW_021161937.1: 75468 bp; NW_021161938.1: 75792 bp; NW_021161939.1: 75747 bp; NW_021161940.1: 75970 bp; NW_021161941.1: 4846 bp; NW_021161942.1: 29991 bp; NW_021161943.1: 76344 bp; NW_021161944.1: 75415 bp; NW_021161945.1: 76568 bp; NW_021161946.1: 75491 bp; NW_021161947.1: 60181 bp; NW_021161948.1: 5528 bp; NW_021161949.1: 77073 bp; NW_021161950.1: 77214 bp; NW_021161951.1: 37192 bp; NW_021161952.1: 76796 bp; NW_021161953.1: 77570 bp; NW_021161954.1: 77127 bp; NW_021161955.1: 77508 bp; NW_021161956.1: 76375 bp; NW_021161957.1: 78239 bp; NW_021161958.1: 78533 bp; NW_021161959.1: 2013 bp; NW_021161960.1: 75623 bp; NW_021161961.1: 78201 bp; NW_021161962.1: 79904 bp; NW_021161963.1: 74757 bp; NW_021161964.1: 79080 bp; NW_021161965.1: 79040 bp; NW_021161966.1: 79409 bp; NW_021161967.1: 5703 bp; NW_021161968.1: 79215 bp; NW_021161969.1: 79370 bp; NW_021161970.1: 80008 bp; NW_021161971.1: 67941 bp; NW_021161972.1: 80423 bp; NW_021161973.1: 78911 bp; NW_021161974.1: 80793 bp; NW_021161975.1: 80473 bp; NW_021161976.1: 5579 bp; NW_021161977.1: 81846 bp; NW_021161978.1: 81117 bp; NW_021161979.1: 81612 bp; NW_021161980.1: 57688 bp; NW_021161981.1: 75843 bp; NW_021161982.1: 87857 bp; NW_021161983.1: 85959 bp; NW_021161984.1: 5530 bp; NW_021161985.1: 82149 bp; NW_021161986.1: 82182 bp; NW_021161987.1: 82208 bp; NW_021161988.1: 78184 bp; NW_021161989.1: 77382 bp; NW_021161990.1: 82558 bp; NW_021161991.1: 83025 bp; NW_021161992.1: 5578 bp; NW_021161993.1: 84645 bp; NW_021161994.1: 84488 bp; NW_021161995.1: 85230 bp; NW_021161996.1: 85953 bp; NW_021161997.1: 84258 bp; NW_021161998.1: 79123 bp; NW_021161999.1: 5533 bp; NW_021162000.1: 85860 bp; NW_021162001.1: 84985 bp; NW_021162002.1: 80628 bp; NW_021162003.1: 75760 bp; NW_021162004.1: 28395 bp; NW_021162005.1: 86271 bp; NW_021162006.1: 86167 bp; NW_021162007.1: 87874 bp; NW_021162008.1: 4364 bp; NW_021162009.1: 87176 bp; NW_021162010.1: 87528 bp; NW_021162011.1: 87450 bp; NW_021162012.1: 27654 bp; NW_021162013.1: 88184 bp; NW_021162014.1: 88315 bp; NW_021162015.1: 85189 bp; NW_021162016.1: 89077 bp; NW_021162017.1: 88353 bp; NW_021162018.1: 580 bp; NW_021162019.1: 88765 bp; NW_021162020.1: 89116 bp; NW_021162021.1: 89317 bp; NW_021162022.1: 89300 bp; NW_021162023.1: 90089 bp; NW_021162024.1: 89536 bp; NW_021162025.1: 89157 bp; NW_021162026.1: 5576 bp; NW_021162027.1: 95384 bp; NW_021162028.1: 90559 bp; NW_021162029.1: 118794 bp; NW_021162030.1: 89611 bp; NW_021162031.1: 106339 bp; NW_021162032.1: 83177 bp; NW_021162033.1: 94579 bp; NW_021162034.1: 847 bp; NW_021162035.1: 93286 bp; NW_021162036.1: 87546 bp; NW_021162037.1: 90689 bp; NW_021162038.1: 93206 bp; NW_021162039.1: 92837 bp; NW_021162040.1: 80168 bp; NW_021162041.1: 79615 bp; NW_021162042.1: 93342 bp; NW_021162043.1: 1017 bp; NW_021162044.1: 95374 bp; NW_021162045.1: 78207 bp; NW_021162046.1: 95974 bp; NW_021162047.1: 95687 bp; NW_021162048.1: 21888 bp; NW_021162049.1: 96414 bp; NW_021162050.1: 96177 bp; NW_021162051.1: 98545 bp; NW_021162052.1: 95353 bp; NW_021162053.1: 5574 bp; NW_021162054.1: 95315 bp; NW_021162055.1: 99493 bp; NW_021162056.1: 94225 bp; NW_021162057.1: 126633 bp; NW_021162058.1: 98132 bp; NW_021162059.1: 98273 bp; NW_021162060.1: 98070 bp; NW_021162061.1: 97734 bp; NW_021162062.1: 87779 bp; NW_021162063.1: 98720 bp; NW_021162064.1: 483 bp; NW_021162065.1: 99708 bp; NW_021162066.1: 100704 bp; NW_021162067.1: 99617 bp; NW_021162068.1: 97056 bp; NW_021162069.1: 94142 bp; NW_021162070.1: 100199 bp; NW_021162071.1: 91746 bp; NW_021162072.1: 103309 bp; NW_021162073.1: 644 bp; NW_021162074.1: 104524 bp; NW_021162075.1: 95462 bp; NW_021162076.1: 105857 bp; NW_021162077.1: 105717 bp; NW_021162078.1: 106467 bp; NW_021162079.1: 93551 bp; NW_021162080.1: 100541 bp; NW_021162081.1: 104962 bp; NW_021162082.1: 5632 bp; NW_021162083.1: 172297 bp; NW_021162084.1: 103022 bp; NW_021162085.1: 107146 bp; NW_021162086.1: 110440 bp; NW_021162087.1: 110143 bp; NW_021162088.1: 110499 bp; NW_021162089.1: 112585 bp; NW_021162090.1: 108503 bp; NW_021162091.1: 113407 bp; NW_021162092.1: 113417 bp; NW_021162093.1: 972 bp; NW_021162094.1: 115593 bp; NW_021162095.1: 113870 bp; NW_021162096.1: 129808 bp; NW_021162097.1: 101318 bp; NW_021162098.1: 121393 bp; NW_021162099.1: 110265 bp; NW_021162100.1: 125694 bp; NW_021162101.1: 116383 bp; NW_021162102.1: 2150 bp; NW_021162103.1: 118746 bp; NW_021162104.1: 119205 bp; NW_021162105.1: 120347 bp; NW_021162106.1: 121230 bp; NW_021162107.1: 121050 bp; NW_021162108.1: 31873 bp; NW_021162109.1: 132044 bp; NW_021162110.1: 119602 bp; NW_021162111.1: 122551 bp; NW_021162112.1: 5895 bp; NW_021162113.1: 111075 bp; NW_021162114.1: 121705 bp; NW_021162115.1: 124221 bp; NW_021162116.1: 123539 bp; NW_021162117.1: 126295 bp; NW_021162118.1: 107979 bp; NW_021162119.1: 125189 bp; NW_021162120.1: 126266 bp; NW_021162121.1: 12279 bp; NW_021162122.1: 5643 bp; NW_021162123.1: 127007 bp; NW_021162124.1: 128435 bp; NW_021162125.1: 129037 bp; NW_021162126.1: 120669 bp; NW_021162127.1: 121549 bp; NW_021162128.1: 130415 bp; NW_021162129.1: 132187 bp; NW_021162130.1: 130461 bp; NW_021162131.1: 5698 bp; NW_021162132.1: 117379 bp; NW_021162133.1: 129961 bp; NW_021162134.1: 119943 bp; NW_021162135.1: 134417 bp; NW_021162136.1: 138879 bp; NW_021162137.1: 140412 bp; NW_021162138.1: 140114 bp; NW_021162139.1: 141557 bp; NW_021162140.1: 5680 bp; NW_021162141.1: 140493 bp; NW_021162142.1: 141499 bp; NW_021162143.1: 141344 bp; NW_021162144.1: 110746 bp; NW_021162145.1: 142752 bp; NW_021162146.1: 144953 bp; NW_021162147.1: 140509 bp; NW_021162148.1: 131735 bp; NW_021162149.1: 141005 bp; NW_021162150.1: 146108 bp; NW_021162151.1: 797 bp; NW_021162152.1: 151929 bp; NW_021162153.1: 153471 bp; NW_021162154.1: 156487 bp; NW_021162155.1: 150250 bp; NW_021162156.1: 153182 bp; NW_021162157.1: 60247 bp; NW_021162158.1: 155958 bp; NW_021162159.1: 157155 bp; NW_021162160.1: 165522 bp; NW_021162161.1: 10000 bp; NW_021162162.1: 2368 bp; NW_021162163.1: 163519 bp; NW_021162164.1: 170664 bp; NW_021162165.1: 165021 bp; NW_021162166.1: 172476 bp; NW_021162167.1: 172921 bp; NW_021162168.1: 173803 bp; NW_021162169.1: 167353 bp; NW_021162170.1: 179292 bp; NW_021162171.1: 2475 bp; NW_021162172.1: 105177 bp; NW_021162173.1: 176600 bp; NW_021162174.1: 183966 bp; NW_021162175.1: 4865 bp; NW_021162176.1: 211248 bp; NW_021162177.1: 183100 bp; NW_021162178.1: 155517 bp; NW_021162179.1: 193892 bp; NW_021162180.1: 5684 bp; NW_021162181.1: 194498 bp; NW_021162182.1: 202498 bp; NW_021162183.1: 191577 bp; NW_021162184.1: 207399 bp; NW_021162185.1: 8826 bp; NW_021162186.1: 211261 bp; NW_021162187.1: 9276 bp; NW_021162188.1: 203441 bp; NW_021162189.1: 215253 bp; NW_021162190.1: 214887 bp; NW_021162191.1: 1630 bp; NW_021162192.1: 217318 bp; NW_021162193.1: 217473 bp; NW_021162194.1: 223700 bp; NW_021162195.1: 170538 bp; NW_021162196.1: 219898 bp; NW_021162197.1: 334584 bp; NW_021162198.1: 22805 bp; NW_021162199.1: 219402 bp; NW_021162200.1: 227500 bp; NW_021162201.1: 421 bp; NW_021162202.1: 198660 bp; NW_021162203.1: 218262 bp; NW_021162204.1: 230069 bp; NW_021162205.1: 240218 bp; NW_021162206.1: 243659 bp; NW_021162207.1: 237673 bp; NW_021162208.1: 248972 bp; NW_021162209.1: 244704 bp; NW_021162210.1: 245458 bp; NW_021162211.1: 231522 bp; NW_021162212.1: 836 bp; NW_021162213.1: 245044 bp; NW_021162214.1: 260032 bp; NW_021162215.1: 272195 bp; NW_021162216.1: 263879 bp; NW_021162217.1: 266033 bp; NW_021162218.1: 247964 bp; NW_021162219.1: 257031 bp; NW_021162220.1: 250898 bp; NW_021162221.1: 262286 bp; NW_021162222.1: 37855 bp; NW_021162223.1: 1013 bp; NW_021162224.1: 285304 bp; NW_021162225.1: 276008 bp; NW_021162226.1: 43653 bp; NW_021162227.1: 290800 bp; NW_021162228.1: 270756 bp; NW_021162229.1: 289325 bp; NW_021162230.1: 325236 bp; NW_021162231.1: 306853 bp; NW_021162232.1: 310572 bp; NW_021162233.1: 406 bp; NW_021162234.1: 294751 bp; NW_021162235.1: 364843 bp; NW_021162236.1: 306510 bp; NW_021162237.1: 341167 bp; NW_021162238.1: 4290 bp; NW_021162239.1: 12050 bp; NW_021162240.1: 160179 bp; NW_021162241.1: 398213 bp; NW_021162242.1: 455 bp; NW_021162243.1: 484070 bp; NW_021162244.1: 9876 bp; NW_021162245.1: 9530 bp; NW_021162246.1: 105638 bp; NW_021162247.1: 41983 bp; NW_021162248.1: 15837 bp; NW_021162249.1: 5694 bp; NW_021162250.1: 17810 bp; NW_021162251.1: 71418 bp; NW_021162252.1: 7822 bp; NW_021162253.1: 31308 bp; NW_021162254.1: 677 bp; NW_021162255.1: 13302 bp; NW_021162256.1: 6908 bp; NW_021162257.1: 10037 bp; NW_021162258.1: 15233 bp; NW_021162259.1: 927 bp; NW_021162260.1: 1182 bp; NW_021162261.1: 93303 bp; NW_021162262.1: 19314 bp; NW_021162263.1: 26495 bp; NW_021162264.1: 19076 bp; NW_021162265.1: 38650 bp; NW_021162266.1: 21844 bp; NW_021162267.1: 1113 bp; NW_021162268.1: 19772 bp; NW_021162269.1: 23759 bp; NW_021162270.1: 20182 bp; NW_021162271.1: 20515 bp; NW_021162272.1: 21771 bp; NW_021162273.1: 9814 bp; NW_021162274.1: 101542 bp; NW_021162275.1: 965 bp; NW_021162276.1: 1177 bp; NW_021162277.1: 24873 bp; NW_021162278.1: 1181 bp; NW_021162279.1: 1808 bp; NW_021162280.1: 1878 bp; NW_021162281.1: 1111 bp; NW_021162282.1: 1186 bp; NW_021162283.1: 1475 bp; NW_021162284.1: 594 bp; NW_021162285.1: 1119 bp; NW_021162286.1: 1271 bp; NW_021162287.1: 1428 bp; NW_021162288.1: 1538 bp; NW_021162289.1: 1630 bp; NW_021162290.1: 1704 bp; NW_021162291.1: 1329 bp; NW_021162292.1: 1408 bp; NW_021162293.1: 217 bp; NW_021162294.1: 1000 bp; NW_021162295.1: 1694 bp; NW_021162296.1: 5841 bp; NW_021162297.1: 1992 bp; NW_021162298.1: 2122 bp; NW_021162299.1: 2137 bp; NW_021162300.1: 2163 bp; NW_021162301.1: 2380 bp; NW_021162302.1: 1572 bp; NW_021162303.1: 5727 bp; NW_021162304.1: 2556 bp; NW_021162305.1: 1747 bp; NW_021162306.1: 1722 bp; NW_021162307.1: 5781 bp; NW_021162308.1: 2673 bp; NW_021162309.1: 2703 bp; NW_021162310.1: 2713 bp; NW_021162311.1: 2709 bp; NW_021162312.1: 1750 bp; NW_021162313.1: 2710 bp; NW_021162314.1: 1849 bp; NW_021162315.1: 5778 bp; NW_021162316.1: 2805 bp; NW_021162317.1: 5617 bp; NW_021162318.1: 1917 bp; NW_021162319.1: 1985 bp; NW_021162320.1: 2082 bp; NW_021162321.1: 2669 bp; NW_021162322.1: 2826 bp; NW_021162323.1: 3329 bp; NW_021162324.1: 2279 bp; NW_021162325.1: 2988 bp; NW_021162326.1: 2173 bp; NW_021162327.1: 5808 bp; NW_021162328.1: 2277 bp; NW_021162329.1: 2320 bp; NW_021162330.1: 3040 bp; NW_021162331.1: 5815 bp; NW_021162332.1: 3004 bp; NW_021162333.1: 3086 bp; NW_021162334.1: 5735 bp; NW_021162335.1: 2500 bp; NW_021162336.1: 2523 bp; NW_021162337.1: 5694 bp; NW_021162338.1: 5860 bp; NW_021162339.1: 5597 bp; NW_021162340.1: 5916 bp; NW_021162341.1: 3105 bp; NW_021162342.1: 5861 bp; NW_021162343.1: 5967 bp; NW_021162344.1: 5894 bp; NW_021162345.1: 6003 bp; NW_021162346.1: 6035 bp; NW_021162347.1: 2647 bp; NW_021162348.1: 6161 bp; NW_021162349.1: 2839 bp; NW_021162350.1: 6105 bp; NW_021162351.1: 3161 bp; NW_021162352.1: 6030 bp; NW_021162353.1: 6126 bp; NW_021162354.1: 4454 bp; NW_021162355.1: 3147 bp; NW_021162356.1: 6186 bp; NW_021162357.1: 3169 bp; NW_021162358.1: 6258 bp; NW_021162359.1: 3265 bp; NW_021162360.1: 3150 bp; NW_021162361.1: 3342 bp; NW_021162362.1: 3293 bp; NW_021162363.1: 3439 bp; NW_021162364.1: 3576 bp; NW_021162365.1: 3862 bp; NW_021162366.1: 3367 bp; NW_021162367.1: 3292 bp; NW_021162368.1: 3378 bp; NW_021162369.1: 3299 bp; NW_021162370.1: 3914 bp; NW_021162371.1: 3537 bp; NW_021162372.1: 6283 bp; NW_021162373.1: 3918 bp; NW_021162374.1: 6242 bp; NW_021162375.1: 6340 bp; NW_021162376.1: 4046 bp; NW_021162377.1: 3402 bp; NW_021162378.1: 3572 bp; NW_021162379.1: 6392 bp; NW_021162380.1: 3723 bp; NW_021162381.1: 4085 bp; NW_021162382.1: 6395 bp; NW_021162383.1: 6339 bp; NW_021162384.1: 3835 bp; NW_021162385.1: 6404 bp; NW_021162386.1: 4048 bp; NW_021162387.1: 6386 bp; NW_021162388.1: 6324 bp; NW_021162389.1: 4165 bp; NW_021162390.1: 4242 bp; NW_021162391.1: 6443 bp; NW_021162392.1: 6559 bp; NW_021162393.1: 4331 bp; NW_021162394.1: 4150 bp; NW_021162395.1: 6707 bp; NW_021162396.1: 6700 bp; NW_021162397.1: 6630 bp; NW_021162398.1: 6713 bp; NW_021162399.1: 6656 bp; NW_021162400.1: 6571 bp; NW_021162401.1: 6673 bp; NW_021162402.1: 6799 bp; NW_021162403.1: 6726 bp; NW_021162404.1: 6897 bp; NW_021162405.1: 6880 bp; NW_021162406.1: 4596 bp; NW_021162407.1: 4580 bp; NW_021162408.1: 4678 bp; NW_021162409.1: 6897 bp; NW_021162410.1: 4355 bp; NW_021162411.1: 4726 bp; NW_021162412.1: 4729 bp; NW_021162413.1: 4248 bp; NW_021162414.1: 6823 bp; NW_021162415.1: 5107 bp; NW_021162416.1: 7005 bp; NW_021162417.1: 5103 bp; NW_021162418.1: 6999 bp; NW_021162419.1: 6987 bp; NW_021162420.1: 5178 bp; NW_021162421.1: 7071 bp; NW_021162422.1: 7140 bp; NW_021162423.1: 7152 bp; NW_021162424.1: 7232 bp; NW_021162425.1: 7165 bp; NW_021162426.1: 7161 bp; NW_021162427.1: 4610 bp; NW_021162428.1: 4932 bp; NW_021162429.1: 7250 bp; NW_021162430.1: 7254 bp; NW_021162431.1: 7273 bp; NW_021162432.1: 4913 bp; NW_021162433.1: 5010 bp; NW_021162434.1: 7303 bp; NW_021162435.1: 4960 bp; NW_021162436.1: 5208 bp; NW_021162437.1: 5086 bp; NW_021162438.1: 5068 bp; NW_021162439.1: 7387 bp; NW_021162440.1: 7283 bp; NW_021162441.1: 5231 bp; NW_021162442.1: 7459 bp; NW_021162443.1: 5201 bp; NW_021162444.1: 5299 bp; NW_021162445.1: 7461 bp; NW_021162446.1: 5234 bp; NW_021162447.1: 7511 bp; NW_021162448.1: 7454 bp; NW_021162449.1: 7480 bp; NW_021162450.1: 5024 bp; NW_021162451.1: 5481 bp; NW_021162452.1: 5507 bp; NW_021162453.1: 7387 bp; NW_021162454.1: 7581 bp; NW_021162455.1: 7483 bp; NW_021162456.1: 5352 bp; NW_021162457.1: 7524 bp; NW_021162458.1: 7580 bp; NW_021162459.1: 5531 bp; NW_021162460.1: 7521 bp; NW_021162461.1: 7551 bp; NW_021162462.1: 7578 bp; NW_021162463.1: 7549 bp; NW_021162464.1: 5554 bp; NW_021162465.1: 5725 bp; NW_021162466.1: 5643 bp; NW_021162467.1: 5596 bp; NW_021162468.1: 7393 bp; NW_021162469.1: 5819 bp; NW_021162470.1: 7519 bp; NW_021162471.1: 7607 bp; NW_021162472.1: 7455 bp; NW_021162473.1: 5546 bp; NW_021162474.1: 5953 bp; NW_021162475.1: 7249 bp; NW_021162476.1: 7739 bp; NW_021162477.1: 7748 bp; NW_021162478.1: 5894 bp; NW_021162479.1: 7571 bp; NW_021162480.1: 7777 bp; NW_021162481.1: 7855 bp; NW_021162482.1: 6082 bp; NW_021162483.1: 7804 bp; NW_021162484.1: 7797 bp; NW_021162485.1: 7762 bp; NW_021162486.1: 7814 bp; NW_021162487.1: 6229 bp; NW_021162488.1: 6482 bp; NW_021162489.1: 7823 bp; NW_021162490.1: 6227 bp; NW_021162491.1: 7834 bp; NW_021162492.1: 7866 bp; NW_021162493.1: 6381 bp; NW_021162494.1: 8009 bp; NW_021162495.1: 6588 bp; NW_021162496.1: 7991 bp; NW_021162497.1: 7948 bp; NW_021162498.1: 7909 bp; NW_021162499.1: 7946 bp; NW_021162500.1: 7933 bp; NW_021162501.1: 8127 bp; NW_021162502.1: 4641 bp; NW_021162503.1: 6648 bp; NW_021162504.1: 8064 bp; NW_021162505.1: 8066 bp; NW_021162506.1: 7982 bp; NW_021162507.1: 6114 bp; NW_021162508.1: 8070 bp; NW_021162509.1: 7978 bp; NW_021162510.1: 8083 bp; NW_021162511.1: 8100 bp; NW_021162512.1: 8132 bp; NW_021162513.1: 6701 bp; NW_021162514.1: 8162 bp; NW_021162515.1: 8158 bp; NW_021162516.1: 8171 bp; NW_021162517.1: 6826 bp; NW_021162518.1: 8247 bp; NW_021162519.1: 8222 bp; NW_021162520.1: 7083 bp; NW_021162521.1: 7185 bp; NW_021162522.1: 8268 bp; NW_021162523.1: 7053 bp; NW_021162524.1: 8214 bp; NW_021162525.1: 8288 bp; NW_021162526.1: 7224 bp; NW_021162527.1: 8324 bp; NW_021162528.1: 8237 bp; NW_021162529.1: 8324 bp; NW_021162530.1: 7305 bp; NW_021162531.1: 8426 bp; NW_021162532.1: 8356 bp; NW_021162533.1: 8416 bp; NW_021162534.1: 8470 bp; NW_021162535.1: 8395 bp; NW_021162536.1: 8472 bp; NW_021162537.1: 8470 bp; NW_021162538.1: 7384 bp; NW_021162539.1: 8491 bp; NW_021162540.1: 7431 bp; NW_021162541.1: 8526 bp; NW_021162542.1: 8633 bp; NW_021162543.1: 8576 bp; NW_021162544.1: 8543 bp; NW_021162545.1: 8642 bp; NW_021162546.1: 8382 bp; NW_021162547.1: 7502 bp; NW_021162548.1: 8575 bp; NW_021162549.1: 8646 bp; NW_021162550.1: 8619 bp; NW_021162551.1: 8743 bp; NW_021162552.1: 8627 bp; NW_021162553.1: 8662 bp; NW_021162554.1: 8246 bp; NW_021162555.1: 8736 bp; NW_021162556.1: 8693 bp; NW_021162557.1: 8650 bp; NW_021162558.1: 8751 bp; NW_021162559.1: 8781 bp; NW_021162560.1: 8512 bp; NW_021162561.1: 8759 bp; NW_021162562.1: 8846 bp; NW_021162563.1: 7768 bp; NW_021162564.1: 8882 bp; NW_021162565.1: 8736 bp; NW_021162566.1: 8616 bp; NW_021162567.1: 8908 bp; NW_021162568.1: 8912 bp; NW_021162569.1: 8902 bp; NW_021162570.1: 7779 bp; NW_021162571.1: 8932 bp; NW_021162572.1: 9005 bp; NW_021162573.1: 9067 bp; NW_021162574.1: 7951 bp; NW_021162575.1: 9083 bp; NW_021162576.1: 9102 bp; NW_021162577.1: 9091 bp; NW_021162578.1: 9083 bp; NW_021162579.1: 9114 bp; NW_021162580.1: 8112 bp; NW_021162581.1: 9107 bp; NW_021162582.1: 8635 bp; NW_021162583.1: 9243 bp; NW_021162584.1: 9225 bp; NW_021162585.1: 8174 bp; NW_021162586.1: 9265 bp; NW_021162587.1: 9274 bp; NW_021162588.1: 8300 bp; NW_021162589.1: 8393 bp; NW_021162590.1: 9211 bp; NW_021162591.1: 9214 bp; NW_021162592.1: 9247 bp; NW_021162593.1: 9297 bp; NW_021162594.1: 8515 bp; NW_021162595.1: 9411 bp; NW_021162596.1: 9361 bp; NW_021162597.1: 9375 bp; NW_021162598.1: 9314 bp; NW_021162599.1: 9375 bp; NW_021162600.1: 8629 bp; NW_021162601.1: 15085 bp; NW_021162602.1: 9511 bp; NW_021162603.1: 6628 bp; NW_021162604.1: 8620 bp; NW_021162605.1: 9450 bp; NW_021162606.1: 9328 bp; NW_021162607.1: 9373 bp; NW_021162608.1: 9462 bp; NW_021162609.1: 9568 bp; NW_021162610.1: 9422 bp; NW_021162611.1: 9085 bp; NW_021162612.1: 9612 bp; NW_021162613.1: 9516 bp; NW_021162614.1: 9842 bp; NW_021162615.1: 9640 bp; NW_021162616.1: 9518 bp; NW_021162617.1: 9669 bp; NW_021162618.1: 8874 bp; NW_021162619.1: 9671 bp; NW_021162620.1: 9721 bp; NW_021162621.1: 9770 bp; NW_021162622.1: 9801 bp; NW_021162623.1: 9694 bp; NW_021162624.1: 9745 bp; NW_021162625.1: 8920 bp; NW_021162626.1: 9820 bp; NW_021162627.1: 9806 bp; NW_021162628.1: 4263 bp; NW_021162629.1: 8779 bp; NW_021162630.1: 9863 bp; NW_021162631.1: 9807 bp; NW_021162632.1: 8623 bp; NW_021162633.1: 9868 bp; NW_021162634.1: 9151 bp; NW_021162635.1: 9955 bp; NW_021162636.1: 9924 bp; NW_021162637.1: 9838 bp; NW_021162638.1: 10004 bp; NW_021162639.1: 9955 bp; NW_021162640.1: 10003 bp; NW_021162641.1: 9999 bp; NW_021162642.1: 9921 bp; NW_021162643.1: 25415 bp; NW_021162644.1: 9991 bp; NW_021162645.1: 9924 bp; NW_021162646.1: 10073 bp; NW_021162647.1: 10228 bp; NW_021162648.1: 10058 bp; NW_021162649.1: 9940 bp; NW_021162650.1: 10204 bp; NW_021162651.1: 10111 bp; NW_021162652.1: 10182 bp; NW_021162653.1: 10313 bp; NW_021162654.1: 11492 bp; NW_021162655.1: 10100 bp; NW_021162656.1: 10334 bp; NW_021162657.1: 9439 bp; NW_021162658.1: 10406 bp; NW_021162659.1: 10221 bp; NW_021162660.1: 10498 bp; NW_021162661.1: 10400 bp; NW_021162662.1: 10024 bp; NW_021162663.1: 10268 bp; NW_021162664.1: 10381 bp; NW_021162665.1: 3153 bp; NW_021162666.1: 10367 bp; NW_021162667.1: 10346 bp; NW_021162668.1: 10300 bp; NW_021162669.1: 10178 bp; NW_021162670.1: 10400 bp; NW_021162671.1: 10505 bp; NW_021162672.1: 10468 bp; NW_021162673.1: 10600 bp; NW_021162674.1: 10579 bp; NW_021162675.1: 10646 bp; NW_021162676.1: 10686 bp; NW_021162677.1: 10682 bp; NW_021162678.1: 10737 bp; NW_021162679.1: 10629 bp; NW_021162680.1: 10838 bp; NW_021162681.1: 10719 bp; NW_021162682.1: 10694 bp; NW_021162683.1: 10866 bp; NW_021162684.1: 10710 bp; NW_021162685.1: 10782 bp; NW_021162686.1: 10247 bp; NW_021162687.1: 10847 bp; NW_021162688.1: 10707 bp; NW_021162689.1: 10888 bp; NW_021162690.1: 10899 bp; NW_021162691.1: 10903 bp; NW_021162692.1: 10977 bp; NW_021162693.1: 10943 bp; NW_021162694.1: 10982 bp; NW_021162695.1: 10633 bp; NW_021162696.1: 11007 bp; NW_021162697.1: 10304 bp; NW_021162698.1: 11099 bp; NW_021162699.1: 11107 bp; NW_021162700.1: 11039 bp; NW_021162701.1: 11251 bp; NW_021162702.1: 11004 bp; NW_021162703.1: 11059 bp; NW_021162704.1: 11138 bp; NW_021162705.1: 11275 bp; NW_021162706.1: 18798 bp; NW_021162707.1: 11251 bp; NW_021162708.1: 11159 bp; NW_021162709.1: 11295 bp; NW_021162710.1: 10713 bp; NW_021162711.1: 11243 bp; NW_021162712.1: 11336 bp; NW_021162713.1: 11295 bp; NW_021162714.1: 10843 bp; NW_021162715.1: 11444 bp; NW_021162716.1: 11408 bp; NW_021162717.1: 11390 bp; NW_021162718.1: 11451 bp; NW_021162719.1: 11342 bp; NW_021162720.1: 11412 bp; NW_021162721.1: 11436 bp; NW_021162722.1: 11385 bp; NW_021162723.1: 11568 bp; NW_021162724.1: 11543 bp; NW_021162725.1: 11379 bp; NW_021162726.1: 11498 bp; NW_021162727.1: 11708 bp; NW_021162728.1: 11336 bp; NW_021162729.1: 11621 bp; NW_021162730.1: 11709 bp; NW_021162731.1: 10966 bp; NW_021162732.1: 11620 bp; NW_021162733.1: 11669 bp; NW_021162734.1: 11610 bp; NW_021162735.1: 11454 bp; NW_021162736.1: 11653 bp; NW_021162737.1: 11716 bp; NW_021162738.1: 11745 bp; NW_021162739.1: 11272 bp; NW_021162740.1: 11688 bp; NW_021162741.1: 11680 bp; NW_021162742.1: 11212 bp; NW_021162743.1: 11720 bp; NW_021162744.1: 11426 bp; NW_021162745.1: 11081 bp; NW_021162746.1: 11763 bp; NW_021162747.1: 16742 bp; NW_021162748.1: 11772 bp; NW_021162749.1: 11950 bp; NW_021162750.1: 11503 bp; NW_021162751.1: 11680 bp; NW_021162752.1: 11848 bp; NW_021162753.1: 11928 bp; NW_021162754.1: 12083 bp; NW_021162755.1: 11991 bp; NW_021162756.1: 12067 bp; NW_021162757.1: 11874 bp; NW_021162758.1: 53119 bp; NW_021162759.1: 12136 bp; NW_021162760.1: 12131 bp; NW_021162761.1: 12066 bp; NW_021162762.1: 12222 bp; NW_021162763.1: 12318 bp; NW_021162764.1: 12183 bp; NW_021162765.1: 12257 bp; NW_021162766.1: 12260 bp; NW_021162767.1: 12309 bp; NW_021162768.1: 11586 bp; NW_021162769.1: 35003 bp; NW_021162770.1: 12334 bp; NW_021162771.1: 12248 bp; NW_021162772.1: 12310 bp; NW_021162773.1: 12294 bp; NW_021162774.1: 12204 bp; NW_021162775.1: 12206 bp; NW_021162776.1: 12314 bp; NW_021162777.1: 12386 bp; NW_021162778.1: 12344 bp; NW_021162779.1: 12101 bp; NW_021162780.1: 22552 bp; NW_021162781.1: 12382 bp; NW_021162782.1: 11940 bp; NW_021162783.1: 12042 bp; NW_021162784.1: 12187 bp; NW_021162785.1: 12533 bp; NW_021162786.1: 12614 bp; NW_021162787.1: 12558 bp; NW_021162788.1: 12524 bp; NW_021162789.1: 12451 bp; NW_021162790.1: 12577 bp; NW_021162791.1: 16440 bp; NW_021162792.1: 12603 bp; NW_021162793.1: 10722 bp; NW_021162794.1: 12730 bp; NW_021162795.1: 12735 bp; NW_021162796.1: 12617 bp; NW_021162797.1: 12605 bp; NW_021162798.1: 12700 bp; NW_021162799.1: 12656 bp; NW_021162800.1: 12782 bp; NW_021162801.1: 12738 bp; NW_021162802.1: 22949 bp; NW_021162803.1: 12656 bp; NW_021162804.1: 12593 bp; NW_021162805.1: 12864 bp; NW_021162806.1: 13007 bp; NW_021162807.1: 12702 bp; NW_021162808.1: 12589 bp; NW_021162809.1: 12649 bp; NW_021162810.1: 12804 bp; NW_021162811.1: 12690 bp; NW_021162812.1: 12815 bp; NW_021162813.1: 28396 bp; NW_021162814.1: 12398 bp; NW_021162815.1: 12743 bp; NW_021162816.1: 12714 bp; NW_021162817.1: 12730 bp; NW_021162818.1: 12883 bp; NW_021162819.1: 12752 bp; NW_021162820.1: 12459 bp; NW_021162821.1: 12714 bp; NW_021162822.1: 12857 bp; NW_021162823.1: 12934 bp; NW_021162824.1: 30612 bp; NW_021162825.1: 12987 bp; NW_021162826.1: 12519 bp; NW_021162827.1: 13025 bp; NW_021162828.1: 13122 bp; NW_021162829.1: 13000 bp; NW_021162830.1: 13136 bp; NW_021162831.1: 13048 bp; NW_021162832.1: 13128 bp; NW_021162833.1: 12996 bp; NW_021162834.1: 13132 bp; NW_021162835.1: 38403 bp; NW_021162836.1: 13199 bp; NW_021162837.1: 13158 bp; NW_021162838.1: 13172 bp; NW_021162839.1: 13291 bp; NW_021162840.1: 13314 bp; NW_021162841.1: 13236 bp; NW_021162842.1: 13272 bp; NW_021162843.1: 13331 bp; NW_021162844.1: 13318 bp; NW_021162845.1: 13362 bp; NW_021162846.1: 11310 bp; NW_021162847.1: 13438 bp; NW_021162848.1: 13399 bp; NW_021162849.1: 13338 bp; NW_021162850.1: 13254 bp; NW_021162851.1: 13051 bp; NW_021162852.1: 13388 bp; NW_021162853.1: 13470 bp; NW_021162854.1: 13489 bp; NW_021162855.1: 13617 bp; NW_021162856.1: 13537 bp; NW_021162857.1: 21541 bp; NW_021162858.1: 13465 bp; NW_021162859.1: 13580 bp; NW_021162860.1: 13567 bp; NW_021162861.1: 13681 bp; NW_021162862.1: 13579 bp; NW_021162863.1: 13572 bp; NW_021162864.1: 13688 bp; NW_021162865.1: 13552 bp; NW_021162866.1: 13585 bp; NW_021162867.1: 13614 bp; NW_021162868.1: 14947 bp; NW_021162869.1: 13577 bp; NW_021162870.1: 13370 bp; NW_021162871.1: 13883 bp; NW_021162872.1: 13774 bp; NW_021162873.1: 13859 bp; NW_021162874.1: 13872 bp; NW_021162875.1: 13134 bp; NW_021162876.1: 13732 bp; NW_021162877.1: 13929 bp; NW_021162878.1: 13801 bp; NW_021162879.1: 22858 bp; NW_021162880.1: 13902 bp; NW_021162881.1: 13861 bp; NW_021162882.1: 13953 bp; NW_021162883.1: 13998 bp; NW_021162884.1: 13888 bp; NW_021162885.1: 13803 bp; NW_021162886.1: 14014 bp; NW_021162887.1: 13991 bp; NW_021162888.1: 14204 bp; NW_021162889.1: 14295 bp; NW_021162890.1: 44378 bp; NW_021162891.1: 14056 bp; NW_021162892.1: 13917 bp; NW_021162893.1: 13939 bp; NW_021162894.1: 14104 bp; NW_021162895.1: 13238 bp; NW_021162896.1: 14209 bp; NW_021162897.1: 14220 bp; NW_021162898.1: 14211 bp; NW_021162899.1: 14304 bp; NW_021162900.1: 13549 bp; NW_021162901.1: 32155 bp; NW_021162902.1: 14220 bp; NW_021162903.1: 14158 bp; NW_021162904.1: 14272 bp; NW_021162905.1: 14321 bp; NW_021162906.1: 14317 bp; NW_021162907.1: 14433 bp; NW_021162908.1: 13953 bp; NW_021162909.1: 14498 bp; NW_021162910.1: 14325 bp; NW_021162911.1: 14328 bp; NW_021162912.1: 55060 bp; NW_021162913.1: 14389 bp; NW_021162914.1: 14413 bp; NW_021162915.1: 14460 bp; NW_021162916.1: 14549 bp; NW_021162917.1: 14368 bp; NW_021162918.1: 14509 bp; NW_021162919.1: 14702 bp; NW_021162920.1: 14508 bp; NW_021162921.1: 14393 bp; NW_021162922.1: 14602 bp; NW_021162923.1: 13704 bp; NW_021162924.1: 14195 bp; NW_021162925.1: 14594 bp; NW_021162926.1: 14544 bp; NW_021162927.1: 14591 bp; NW_021162928.1: 14671 bp; NW_021162929.1: 14570 bp; NW_021162930.1: 14577 bp; NW_021162931.1: 14690 bp; NW_021162932.1: 14648 bp; NW_021162933.1: 14727 bp; NW_021162934.1: 25116 bp; NW_021162935.1: 14639 bp; NW_021162936.1: 13671 bp; NW_021162937.1: 14564 bp; NW_021162938.1: 14580 bp; NW_021162939.1: 14794 bp; NW_021162940.1: 14810 bp; NW_021162941.1: 14798 bp; NW_021162942.1: 14675 bp; NW_021162943.1: 14848 bp; NW_021162944.1: 14717 bp; NW_021162945.1: 10281 bp; NW_021162946.1: 14243 bp; NW_021162947.1: 15014 bp; NW_021162948.1: 14871 bp; NW_021162949.1: 14993 bp; NW_021162950.1: 14950 bp; NW_021162951.1: 14818 bp; NW_021162952.1: 14866 bp; NW_021162953.1: 14986 bp; NW_021162954.1: 14931 bp; NW_021162955.1: 14882 bp; NW_021162956.1: 14945 bp; NW_021162957.1: 15028 bp; NW_021162958.1: 15180 bp; NW_021162959.1: 15060 bp; NW_021162960.1: 15321 bp; NW_021162961.1: 14722 bp; NW_021162962.1: 14720 bp; NW_021162963.1: 15258 bp; NW_021162964.1: 15563 bp; NW_021162965.1: 15316 bp; NW_021162966.1: 37796 bp; NW_021162967.1: 15318 bp; NW_021162968.1: 15330 bp; NW_021162969.1: 15517 bp; NW_021162970.1: 15589 bp; NW_021162971.1: 15588 bp; NW_021162972.1: 15338 bp; NW_021162973.1: 15529 bp; NW_021162974.1: 15700 bp; NW_021162975.1: 15590 bp; NW_021162976.1: 8909 bp; NW_021162977.1: 15493 bp; NW_021162978.1: 15549 bp; NW_021162979.1: 14868 bp; NW_021162980.1: 37717 bp; NW_021162981.1: 15306 bp; NW_021162982.1: 15859 bp; NW_021162983.1: 15679 bp; NW_021162984.1: 15846 bp; NW_021162985.1: 15570 bp; NW_021162986.1: 15710 bp; NW_021162987.1: 27507 bp; NW_021162988.1: 15776 bp; NW_021162989.1: 15726 bp; NW_021162990.1: 15964 bp; NW_021162991.1: 15790 bp; NW_021162992.1: 15927 bp; NW_021162993.1: 15944 bp; NW_021162994.1: 15879 bp; NW_021162995.1: 15880 bp; NW_021162996.1: 16121 bp; NW_021162997.1: 16080 bp; NW_021162998.1: 33825 bp; NW_021162999.1: 15822 bp; NW_021163000.1: 16025 bp; NW_021163001.1: 15997 bp; NW_021163002.1: 15858 bp; NW_021163003.1: 16094 bp; NW_021163004.1: 15959 bp; NW_021163005.1: 15799 bp; NW_021163006.1: 15823 bp; NW_021163007.1: 15985 bp; NW_021163008.1: 15913 bp; NW_021163009.1: 26049 bp; NC_005943.1: 16564 bp; \nNon-zero elements:  21,140,807\nMinimum (non zero): 3.59173195802721e-05\nMaximum:    0.06933028755391794\nNaN bins:   20943\n\n\n\n\n!hicMergeMatrixBins -m ../steps/SRR6502335_matrix.h5 -o SRR6502335_nb100 --numBins 100\n\n\n# Plot chr1 (NC_041755.1)\n\n!hicPlotMatrix -m SRR6502335_norm0_1_corrected.h5 -o SRR6502335_normcorrect_1.png --region NC_041755.1:0-105000000 --dpi 300\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: False\nINFO:hicexplorer.hicPlotMatrix:min: 3.59173195802721e-05, max: 0.06933028755391794\n\n\n\n\n!hicPlotMatrix -m SRR6502335_norm0_1_corrected.h5 -o SRR6502335_normcorrect_x.png --region NC_041774.1:0-105000000 --log1p --dpi 300\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: False\nINFO:hicexplorer.hicPlotMatrix:min: 3.59173195802721e-05, max: 0.06933028755391794",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#results-from-bowtie2---end-to-end",
    "href": "notebooks/01_hicexplorer.html#results-from-bowtie2---end-to-end",
    "title": "HiCExplorer using macaque data",
    "section": "Results from bowtie2 --end-to-end",
    "text": "Results from bowtie2 --end-to-end\nLet’s look at the summary logs for each of the samples\n\nfrom hicstuff import HiCQCLog, plot_pngs_in_grid\n\nSRR39 = HiCQCLog(\"../steps/bowtie2/end-to-end/SRR6502339_QC/QC.log\")\n\n\nimport os\nimport pandas as pd\nfrom IPython.display import display, HTML\n\n# Define the base directory\nbase_dir = \"../steps/bowtie2/end-to-end/\"\n\n# List of sample directories (subfolders named SRR6502335_QC, SRR6502336_QC, ...)\nsample_dirs = [f\"SRR65023{n}_QC\" for n in range(35, 40)]\n\n\n# List of images to compare\nimage_filenames = [\n    \"distance.png\",\n    \"pairs_discarded.png\",\n    \"pairs_sequenced.png\",\n    \"read_orientation.png\",\n    \"unmappable_and_non_unique.png\"\n]\n\n# Create an empty dictionary to hold the image paths for each sample\ndata = {sample: [] for sample in sample_dirs}\n\n# Iterate over each sample folder and populate the paths for each image type\nfor sample_dir in sample_dirs:\n    sample_path = os.path.join(base_dir, sample_dir)\n    for image_filename in image_filenames:\n        image_path = os.path.join(sample_path, image_filename)\n        if os.path.exists(image_path):\n            # Use HTML to display the image in a cell\n            img_tag = f'&lt;img src=\"{image_path}\" width=\"400\"/&gt;'\n            data[sample_dir].append(img_tag)\n        else:\n            data[sample_dir].append('Image not found')\n\n# Create a DataFrame from the collected data\ndf = pd.DataFrame(data, index=image_filenames)\n\n# Display the DataFrame as HTML in Jupyter notebook with images\ndisplay(HTML(df.to_html(escape=False)))\n\n\n\n\n\nSRR6502335_QC\nSRR6502336_QC\nSRR6502337_QC\nSRR6502338_QC\nSRR6502339_QC\n\n\n\n\ndistance.png\n\n\n\n\n\n\n\npairs_discarded.png\n\n\n\n\n\n\n\npairs_sequenced.png\n\n\n\n\n\n\n\nread_orientation.png\n\n\n\n\n\n\n\nunmappable_and_non_unique.png\n\n\n\n\n\n\n\n\n\n\n\n%%bash\n\n# Use hicQC to compare:\n\n(echo ../steps/bowtie2/end-to-end/*_QC/QC.log)\n\nhicQC --logfiles $(echo ../steps/bowtie2/end-to-end/*_QC/QC.log) --labels \"SRR35\" \"SRR36\" \"SRR37\" \"SRR38\" \"SRR39\" --outputFolder ../steps/bowtie2/end-to-end/QC_all_samples\n\n../steps/bowtie2/end-to-end/SRR6502335_QC/QC.log ../steps/bowtie2/end-to-end/SRR6502336_QC/QC.log ../steps/bowtie2/end-to-end/SRR6502337_QC/QC.log ../steps/bowtie2/end-to-end/SRR6502338_QC/QC.log ../steps/bowtie2/end-to-end/SRR6502339_QC/QC.log\n\n\n\nplot_pngs_in_grid(\"../steps/bowtie2/end-to-end/QC_all_samples/\", ncol=3)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#results-from-bowtie2---local",
    "href": "notebooks/01_hicexplorer.html#results-from-bowtie2---local",
    "title": "HiCExplorer using macaque data",
    "section": "Results from bowtie2 --local",
    "text": "Results from bowtie2 --local\n\n%%bash\n\n# Use hicQC to compare:\n\n(echo ../steps/bowtie2/*_QC/QC.log)\n\nhicQC --logfiles $(echo ../steps/bowtie2/local/*_QC/QC.log) --labels \"SRR35\" \"SRR36\" \"SRR37\" \"SRR38\" \"SRR39\" --outputFolder ../steps/bowtie2/local/QC_all_samples\n\n../steps/bowtie2/SRR6502335_QC/QC.log ../steps/bowtie2/SRR6502336_QC/QC.log ../steps/bowtie2/SRR6502337_QC/QC.log ../steps/bowtie2/SRR6502338_QC/QC.log ../steps/bowtie2/SRR6502339_QC/QC.log\n\n\n\nplot_pngs_in_grid(\"../steps/bowtie2/local/QC_all_samples/\")",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#comparing-qc-results-from-all-3-mappings",
    "href": "notebooks/01_hicexplorer.html#comparing-qc-results-from-all-3-mappings",
    "title": "HiCExplorer using macaque data",
    "section": "Comparing QC results from all 3 mappings",
    "text": "Comparing QC results from all 3 mappings\n\n\n\n\n\n\n\n\nFigure 3.1: Comparison of HiCExplorer QC plots for all samples using different alignment tools. The rows represent different QC plots (pairs sequenced, pairs discarded, unmappable/non-unique, distance, and read orientation), and the columns represent the 3 alignments used (BWA, Bowtie2 end-to-end, Bowtie2 local). Generated by hicQC.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#filter-the-unplaced-scaffolds-from-the-mapping",
    "href": "notebooks/01_hicexplorer.html#filter-the-unplaced-scaffolds-from-the-mapping",
    "title": "HiCExplorer using macaque data",
    "section": "Filter the unplaced scaffolds from the mapping",
    "text": "Filter the unplaced scaffolds from the mapping\n\n!zcat \"../data/links/ucsc_ref/rheMac10.fa.gz\" | grep \"&gt;\" | sed 's/&gt;//' &gt; all_chromosomes.txt\n\n\n!grep -v \"_\" all_chromosomes.txt | sort -V &gt; standard_chromosomes.txt\n\n\n!cat standard_chromosomes.txt | tr '\\n' ' ' &gt; chromosome_order.txt\n\n\n%%bash \n\nhicAdjustMatrix -m ../steps/bowtie2/local/SRR6502335.cool \\\n--outFileName filtered_SRR6502335.cool \\\n--chromosomes $(cat standard_chromosomes.txt | tr '\\n' ' ')\n\n\n# Check the reduction in size\n\n!du -ha ../steps/bowtie2/local/*35.cool -d1\n\n76M ../steps/bowtie2/local/filtered_SRR6502335.cool\n80M ../steps/bowtie2/local/SRR6502335.cool",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#try-to-plot-the-new-filtered-matrix",
    "href": "notebooks/01_hicexplorer.html#try-to-plot-the-new-filtered-matrix",
    "title": "HiCExplorer using macaque data",
    "section": "Try to plot the new filtered matrix",
    "text": "Try to plot the new filtered matrix\nFirst, check the info on the cooler\n\n!hicInfo -m ../steps/bowtie2/local/filtered_SRR6502335.cool\n\n# Matrix information file. Created with HiCExplorer's hicInfo version 3.7.5\nFile:   ../steps/bowtie2/local/filtered_SRR6502335.cool\nDate:   2024-09-24T12:08:51.357930\nGenome assembly:    unknown\nSize:   285,408\nBin_length: 10000\nChromosomes:length: chr1: 223616942 bp; chr2: 196197964 bp; chr3: 185288947 bp; chr4: 169963040 bp; chr5: 187317192 bp; chr6: 179085566 bp; chr7: 169868564 bp; chr8: 145679320 bp; chr9: 134124166 bp; chr10: 99517758 bp; chr11: 133066086 bp; chr12: 130043856 bp; chr13: 108737130 bp; chr14: 128056306 bp; chr15: 113283604 bp; chr16: 79627064 bp; chr17: 95433459 bp; chr18: 74474043 bp; chr19: 58315233 bp; chr20: 77137495 bp; chrM: 16564 bp; chrX: 153388924 bp; chrY: 11753682 bp; \nNumber of chromosomes:  23\nNon-zero elements:  36,751,866\nThe following columns are available: ['chrom' 'start' 'end']\n\n\nGenerated by:   HiCMatrix-17.2\nCooler library version: cooler-0.10.2\nHiCMatrix url:  https://github.com/deeptools/HiCMatrix\n\n\n\n\n# Apparently, something went wrong when creating the different binSizes with hicBuildMatrix, so we will create and merge them manually and may convert them into .mcool\n\n!hicMergeMatrixBins --help\n\nusage: hicMergeMatrixBins --matrix matrix.h5 --outFileName OUTFILENAME\n                          --numBins int [--runningWindow] [--help] [--version]\n\nMerges bins from a Hi-C matrix. For example, using a matrix containing 5kb\nbins, a matrix of 50kb bins can be derived using --numBins 10. From one type\nof downstream analysis to another, different bin sizes are used. For example\nto call TADs, unmerged matrices are recommended while to display Hi-C\nmatrices, bins of approximately 2000bp usually yield the best representations\nwith `hicPlotMatrix` for small regions, and even larger bins (50kb) are\nrecommended for whole chromosome representations or for `hicPlotDistVsCounts`.\n\nRequired arguments:\n  --matrix matrix.h5, -m matrix.h5\n                        Matrix to reduce in h5 format. (default: None)\n  --outFileName OUTFILENAME, -o OUTFILENAME\n                        File name to save the resulting matrix. The output is\n                        also a .h5 file. But don't add the suffix. (default:\n                        None)\n  --numBins int, -nb int\n                        Number of bins to merge. (default: None)\n\nOptional arguments:\n  --runningWindow       Set to merge for using a running window of length\n                        --numBins. (default: False)\n  --help, -h            Show this help message and exit.\n  --version             show program's version number and exit\n\n\n\nMerge bins from the raw matrix\n\n!hicMergeMatrixBins -m ../steps/bowtie2/local/matrices/SRR6502335.cool -o ../steps/bowtie2/local/matrices/SRR6502335_50kb.cool -nb 5\n\nWARNING:hicexplorer.hicMergeMatrixBins:*WARNING*: The matrix is probably a corrected matrix that contains NaN bins. This bins can not be merged and are removed. It is preferable to first merge bins in a uncorrected  matrix and then correct the matrix. Correction factors, if present, are removed as well.\n\n\n\n!hicMergeMatrixBins -m ../steps/bowtie2/local/matrices/SRR6502335.cool -o ../steps/bowtie2/local/matrices/SRR6502335_100kb.cool -nb 10\n\nWARNING:hicexplorer.hicMergeMatrixBins:*WARNING*: The matrix is probably a corrected matrix that contains NaN bins. This bins can not be merged and are removed. It is preferable to first merge bins in a uncorrected  matrix and then correct the matrix. Correction factors, if present, are removed as well.\n\n\n\n\nMerge bins from the filtered matrix\n\n!hicMergeMatrixBins -m ../steps/bowtie2/local/matrices/filtered_SRR6502335.cool -o ../steps/bowtie2/local/matrices/filtered_SRR6502335_50kb.cool -nb 5\n\n\n!hicInfo -m ../steps/bowtie2/local/matrices/filtered_SRR6502335_50kb.cool\n\n# Matrix information file. Created with HiCExplorer's hicInfo version 3.7.5\nFile:   ../steps/bowtie2/local/matrices/filtered_SRR6502335_50kb.cool\nDate:   2024-09-24T15:52:47.957236\nGenome assembly:    unknown\nSize:   56,325\nChromosomes:length: chr1: 223616942 bp; chr2: 196190000 bp; chr3: 185270000 bp; chr4: 169963040 bp; chr5: 187280000 bp; chr6: 179085566 bp; chr7: 169850000 bp; chr8: 145679320 bp; chr9: 134110000 bp; chr10: 99517758 bp; chr11: 133066086 bp; chr12: 130040000 bp; chr13: 108730000 bp; chr14: 128040000 bp; chr15: 113283604 bp; chr16: 79627064 bp; chr17: 95410000 bp; chr18: 74460000 bp; chr19: 58310000 bp; chr20: 77137495 bp; chrX: 153380000 bp; chrY: 11250000 bp; \nNumber of chromosomes:  22\nNon-zero elements:  24,159,441\nThe following columns are available: ['chrom' 'start' 'end']\n\n\nGenerated by:   HiCMatrix-17.2\nCooler library version: cooler-0.10.2\nHiCMatrix url:  https://github.com/deeptools/HiCMatrix\n\n\n\n\n!hicMergeMatrixBins -m ../steps/bowtie2/local/matrices/filtered_SRR6502335.cool -o ../steps/bowtie2/local/matrices/filtered_SRR6502335_100kb.cool -nb 10\n\nWARNING:hicexplorer.hicMergeMatrixBins:*WARNING*: The matrix is probably a corrected matrix that contains NaN bins. This bins can not be merged and are removed. It is preferable to first merge bins in a uncorrected  matrix and then correct the matrix. Correction factors, if present, are removed as well.\n\n\n\n\nCreate plots (each chromosome separately) and compare filtered vs unfiltered matrices\n\n%%bash \n\nfor CHR in $(cat standard_chromosomes.txt)\ndo \n    echo $CHR\n    hicPlotMatrix -m ../steps/bowtie2/local/matrices/SRR6502335_50kb.cool --chromosomeOrder $CHR -o ../figures/bowtie2/local/raw_50kb_$CHR.png --dpi 200\n    hicPlotMatrix -m ../steps/bowtie2/local/matrices/filtered_SRR6502335_50kb.cool --chromosomeOrder $CHR -o ../figures/bowtie2/local/raw_filter_50kb_$CHR.png --dpi 200\ndone\n\nchr1\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr2\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr3\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr4\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr5\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr6\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr7\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr8\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr9\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr10\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr11\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr12\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr13\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr14\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr15\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr16\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr17\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr18\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr19\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr20\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrX\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrY\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nimport os\nfrom natsort import natsorted\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image\n\n# Directory containing the PNG files\ndirectory = '../figures/bowtie2/local/'\n\n# List all raw_chr* files\nraw_files = [f for f in os.listdir(directory) if f.startswith('raw_50kb') and f.endswith('.png')]\n\n# List all raw_filter_chr* files\nraw_filter_files = [f for f in os.listdir(directory) if f.startswith('raw_filter_50kb') and f.endswith('.png')]\n\n# Sort files using natural sorting\nsorted_raw_files = natsorted(raw_files)\nsorted_raw_filter_files = natsorted(raw_filter_files)\n\npaired_files = list(zip(sorted_raw_files, sorted_raw_filter_files))\n\n# Plot the images side by side\nnum_pairs = len(paired_files)\nfig, axes = plt.subplots(num_pairs, 2, figsize=(15, 7 * num_pairs))\n\nfor i, (raw_file, raw_filter_file) in enumerate(paired_files):\n    # Plot raw image\n    raw_img_path = os.path.join(directory, raw_file)\n    raw_img = plt.imread(raw_img_path)\n    axes[i, 0].imshow(raw_img)\n    axes[i, 0].axis('off')\n    axes[i, 0].set_title(raw_file)\n\n    # Plot raw_filter image\n    raw_filter_img_path = os.path.join(directory, raw_filter_file)\n    raw_filter_img = plt.imread(raw_filter_img_path)\n    axes[i, 1].imshow(raw_filter_img)\n    axes[i, 1].axis('off')\n    axes[i, 1].set_title(raw_filter_file)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#pooled-samples",
    "href": "notebooks/01_hicexplorer.html#pooled-samples",
    "title": "HiCExplorer using macaque data",
    "section": "Pooled samples",
    "text": "Pooled samples\n\nPool the samples (matrices) into one big matrix\n\n%%bash\n\n# Check the sizes of the (unmodified, 10kb binned) matrices\nhicInfo -m ../steps/bowtie2/local/matrices/SRR650233{5..9}.cool \\\n    | grep -E \"File|Size\" \\\n    | awk '/File/ {print; next} /Size/ {print $0 \"\\n\"}'\n\nFile:   ../steps/bowtie2/local/matrices/SRR6502335.cool\nSize:   298,615\n\nFile:   ../steps/bowtie2/local/matrices/SRR6502336.cool\nSize:   298,615\n\nFile:   ../steps/bowtie2/local/matrices/SRR6502337.cool\nSize:   298,615\n\nFile:   ../steps/bowtie2/local/matrices/SRR6502338.cool\nSize:   298,615\n\nFile:   ../steps/bowtie2/local/matrices/SRR6502339.cool\nSize:   298,615\n\n\n\n\n!hicSumMatrices -m $(echo ../steps/bowtie2/local/matrices/SRR650233{5..9}.cool) -o ../steps/bowtie2/local/matrices/pooled_10kb.cool\n\n\n%%bash \n\nhicAdjustMatrix -m ../steps/bowtie2/local/matrices/pooled_10kb.cool \\\n    --outFileName filtered_pooled_10kb.cool \\\n    --chromosomes $(cat chromosome_order.txt)\n\n\n!hicInfo -m ../steps/bowtie2/local/matrices/pooled_10kb.cool | grep -E 'File|Size|Number|Non'\n!echo \"\"\n!hicInfo -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool | grep -E 'File|Size|Number|Non'\n\nFile:   ../steps/bowtie2/local/matrices/pooled_10kb.cool\nSize:   298,615\nNumber of chromosomes:  2939\nNon-zero elements:  117,537,653\n\nFile:   ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool\nSize:   285,406\nNumber of chromosomes:  22\nNon-zero elements:  117,090,191\n\n\n\n\nCreate different bin sizes (hicMergeMatrixBins)\n\n%%bash \n\n# This command requires ~14G available memory. \n# hicMergeMatrixBins -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool -o ../steps/bowtie2/local/matrices/filtered_pooled_40kb.cool -nb 4\n\n\n%%bash \n\nhicMergeMatrixBins \\\n    -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool \\\n    -o ../steps/bowtie2/local/matrices/filtered_pooled_50kb.cool \\\n    -nb 5 \n\nhicMergeMatrixBins \\\n    -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool \\\n    -o ../steps/bowtie2/local/matrices/filtered_pooled_100kb.cool \\\n    -nb 10\n\nWARNING:hicexplorer.hicMergeMatrixBins:*WARNING*: The matrix is probably a corrected matrix that contains NaN bins. This bins can not be merged and are removed. It is preferable to first merge bins in a uncorrected  matrix and then correct the matrix. Correction factors, if present, are removed as well.\nWARNING:hicexplorer.hicMergeMatrixBins:*WARNING*: The matrix is probably a corrected matrix that contains NaN bins. This bins can not be merged and are removed. It is preferable to first merge bins in a uncorrected  matrix and then correct the matrix. Correction factors, if present, are removed as well.\n\n\n\n%%bash\nhicInfo -m ../steps/bowtie2/local/matrices/filtered_pooled_{10,50,100}kb.cool \\\n    | grep -E 'File|Size|Number|Non' \\\n    | sed '/Non/a\\\\'\n\nFile:   ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool\nSize:   285,406\nNumber of chromosomes:  22\nNon-zero elements:  117,090,191\n\nFile:   ../steps/bowtie2/local/matrices/filtered_pooled_50kb.cool\nSize:   56,129\nNumber of chromosomes:  22\nNon-zero elements:  73,496,938\n\nFile:   ../steps/bowtie2/local/matrices/filtered_pooled_100kb.cool\nSize:   28,066\nNumber of chromosomes:  22\nNon-zero elements:  55,337,833\n\n\n\n\n\nPlot the chromosomes (seperately)\n\n%%bash \n\nfor CHR in $(cat standard_chromosomes.txt)\ndo \n    echo $CHR\n    hicPlotMatrix -m ../steps/bowtie2/local/matrices/filtered_pooled_50kb.cool \\\n    --chromosomeOrder $CHR \\\n    -o ../figures/bowtie2/local/filter_pooled_50kb_$CHR.png \\\n    --dpi 200 \\\n    --colorMap \"Reds\" \\\n    --log1p\ndone\n\nchr1\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr2\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr3\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr4\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr5\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr6\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr7\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr8\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr9\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr10\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr11\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr12\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr13\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr14\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr15\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr16\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr17\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr18\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr19\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr20\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrX\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrY\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/\", suffix=\"filter_pooled_50kb_*\", ncol=3)\n\n\n\n\n\n\n\n\n\n\nDiagnostic plot for raw sample\n\n%%bash \n\nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool -o ../figures/bowtie2/local/raw/diag_filter_pooled_10kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/filtered_pooled_40kb.cool -o ../figures/bowtie2/local/raw/diag_filter_pooled_40kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/filtered_pooled_50kb.cool -o ../figures/bowtie2/local/raw/diag_filter_pooled_50kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/filtered_pooled_100kb.cool -o ../figures/bowtie2/local/raw/diag_filter_pooled_100kb.png & \n\nwait",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#normalize-to-the-smallest-read-count-hicnormalize--n-smallest--sz-1.0",
    "href": "notebooks/01_hicexplorer.html#normalize-to-the-smallest-read-count-hicnormalize--n-smallest--sz-1.0",
    "title": "HiCExplorer using macaque data",
    "section": "Normalize to the smallest read count (hicNormalize -n smallest -sz 1.0)",
    "text": "Normalize to the smallest read count (hicNormalize -n smallest -sz 1.0)\n\n!hicNormalize --help\n\nusage: hicNormalize --matrices MATRICES [MATRICES ...] --normalize\n                    {norm_range,smallest,multiplicative} --outFileName\n                    FILENAME [FILENAME ...]\n                    [--multiplicativeValue MULTIPLICATIVEVALUE]\n                    [--setToZeroThreshold SETTOZEROTHRESHOLD] [--help]\n                    [--version]\n\nNormalizes given matrices either to the smallest given read number of all matrices or to 0 - 1 range. However, it does NOT compute the contact probability.\n\nWe recommend to compute first the normalization (with hicNormalize) and correct the data (with hicCorrectMatrix) in a second step.\n\nRequired arguments:\n  --matrices MATRICES [MATRICES ...], -m MATRICES [MATRICES ...]\n                        The matrix (or multiple matrices) to get information\n                        about. HiCExplorer supports the following file\n                        formats: h5 (native HiCExplorer format) and cool.\n  --normalize {norm_range,smallest,multiplicative}, -n {norm_range,smallest,multiplicative}\n                        Normalize to a) 0 to 1 range, b) all matrices to the\n                        lowest read count of the given matrices (Default:\n                        smallest).\n  --outFileName FILENAME [FILENAME ...], -o FILENAME [FILENAME ...]\n                        Output file name for the Hi-C matrix.\n\nOptional arguments:\n  --multiplicativeValue MULTIPLICATIVEVALUE, -mv MULTIPLICATIVEVALUE\n                        Value to multiply if --normalize is set to\n                        multiplicative. (Default: 1).\n  --setToZeroThreshold SETTOZEROTHRESHOLD, -sz SETTOZEROTHRESHOLD\n                        A threshold to set all values after normalization to 0\n                        if smaller this threshold. Default value is 0 i.e.\n                        there is no effect.It is recommended to set it for the\n                        normalize mode \"smallest\" to 1.0. This parameter will\n                        influence the sparsity of the matrix by removing many\n                        values close to 0 in smallest normalization mode.\n  --help, -h            show this help message and exit\n  --version             show program's version number and exit\n\n\n\n%%bash \n\n# Try to utilize more than one core (if they have been requested) by submitting lines in the background (with '&')\n\nhicNormalize -m ../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool  -o ../steps/bowtie2/local/matrices/normsm_filtered_pooled_10kb.cool -n smallest -sz 1.0 &\nhicNormalize -m ../steps/bowtie2/local/matrices/filtered_pooled_40kb.cool  -o ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb.cool -n smallest -sz 1.0 &\nhicNormalize -m ../steps/bowtie2/local/matrices/filtered_pooled_50kb.cool  -o ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb.cool -n smallest -sz 1.0 &\nhicNormalize -m ../steps/bowtie2/local/matrices/filtered_pooled_100kb.cool -o ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb.cool -n smallest -sz 1.0 &\n\nwait \n\n\n%%bash\n\nhicInfo -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_{10,40,50,100}kb.cool | grep -E 'File|Size|Number|Non' | sed '/Non/a\\\\'\n\nFile:   ../steps/bowtie2/local/matrices/normsm_filtered_pooled_10kb.cool\nSize:   285,406\nNumber of chromosomes:  22\nNon-zero elements:  117,090,191\n\nFile:   ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb.cool\nSize:   70,164\nNumber of chromosomes:  22\nNon-zero elements:  79,495,904\n\nFile:   ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb.cool\nSize:   56,129\nNumber of chromosomes:  22\nNon-zero elements:  73,496,938\n\nFile:   ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb.cool\nSize:   28,066\nNumber of chromosomes:  22\nNon-zero elements:  55,337,833\n\n\n\n\nPlot the normalized, pooled matrix\n\n%%bash\n\nfor CHR in $(cat standard_chromosomes.txt)\ndo \n    echo $CHR\n    hicPlotMatrix -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb.cool --chromosomeOrder $CHR -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_40kb_$CHR.png --dpi 200\n    #hicPlotMatrix -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb.cool --chromosomeOrder $CHR -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_50kb_$CHR.png --dpi 200\ndone\n\nchr1\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr2\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr3\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr4\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr5\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr6\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr7\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr8\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr9\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr10\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr11\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr12\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr13\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr14\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr15\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr16\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr17\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr18\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr19\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchr20\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrX\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\nchrY\n\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\n\nDiagnose and correct the normalized, pooled matrix\n\n%%bash \n\nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_10kb.cool -o ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_10kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb.cool  -o ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_40kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb.cool  -o ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_50kb.png & \nhicCorrectMatrix diagnostic_plot -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb.cool -o ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_100kb.png & \n\nwait\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 0 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -3.261957134177215\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_100kb.png\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 0 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -3.3912234086628996\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_50kb.png\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 0 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -3.3260620737327184\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_40kb.png\n\nINFO:hicexplorer.hicCorrectMatrix:Removing 4762 zero value bins\nINFO:hicexplorer.hicCorrectMatrix:mad threshold -2.7562685931558937\nINFO:hicexplorer.hicCorrectMatrix:Saving diagnostic plot ../figures/bowtie2/local/normalized/diag_normsm_filter_pooled_10kb.png\n\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\nplt(\"../figures/bowtie2/local/normalized\", suffix=\"diag*\", ncol=4)\n\nplt(\"../figures/bowtie2/local/raw\", suffix=\"diag*\", ncol=4)\n\nPlotting all images in '../figures/bowtie2/local/normalized/*diag*':\n\n\n\n\n\n\n\n\n\nPlotting all images in '../figures/bowtie2/local/raw/*diag*':\n\n\n\n\n\n\n\n\n\n\n!hicCorrectMatrix correct --help\n\nusage: hicCorrectMatrix correct --matrix hic_matrix.h5 --filterThreshold -1.2 5 (Only if ICE)-out corrected_matrix.h5 \n\noptions:\n  -h, --help            show this help message and exit\n\nRequired arguments:\n  --matrix MATRIX, -m MATRIX\n                        Name of the Hi-C matrix to correct in .h5 format.\n                        (default: None)\n  --outFileName OUTFILENAME, -o OUTFILENAME\n                        File name to save the resulting matrix. The output is\n                        a .h5 file. (default: None)\n\nOptional arguments:\n  --correctionMethod STR\n                        Method to be used for matrix correction. It can be set\n                        to KR or ICE (Default: KR).\n  --filterThreshold FILTERTHRESHOLD FILTERTHRESHOLD, -t FILTERTHRESHOLD FILTERTHRESHOLD\n                        Removes bins of low or large coverage. Usually these\n                        bins do not contain valid Hi-C data or represent\n                        regions that accumulate reads and thus must be\n                        discarded. Use hicCorrectMatrix diagnostic_plot to\n                        identify the modified z-value thresholds. A lower and\n                        upper threshold are required separated by space, e.g.\n                        --filterThreshold -1.5 5. Applied only for ICE!\n                        (default: None)\n  --iterNum INT, -n INT\n                        Number of iterations to compute.only for ICE!\n                        (Default: 500).\n  --inflationCutoff INFLATIONCUTOFF\n                        Value corresponding to the maximum number of times a\n                        bin can be scaled up during the iterative correction.\n                        For example, an inflation cutoff of 3 will filter out\n                        all bins that were expanded 3 times or more during the\n                        iterative correctionself.Only for ICE! (default: None)\n  --transCutoff TRANSCUTOFF, -transcut TRANSCUTOFF\n                        Clip high counts in the top -transcut trans regions\n                        (i.e. between chromosomes). A usual value is 0.05.\n                        Only for ICE! (default: None)\n  --sequencedCountCutoff SEQUENCEDCOUNTCUTOFF\n                        Each bin receives a value indicating the fraction that\n                        is covered by reads. A cutoff of 0.5 will discard all\n                        those bins that have less than half of the bin\n                        covered. Only for ICE! (default: None)\n  --chromosomes CHROMOSOMES [CHROMOSOMES ...]\n                        List of chromosomes to be included in the iterative\n                        correction. The order of the given chromosomes will be\n                        then kept for the resulting corrected matrix (default:\n                        None)\n  --skipDiagonal, -s    If set, diagonal counts are not included. Only for\n                        ICE! (default: False)\n  --perchr              Normalize each chromosome separately. This is useful\n                        for samples from cells with uneven number of\n                        chromosomes and/or translocations. (default: False)\n  --filteredBed FILTEREDBED\n                        Print bins filtered our by --filterThreshold to this\n                        file (default: None)\n  --verbose             Print processing status. (default: False)\n  --version             show program's version number and exit\n\n\n\n\nCorrecting the matrices\nIs memory-intensive, and was therefore run in a workflow. However, I don’t know if it went well. It spent waay less MEM than documentation suggests.\n\n\nPlotting the corrected matrices\n\n\nChromosome 1\n\n%%bash \n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_10kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_10kb_corrected_chr1-20-80Mb.png \\\n    --region chr1:20000000-80000000 --log1p &\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_10kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_10kb_corrected_chr1-50-60Mb.png \\\n    --region chr1:50000000-60000000 --log1p &\n\nwait\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\n%%bash\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_50kb_corrected_chr1.png \\\n    --region chr1 --log1p\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\n%%bash\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_100kb_corrected_chr1.png \\\n    --region chr1 --log1p\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized/\", suffix=\"corrected*.png\", ncol=2)\n\nPlotting all images in '../figures/bowtie2/local/normalized/*corrected*.png':\n\n\n\n\n\n\n\n\n\n\n\nChr12 (as in Wang2019)\n\n%%bash \n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_100kb_corrected_chr12-1-105Mb.png \\\n    --region chr12:1-105000000 --log1p \\\n    --colorMap \"Reds\" &\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_50kb_corrected_chr12-60-70Mb.png \\\n    --region chr12:60000000-70000000 --log1p \\\n    --colorMap \"Reds\" &\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_40kb_corrected_chr12-60-70Mb.png \\\n    --region chr12:60000000-70000000 --log1p \\\n    --colorMap \"Reds\" &\n\nwait\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized/\", suffix=\"corrected_chr12*.png\", ncol=3)\n\nPlotting all images in '../figures/bowtie2/local/normalized/*corrected_chr12*.png':\n\n\n\n\n\n\n\n\n\n\n\nChrX\n\n%%bash \n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_100kb_corrected_chrX-1-105Mb.png \\\n    -t 'ChrX: 100kb bins' \\\n    --region chrX:1-105000000 --log1p \\\n    --colorMap \"Reds\" &\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_50kb_corrected_chrX-60-70Mb.png \\\n    -t 'ChrX: 50kb bins' \\\n    --region chrX:60000000-70000000 --log1p \\\n    --colorMap \"Reds\" &\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_40kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_40kb_corrected_chrX-60-70Mb.png \\\n    -t 'ChrX: 40kb bins' \\\n    --region chrX:60000000-70000000 --log1p \\\n    --colorMap \"Reds\" &\n\nwait\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized/\", suffix=\"corrected_chrX*.png\", ncol=3)\n\nPlotting all images in '../figures/bowtie2/local/normalized/*corrected_chrX*.png':\n\n\n\n\n\n\n\n\n\n\n%%bash\n\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/normsm_filter_pooled_100kb_corrected_chrX-full.png \\\n    --chromosomeOrder chrX \\\n    --dpi 320 \\\n    --colorMap \"Reds\" \\\n    --log1p\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized/\", suffix=\"normsm*corrected_chrX*.png\", ncol=2)\n\n\n\n\n\n\n\n\n\n\nDist versus counts (P(s) in Wang2019?)\n\n!hicPlotDistVsCounts --help\n\nusage: hicPlotDistVsCounts --matrices MATRICES [MATRICES ...] --plotFile file\n                           name [--labels LABELS [LABELS ...]]\n                           [--skipDiagonal] [--maxdepth INT bp] [--perchr]\n                           [--chromosomeExclude CHROMOSOMEEXCLUDE [CHROMOSOMEEXCLUDE ...]]\n                           [--domains DOMAINS] [--outFileData OUTFILEDATA]\n                           [--plotsize PLOTSIZE PLOTSIZE] [--help] [--version]\n\nThis program creates distance vs. Hi-C counts plots. It can use several matrix\nfiles to compare them at once. If the `--perchr` option is given, each\nchromosome is plotted independently. When plotting multiple matrices, denser\nmatrices are scaled down to match the sum of the smallest matrix.\n\nRequired arguments:\n  --matrices MATRICES [MATRICES ...], -m MATRICES [MATRICES ...]\n                        Hi-C normalized (corrected) matrices. Each path should\n                        be separated by a space.\n  --plotFile file name, -o file name\n                        File name to save the file. The given file ending will\n                        be used to determine the image format. The available\n                        options are: .png, .emf, .eps, .pdf and .svg.\n\nOptional arguments:\n  --labels LABELS [LABELS ...]\n                        Label to assign to each matrix file. Each label should\n                        be separated by a space. Quote labels that contain\n                        spaces: E.g. --labels label1 \"labels 2\". If no labels\n                        are given then the file name is used.\n  --skipDiagonal, -s    If set, diagonal counts are not included.\n  --maxdepth INT bp     Maximum distance from diagonal to use. In other words,\n                        distances up to maxDepth are computed. Default is 3\n                        million bp.\n  --perchr              If given, computes and display distance versus Hi-C\n                        counts plots for each chromosome stored in the\n                        matrices passed to --matrices.\n  --chromosomeExclude CHROMOSOMEEXCLUDE [CHROMOSOMEEXCLUDE ...]\n                        Exclude the given list of chromosomes. This is useful\n                        for example to exclude the Y chromosome. The names of\n                        the chromosomes should be separated by space.\n  --domains DOMAINS     Bed file with domains coordinates: instead of\n                        evaluating the distance vs. Hi-C counts for intra\n                        chromosomal counts, compute it for intra-domains.\n  --outFileData OUTFILEDATA\n                        If given, the data underlying the plots is saved on\n                        this file.\n  --plotsize PLOTSIZE PLOTSIZE\n                        Width and height of the plot (in inches). Default is\n                        6*number of cols, 4 * number of rows. The maximum\n                        number of rows is 4. Example: --plotsize 6 5\n  --help, -h            show this help message and exit\n  --version             show program's version number and exit\n\n\n\n%%bash \n\nhicPlotDistVsCounts \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/distvscounts_100kb_corrected_chr.png \\\n    --perchr \\\n    --labels 'Pooled' \\\n    --plotsize 6 4 &\n\nhicPlotDistVsCounts \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/distvscounts_100kb_corrected_all.png \\\n    --labels 'Pooled' \\\n    --plotsize 6 4 &\n\nwait\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome all\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr1\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr2\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr3\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 47, diagonal len: 1791\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr4\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr5\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr6\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 49, diagonal len: 1724\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 50, diagonal len: 1723\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr7\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr8\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr9\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 48, diagonal len: 1265\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 49, diagonal len: 1264\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 50, diagonal len: 1263\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 51, diagonal len: 1262\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 52, diagonal len: 1261\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 53, diagonal len: 1260\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 54, diagonal len: 1259\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 55, diagonal len: 1258\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 56, diagonal len: 1257\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 57, diagonal len: 1256\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 58, diagonal len: 1255\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 59, diagonal len: 1254\n\nINFO:hicexplorer.hicPlotDistVsCounts:skipping rest of chromosome chr9. Too many emtpy diagonals\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr10\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 48, diagonal len: 908\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 49, diagonal len: 907\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 50, diagonal len: 906\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 51, diagonal len: 905\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 52, diagonal len: 904\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 53, diagonal len: 903\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 54, diagonal len: 902\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 55, diagonal len: 901\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 56, diagonal len: 900\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 57, diagonal len: 899\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 58, diagonal len: 898\n\nINFO:hicexplorer.hicPlotDistVsCounts:zero value for 59, diagonal len: 897\n\nINFO:hicexplorer.hicPlotDistVsCounts:skipping rest of chromosome chr10. Too many emtpy diagonals\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr11\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr12\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr13\n\nINFO:hicexplorer.hicPlotDistVsCounts:The scale factors used are: {'../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool': 1.0}\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr14\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr15\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr16\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr17\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr18\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr19\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chr20\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chrX\n\nINFO:hicexplorer.hicPlotDistVsCounts:processing chromosome chrY\n\nINFO:hicexplorer.hicPlotDistVsCounts:The scale factors used are: {'../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool': 1.0}\n\n\n\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized/\", suffix=\"distvscounts*.png\", ncol=2)\n\nPlotting all images in '../figures/bowtie2/local/normalized/*distvscounts*.png':",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/01_hicexplorer.html#chromatin-compartments",
    "href": "notebooks/01_hicexplorer.html#chromatin-compartments",
    "title": "HiCExplorer using macaque data",
    "section": "Chromatin Compartments",
    "text": "Chromatin Compartments\n\nHiCExplorer\n\n!hicPCA --help\n\nusage: hicPCA --matrix MATRIX --outputFileName OUTPUTFILENAME\n              [OUTPUTFILENAME ...]\n              [--whichEigenvectors WHICHEIGENVECTORS [WHICHEIGENVECTORS ...]]\n              [--format {bedgraph,bigwig}]\n              [--chromosomes CHROMOSOMES [CHROMOSOMES ...]]\n              [--method {dist_norm,lieberman}] [--ligation_factor]\n              [--extraTrack EXTRATRACK] [--histonMarkType HISTONMARKTYPE]\n              [--pearsonMatrix PEARSONMATRIX] [--obsexpMatrix OBSEXPMATRIX]\n              [--ignoreMaskedBins] [--help] [--version]\n\nComputes PCA eigenvectors for a Hi-C matrix.\n\n    $ hicPCA --matrix hic_matrix.h5 -o pca1.bedgraph pca2.bedgraph\n\nRequired arguments:\n  --matrix MATRIX, -m MATRIX\n                        HiCExplorer matrix in h5 format. (default: None)\n  --outputFileName OUTPUTFILENAME [OUTPUTFILENAME ...], -o OUTPUTFILENAME [OUTPUTFILENAME ...]\n                        File names for the result of the pca.Number of output\n                        files must match the number of computed eigenvectors.\n                        (default: None)\n\nOptional arguments:\n  --whichEigenvectors WHICHEIGENVECTORS [WHICHEIGENVECTORS ...], -we WHICHEIGENVECTORS [WHICHEIGENVECTORS ...]\n                        The list of eigenvectors that the PCA should compute\n                        e.g. 1 2 5 will return the first, second and fifth\n                        eigenvector. (Default: 1 2).\n  --format {bedgraph,bigwig}, -f {bedgraph,bigwig}\n                        Output format. Either bedgraph or bigwig (Default:\n                        bigwig).\n  --chromosomes CHROMOSOMES [CHROMOSOMES ...]\n                        List of chromosomes to be included in the correlation.\n                        (default: None)\n  --method {dist_norm,lieberman}\n                        possible methods which can be used to build the obs-\n                        exp matrix are dist_norm and lieberman (Default:\n                        dist_norm).\n  --ligation_factor     Setting this flag multiplies a scaling factor to each\n                        entry of the expected matrix to take care of the\n                        proximity ligation as has been explained in Homer\n                        software. This flag is only affective with dist_norm\n                        method and will be ignored if lieberman method is\n                        chosen. (default: False)\n  --extraTrack EXTRATRACK\n                        Either a gene track or a histone mark coverage file\n                        (preferably a broad mark) is needed to decide if the\n                        values of the eigenvector need a sign flip or not.\n                        Please consider: bed files are interpreted as gene\n                        tracks and bigwig files as histone marks. (default:\n                        None)\n  --histonMarkType HISTONMARKTYPE\n                        Set it to active or inactive. This is only necessary\n                        if a histon mark coverage file is given as an\n                        extraTrack (Default: active).\n  --pearsonMatrix PEARSONMATRIX, -pm PEARSONMATRIX\n                        Internally the input matrix is converted per\n                        chromosome to obs_exp matrix and consecutively to a\n                        Pearson matrix. Set this parameter to write the\n                        pearson matrix to a file. (default: None)\n  --obsexpMatrix OBSEXPMATRIX, -oem OBSEXPMATRIX\n                        Internally the input matrix is converted per\n                        chromosome to obs_exp matrix and consecutively to a\n                        Pearson matrix. Set this parameter to write the\n                        observe/expected matrix to a file. (default: None)\n  --ignoreMaskedBins    Mask bins are usually set to 0. This option removes\n                        the masked bins before the PCA is computed. Attention:\n                        this will lead to empty PCA regions. (default: False)\n  --help, -h            show the help message and exit\n  --version             show program's version number and exit\n\n\n\n%%bash\n\nhicPCA \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/pc{1,2,3}_100kb_corrected_chrX.bigwig \\\n    --chromosomes chrX \\\n    -we 1 2 3 &\n\nhicPCA \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/pc{1,2,3}_50kb_corrected_chrX.bigwig \\\n    --chromosomes chrX \\\n    -we 1 2 3 &\n\nwait\n\n\n%%bash \n\nfor NUM in 1 2 3; do\nhicPlotMatrix \\\n    -m ../steps/bowtie2/local/matrices/normsm_filtered_pooled_50kb_corrected.cool \\\n    -o ../figures/bowtie2/local/normalized/pc${NUM}_50kb_corrected_chrX.png \\\n    --bigwig ../figures/bowtie2/local/normalized/pc${NUM}_50kb_corrected_chrX.bigwig \\\n    --region chrX \\\n    -t \"ChrX:50kb bins: PC${NUM}\" \\\n    --log1p \\\n    --colorMap \"Reds\" \\\n    --dpi 100 &\ndone\n\nwait\n\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\nINFO:hicexplorer.hicPlotMatrix:Cooler or no cooler: True\n\n\n\nimport hicstuff\nimport importlib\nimportlib.reload(hicstuff)\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized\", suffix=\"pc*50kb*chrX.png\", ncol=3)\n\n\n\n\n\nThe X chromosome in 50kb bins and the first 3 PCs below. Made with HicExplorer.\n\n\n\n\n\nimport hicstuff\nimport importlib\nimportlib.reload(hicstuff)\nfrom hicstuff import plot_pngs_in_grid as plt\n\nplt(\"../figures/bowtie2/local/normalized\", suffix=\"pc*100kb*chrX.png\", ncol=3)\n\n\n\n\n\nThe X chromosome in 100kb bins and the first 3 PCs below. Made with HicExplorer.\n\n\n\n\n\n\nmatplotlib\n\n[f\"../figures/bowtie2/local/normalized/pc{NUM}_50kb_corrected_chrX.bigwig\" for NUM in range(1,4)]\n\n['../figures/bowtie2/local/normalized/pc1_50kb_corrected_chrX.bigwig',\n '../figures/bowtie2/local/normalized/pc2_50kb_corrected_chrX.bigwig',\n '../figures/bowtie2/local/normalized/pc3_50kb_corrected_chrX.bigwig']\n\n\n\nimport h5py\nimport pyBigWig\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load Hi-C matrix from .cool file\ncool_file = '../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool'\nf = h5py.File(cool_file, 'r')\n\n\nfor key in list(f.keys()):\n    print(f\"{key}: {list(f[key])}\")\n\nbins: ['chrom', 'end', 'start', 'weight']\nchroms: ['length', 'name']\nindexes: ['bin1_offset', 'chrom_offset']\npixels: ['bin1_id', 'bin2_id', 'count']\n\n\n\nbins = f['bins']\nchroms = f['chroms']\nindexes = f['indexes']\npixels = f['pixels']\n\n\n# Determine the size of the matrix\nnum_bins = len(bins['start'])\nhic_matrix = np.zeros((num_bins, num_bins))\n\n\n# NB Uses 20Gb RAM\n# Fill the Hi-C matrix using pixels and indexes\nbin1_ids = pixels['bin1_id']\nbin2_ids = pixels['bin2_id']\ncounts = np.log1p(pixels['count'])  # Apply log1p transformation directly\n\n# Use NumPy's advanced indexing to fill the matrix\nhic_matrix[bin1_ids, bin2_ids] = counts\nhic_matrix[bin2_ids, bin1_ids] = counts  # Symmetric matrix\n\n\n# NB Uses 32 Gb RAM\n# Load bw files\n\nbw_files = [f\"../figures/bowtie2/local/normalized/pc{NUM}_100kb_corrected_chrX.bigwig\" for NUM in range(1,4)]\nbw_data = []\nfor bw_file in bw_files:\n    bw = pyBigWig.open(bw_file)\n    chroms = bw.chroms()\n    data = []\n    for chrom in chroms:\n        chrom_data = bw.values(chrom, 0, chroms[chrom])\n        data.append(chrom_data)\n    bw_data.append(np.concatenate(data))\n    bw.close()\n\n\n# NB Crashed at 64 Gb RAM w/ 50 kb bins\n\n# Plot Hi-C matrix\nfig, ax = plt.subplots(len(bw_files) + 1, 1, figsize=(10, 10), gridspec_kw={'height_ratios': [3] + [1] * len(bw_files)})\n\n# Plot Hi-C matrix with log1p transformation\nax[0].imshow(hic_matrix_dense, cmap='Reds', aspect='equal')\nax[0].set_title('Hi-C Matrix (log1p transformed)')\n\n# Plot bigwig tracks\nfor i, data in enumerate(bw_data):\n    ax[i + 1].plot(data)\n    ax[i + 1].set_title(f'PC{i + 1}')\n    ax[i + 1].set_xlim(0, len(data))\n\nplt.tight_layout()\nplt.show()\n\n\n\nFirst try Copilot\nI don´t want to spend more time on this now. Switching notebook to cooler.\n\nimport h5py\nimport pyBigWig\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.sparse as sp\nimport gc\n\n# Load Hi-C matrix from .cool file\ncool_file = '../steps/bowtie2/local/matrices/normsm_filtered_pooled_100kb_corrected.cool'\n\nwith h5py.File(cool_file, 'r') as f:\n    bins = f['bins']\n    pixels = f['pixels']\n\n    # Determine the size of the matrix\n    num_bins = len(bins['start'])\n    hic_matrix = sp.lil_matrix((num_bins, num_bins))\n\n    # Fill the Hi-C matrix using pixels\n    bin1_ids = pixels['bin1_id']\n    bin2_ids = pixels['bin2_id']\n    counts = np.log1p(pixels['count'])  # Apply log1p transformation directly\n\n    # Use sparse matrix to fill the matrix\n    hic_matrix[bin1_ids, bin2_ids] = counts\n    hic_matrix[bin2_ids, bin1_ids] = counts  # Symmetric matrix\n\n# Convert to CSR format for efficient arithmetic and matrix vector operations\nhic_matrix = hic_matrix.tocsr()\n\n# Load bw files and plot in chunks\nbw_files = [f\"../figures/bowtie2/local/normalized/pc{NUM}_100kb_corrected_chrX.bigwig\" for NUM in range(1, 4)]\n\nfig, ax = plt.subplots(len(bw_files) + 1, 1, figsize=(10, 10), gridspec_kw={'height_ratios': [3] + [1] * len(bw_files)})\n\n# Plot Hi-C matrix with log1p transformation\nax[0].imshow(hic_matrix.toarray(), cmap='Reds', aspect='equal')\nax[0].set_title('Hi-C Matrix (log1p transformed)')\n\n# Plot bigwig tracks\nfor i, bw_file in enumerate(bw_files):\n    with pyBigWig.open(bw_file) as bw:\n        chroms = bw.chroms()\n        data = []\n        for chrom in chroms:\n            chrom_data = bw.values(chrom, 0, chroms[chrom])\n            data.append(chrom_data)\n        data = np.concatenate(data)\n        ax[i + 1].plot(data)\n        ax[i + 1].set_title(f'PC{i + 1}')\n        ax[i + 1].set_xlim(0, len(data))\n\nplt.tight_layout()\nplt.show()\n\n# Free memory\ndel hic_matrix\ndel data\ngc.collect()\n\n\n\n\n\n\n\n\n9",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HiCExplorer using macaque data</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html",
    "href": "notebooks/02_open2c_framework.html",
    "title": "Open2C framework",
    "section": "",
    "text": "pairtools: Convert sequencing data to a list of contacts",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#check-out-the-bamfiles",
    "href": "notebooks/02_open2c_framework.html#check-out-the-bamfiles",
    "title": "Open2C framework",
    "section": "Check out the bamfiles",
    "text": "Check out the bamfiles\n\n%%bash \n\ncd ../steps/bowtie2/local/bamfiles\n\nsamtools view SRR6502335_1.bam | head -n1\n\nSRR6502335.1    16  chr2    194419849   44  149M1S  *   0   0   AGAGAGAAAGAGTAGAAGGGAGAAACAAAGGGCAGGAGAGGGGATAGATGAAGAGGAACTAGACTTTGCACATATTGGCTGGCAATGATGGAATAGTCCAGTTTCAAAGAGTGAGATCTTGTAGTTATCTTCTCATTTATTCACTTAATN  &lt;FFAF-J7AJJA7AFA77-&lt;AAF-7-A7-7A7-FJ&lt;FA7FAA-7--AAA--&lt;&lt;A7FFJAJJJA&lt;-A-F7F7&lt;-A&lt;F7---&lt;A&lt;JJFFAAF7JFAAJ&lt;FFJF-&lt;-FJJFFFFFJFAF&lt;&lt;-AJJJJJFFF-JFJFFJF7AFJFFFAA-AAA#  AS:i:285    XN:i:0  XM:i:2  XO:i:0  XG:i:0  NM:i:2  MD:Z:44G78A25   YT:Z:UU\n\n\n\n%%bash \n\ncd ../steps/bowtie2/local/bamfiles/paired\n\nsamtools view SRR6502335_paired.bam | head -n1\n\nSRR6502335.1    0   chr2    194419717   44  10S140M *   0   0   NTTCTGGATCGATCATTTTTACATTATTTTTGCCTATGAACCAACTTTCAAAATTATTTCTCGTTTAAAATACAATTCAATGAGGTATTCATTTTTGTCTGGGGGGAAAGATGGAAGGTAGGAAGAAGAAAGAAGTGAAGAAAGAGAGAA  #AAAFAF&lt;JJJJJJFJJJJJJJ-JJFJJJJJ&lt;JAA-FF-FFAAFJFJFJJ--7&lt;F-AJFFAJFFFJF-7FF-FJF&lt;FFJFJFFF&lt;JA&lt;AJA7&lt;AJ&lt;AJFJ&lt;---77-7--7-7&lt;AAFFAF77&lt;FJ-&lt;&lt;--7-AFJ---7AF&lt;AAF--7&lt;7  AS:i:275    XN:i:0  XM:i:1  XO:i:0  XG:i:0  NM:i:1  MD:Z:125G14 YT:Z:UU\n\n\n\nI had to decompress the reference genome\nTo make samtools faidx work (or compress with bgzip, not gunzip)\n\n%%bash \n\ncd /home/sojern/hic-spermatogenesis/data/macaque_raw/ucsc_ref\n\ngunzip -k rheMac10.fa.gz",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#pair-and-sort-the-bamfiles-workfflow---turned-out-not-to-work-no-mapped-reads-were-left-after-filtering",
    "href": "notebooks/02_open2c_framework.html#pair-and-sort-the-bamfiles-workfflow---turned-out-not-to-work-no-mapped-reads-were-left-after-filtering",
    "title": "Open2C framework",
    "section": "Pair and sort the bamfiles (workfflow) - turned out not to work (no mapped reads were left after filtering)",
    "text": "Pair and sort the bamfiles (workfflow) - turned out not to work (no mapped reads were left after filtering)\n\nfrom IPython.display import display, Markdown\n\n# Read the content of the Python file\nwith open('../gwf_pair_alignments.py', 'r') as file:\n    file_content = file.read()\n\n# Display the content as Markdown\ndisplay(Markdown(f\"```python\\n{file_content}\\n```\"))\n\n# %% [markdown]\n# ---\n# title: \"gwf_bowtie_local\"\n# author: Søren Jørgensen\n# date: last-modified\n# execute: \n#   enabled: false\n# ---\n\n# %%\nfrom gwf import *\nimport glob\nimport os.path as op\n\n#######################################\n#\n# GWF workflow to pair alignments from mate-pair sequencing, after mapping to the reference individually.\n# After mapping, the mate-pairs are merged with `samtools merge` (another workflow) and then parsed with `pairtools parse`. \n#\n# How to run:\n# conda activate gwf\n# gwf -f gwf_gwf_pair_alignments.py status\n#\n# Workflow:\n#   1   pairtools parse : Parse the fastq files into pairs (after merging with `samtools merge`)\n#\n# Footnote: always activate the conda environment before running the workflow:\n# source $(conda info --base)/etc/profile.d/conda.sh\n# conda activate env_name\n#######################################\n\n# Create a workflow object\ngwf = Workflow(defaults={'nodes': 1, 'queue':\"normal\", 'account':\"hic-spermatogenesis\"})\n\n#############################################\n############### Templates ###################\n#############################################\n\ndef pair_sort_alignments(chromsizes, bam_merged, sorted_pairs):\n    \"\"\"Pair the merged alignments from mate-pair sequencing with `pairtools parse`\"\"\"\n    inputs = [bam_merged]\n    outputs = [f\"{bam_merged}_parsed.stats\", \n               sorted_pairs]\n    options = {'cores':12, 'memory':\"4g\", 'walltime':\"01:00:00\"}\n    spec=f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools parse \\\n    -c {chromsizes} \\\n    --drop-sam --drop-seq \\\n    --output-stats {bam_merged}_parsed.stats \\\n    --add-columns mapq \\\n    --assembly rheMac10 --no-flip \\\n    --walks-policy mask \\\n    {bam_merged} | \\\npairtools sort -o {sorted_pairs} \n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef dedup(sorted_pairs, ):\n    \"\"\"Deduplicate the sorted pairs with `pairtools dedup`\"\"\"\n\n    pairs_prefix = sorted_pairs.split(\".sorted\")[0]\n    inputs = [sorted_pairs]\n    outputs = [f\"{pairs_prefix}.nodups.pairs.gz\",\n               f\"{pairs_prefix}.nodups.bam\",\n               f\"{pairs_prefix}.unmapped.pairs.gz\",\n               f\"{pairs_prefix}.unmapped.bam\",\n               f\"{pairs_prefix}.dups.pairs.gz\",\n               f\"{pairs_prefix}.dups.bam\",\n               f\"{pairs_prefix}.dedup.stats\"]\n    options = {'cores':12, 'memory': \"4g\", 'walltime': \"01:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools dedup \\\n    --max-mismatch 3 \\\n    --mark-dups \\\n    --output \\\n        &gt;(pairtools split \\\n            --output-pairs {pairs_prefix}.nodups.pairs.gz \\\n            --output-sam {pairs_prefix}.nodups.bam \\\n         ) \\\n    --output-unmapped \\\n        &gt;( pairtools split \\\n            --output-pairs {pairs_prefix}.unmapped.pairs.gz \\\n            --output-sam {pairs_prefix}.unmapped.bam \\\n         ) \\\n    --output-dups \\\n        &gt;( pairtools split \\\n            --output-pairs {pairs_prefix}.dups.pairs.gz \\\n            --output-sam {pairs_prefix}.dups.bam \\\n            ) \\\n    --output-stats {pairs_prefix}.dedup.stats \\\n    {sorted_pairs}\n\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n#############################################\n################ Targets ####################\n#############################################\n\n# Define the chromsizes file\nchromsizes = \"data/links/ucsc_ref/misc/rheMac10.chrom.sizes\"\n\n# Find the merged bam files\nmerged_bams = gwf.glob(\"steps/bowtie2/local/bamfiles/paired/*_paired.bam\")\n\nsorted_bams = sorted(merged_bams)\n\n\nfor inbam in sorted_bams:\n    base = op.basename(inbam)\n    prefix = base.split(\"_paired\")[0]\n    \n    outdir = \"steps/bowtie2/local/bamfiles/paired/\"\n    outfile = f\"{base.split(\"_paired\")[0]}\" + \".sorted.pairs.gz\"\n    out_sorted_pairs = op.join(outdir, outfile)\n\n    gwf.target_from_template(f\"pair_sort_{prefix}\",\n                            pair_sort_alignments(chromsizes, inbam, out_sorted_pairs))\n    \n    gwf.target_from_template(f\"dedup_{prefix}\",\n                            dedup(out_sorted_pairs))",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#map-the-reads-again-but-as-pe-reads-in-stead-cooler-recommendation-workflow",
    "href": "notebooks/02_open2c_framework.html#map-the-reads-again-but-as-pe-reads-in-stead-cooler-recommendation-workflow",
    "title": "Open2C framework",
    "section": "Map the reads again but as PE reads in stead (cooler recommendation, workflow)",
    "text": "Map the reads again but as PE reads in stead (cooler recommendation, workflow)\n\nfrom IPython.display import display, Markdown\n\n# Read the content of the Python file\nwith open('../gwf_bwamem.py', 'r') as file:\n    file_content = file.read()\n\n# Display the content as Markdown\ndisplay(Markdown(f\"```python\\n{file_content}\\n```\"))\n\n# %% [markdown]\n# ---\n# title: \"gwf_map_reads\"\n# author: Søren Jørgensen\n# date: last-modified\n# execute: \n#   enabled: false\n# ---\n\n# %%\nfrom gwf import *\nimport glob\nimport os\n\n#######################################\n#\n# GWF workflow to map Hi-C reads to pairs with `bwa` and `samtools`.\n# Pairs are generated with `pairtools parse` and deduplicated with `pairtools dedup`.\n#\n# How to run:\n# conda activate gwf\n# gwf -f gwf_bwamem.py status\n#\n# Workflow:\n#   1a bwa_index        : [Reference genome] Index the reference genome with `bwa index`\n#   1b sam_index        : [Reference genome] Index the fasta again with `samtools faidx``\n#   2  bwa_map          : Map reads (PE) to the reference with `bwa mem` \n#   3  pair_sort        : Pair the merged alignments from mate-pair sequencing with `pairtools parse`, \n#                         then sort with `pairtools sort`\n#   4  dedup            : Deduplicate the sorted pairs with `pairtools dedup`  \n#\n#######################################\n\n# Create a workflow object\ngwf = Workflow(defaults={'nodes': 1, 'queue':\"normal\", 'account':\"hic-spermatogenesis\"})\n\n#############################################\n############### Templates ###################\n#############################################\n\ndef bwa_index(ref_genome):\n    \"\"\"Template for indexing the reference genome with bwa\"\"\"\n    inputs  = [ref_genome]\n    outputs = [f\"{ref_genome}.amb\", \n               f\"{ref_genome}.ann\", \n               f\"{ref_genome}.bwt\", \n               f\"{ref_genome}.pac\", \n               f\"{ref_genome}.sa\"]\n    options = {'cores':1, 'memory': \"5g\", 'walltime':\"02:00:00\"}\n    spec = f'''\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nbwa index -p {ref_genome} -a bwtsw {ref_genome}\n'''\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef sam_index(ref_genome):\n    \"\"\"Creating a Fasta index. `bwa mem` also needs a fasta index generated by samtools\"\"\"\n    inputs = [ref_genome]\n    outputs = [f\"{ref_genome}.fai\"]\n    options = {'cores':1, 'memory':\"5g\", 'walltime':\"00:20:00\"}\n    spec=f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nsamtools faidx {ref_genome}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\ndef bwa_map(ref_genome, mate_1, mate_2, out_bam):\n    \"\"\"\n    Template for mapping reads to a reference genome using `bwa` and `samtools`. \n    NB! Here, we map the mates together, as bwa states it is no problem for Hi-C reads. \n    \"\"\"\n    threads = 32\n    inputs = [f\"{ref_genome}.amb\", \n              f\"{ref_genome}.ann\", \n              f\"{ref_genome}.bwt\", \n              f\"{ref_genome}.pac\", \n              f\"{ref_genome}.sa\", \n              f\"{ref_genome}.fai\",\n              mate_1, mate_2]\n    outputs = [out_bam]\n    options = {'cores':threads, 'memory': \"32g\", 'walltime':\"06:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nbwa mem -t {threads} -SP {ref_genome} {mate_1} {mate_2} &gt; {out_bam}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef pair_sort_alignments(chromsizes, bam_merged, sorted_pairs):\n    \"\"\"Pair the merged alignments from mate-pair sequencing with `pairtools parse`\"\"\"\n    inputs = [bam_merged]\n    outputs = [f\"{bam_merged}_parsed.stats\", \n               sorted_pairs]\n    options = {'cores':12, 'memory':\"4g\", 'walltime':\"02:00:00\"}\n    spec=f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools parse \\\n    -c {chromsizes} \\\n    --drop-sam --drop-seq \\\n    --output-stats {bam_merged}_parsed.stats \\\n    --add-columns mapq \\\n    --assembly rheMac10 --no-flip \\\n    --walks-policy mask \\\n    {bam_merged} | \\\npairtools sort -o {sorted_pairs} \n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef dedup(sorted_pairs):\n    \"\"\"Deduplicate the sorted pairs with `pairtools dedup`\"\"\"\n    pairs_prefix = sorted_pairs.split(\".sorted\")[0]\n    inputs = [sorted_pairs]\n    outputs = [f\"{pairs_prefix}.nodups.pairs.gz\",\n               f\"{pairs_prefix}.nodups.bam\",\n               f\"{pairs_prefix}.unmapped.pairs.gz\",\n               f\"{pairs_prefix}.unmapped.bam\",\n               f\"{pairs_prefix}.dups.pairs.gz\",\n               f\"{pairs_prefix}.dups.bam\",\n               f\"{pairs_prefix}.dedup.stats\"]\n    options = {'cores':12, 'memory': \"4g\", 'walltime': \"01:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools dedup \\\n    --max-mismatch 3 \\\n    --mark-dups \\\n    --output \\\n        &gt;(pairtools split \\\n            --output-pairs {pairs_prefix}.nodups.pairs.gz \\\n            --output-sam {pairs_prefix}.nodups.bam \\\n         ) \\\n    --output-unmapped \\\n        &gt;( pairtools split \\\n            --output-pairs {pairs_prefix}.unmapped.pairs.gz \\\n            --output-sam {pairs_prefix}.unmapped.bam \\\n         ) \\\n    --output-dups \\\n        &gt;( pairtools split \\\n            --output-pairs {pairs_prefix}.dups.pairs.gz \\\n            --output-sam {pairs_prefix}.dups.bam \\\n            ) \\\n    --output-stats {pairs_prefix}.dedup.stats \\\n    {sorted_pairs}\n\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n\n#############################################\n############### Create targets ##############\n#############################################\n\n# Do stuff with the [unpacked] reference genome\nref_genome = \"data/links/ucsc_ref/rheMac10.fa\"\n\nT1a = gwf.target_from_template(f\"bwa_index_{os.path.basename(ref_genome)}\", \n                               bwa_index(ref_genome=ref_genome))\nT1b = gwf.target_from_template(f\"sam_index_{os.path.basename(ref_genome)}\", \n                               sam_index(ref_genome=ref_genome))\n\n\n# Define the chromsizes file\nchromsizes = \"data/links/ucsc_ref/misc/rheMac10.chrom.sizes\"\n\n\n# Locate Hi-C reads \nfastq_folder = \"data/links/macaque_fastq/\"\nfastq_files = glob.glob(os.path.join(fastq_folder, \"*.fastq.gz\"))\n\n# Pair the files (make sure they have the same base name prefix):\nfastq_files.sort()\npaired_fastq_files = list(zip(fastq_files[::2], fastq_files[1::2]))\n\nfor f1,f2 in paired_fastq_files:\n    \n    # Get the base names\n    basename_1 = os.path.basename(f1).split('.fast')[0]\n    basename_2 = os.path.basename(f2).split('.fast')[0]\n    \n    # Combine pair names\n    pairname = os.path.commonprefix([basename_1, basename_2]).split('_')[0]\n\n    # Create the output bam filenames\n    bam_dir = f\"steps/bwa/PE/bamfiles/\"\n    bam_file = pairname + \".PE.bam\"\n    out_bam = os.path.join(bam_dir, bam_file)\n\n    # Create targets for mapping\n    T2 = gwf.target_from_template(f\"bwa_map_{pairname}\", \n                                  bwa_map(ref_genome=ref_genome, \n                                          mate_1=f1, mate_2=f2, \n                                          out_bam=out_bam))\n    \n    # Create targets for sorting the pairs\n    pair_dir = \"steps/bwa/PE/pairs/\"\n    pair_file = pairname + \".sorted.pairs.gz\"\n    sorted_pairs = os.path.join(pair_dir, pair_file)\n\n    T3 = gwf.target_from_template(f\"pair_sort_{pairname}\", \n                                  pair_sort_alignments(chromsizes=chromsizes, \n                                                       bam_merged=out_bam, \n                                                       sorted_pairs=sorted_pairs))\n    \n    T4 = gwf.target_from_template(f\"dedup_{pairname}\", dedup(sorted_pairs=sorted_pairs))",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#check-the-sorted-pairs",
    "href": "notebooks/02_open2c_framework.html#check-the-sorted-pairs",
    "title": "Open2C framework",
    "section": "Check the sorted pairs",
    "text": "Check the sorted pairs\n\n%%bash\n\n#cd ../steps/bowtie2/local/bamfiles/paired\ncd ../steps/bwa/PE/pairs\n\n# Unique pairs:\ngzip -dc SRR6502339.nodups.pairs.gz | grep -v '#' |  head -n 5\n\necho \"--\"\n\n# Only dups\ngzip -dc SRR6502339.dups.pairs.gz | grep -v '#' |  head -n 5\n\necho \"--\"\n\nSRR6502339.38272510 chr1    898 chr1    1026    +   -   UU  3   3\nSRR6502339.13727657 chr1    976 chr1    175669579   +   -   UR  4   60\nSRR6502339.67930411 chr1    1035    chr1    99209   +   -   UU  22  60\nSRR6502339.90172213 chr1    1134    chr1    11385306    -   +   UR  9   60\nSRR6502339.53849219 chr1    5186    chr1    56858619    +   -   UR  2   60\n--\nSRR6502339.53849978 chr1    5186    chr1    56858619    +   -   DD  2   60\nSRR6502339.67632192 chr1    13335   chr1    370581  +   -   DD  3   7\nSRR6502339.92006828 chr1    16215   chr1    16560   +   -   DD  35  12\nSRR6502339.71065550 chr1    19644   chr1    62483   +   -   DD  23  60\nSRR6502339.89600080 chr1    19644   chr1    62483   +   -   DD  25  60\n--\n\n\n[main_samview] fail to read the header from \"SRR6502339.nodups.bam\".",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#visualize-stats-pairtools-stats",
    "href": "notebooks/02_open2c_framework.html#visualize-stats-pairtools-stats",
    "title": "Open2C framework",
    "section": "Visualize Stats: pairtools stats",
    "text": "Visualize Stats: pairtools stats\nIt might be the same stats that are (optionally) returned from pairtools parse.\nLet’s look at the parsed stats in a nice way:\n\nIf it is not the same, then run this command on all the sorted pairs.\n\n%%bash \n\ncd ../steps/bwa/PE/pairs\n\n#pairtools stats SRR6502339.sorted.pairs.gz -o test.stats\n\n\n\nOtherwise, just use MultiQC\n\nGenerate the MultiQC files\n\n\nNow visualize:\n\nAll results merged (before dedup)\n\nfrom IPython.display import IFrame\n\nIFrame(src='../steps/bwa/PE/bamfiles/fibroblast/Fibroblasts_all_multiqc_report.html', width=1200, height=800)\n\n\n        \n        \n\n\n\n%%bash \n\ncd ../steps/bwa/PE/pairs/\n\nmultiqc -i Fibroblasts_all.dedup --no-data-dir  *.stats \n\n\n/// d=807531;https://multiqc.info\u001b\\MultiQC;;\u001b\\ 🔍 v1.25.1\n\n     update_config | Report title: Fibroblasts_all.dedup\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/SRR6502335.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/SRR6502336.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/SRR6502337.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/SRR6502338.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/SRR6502339.dedup.stats\n         searching | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 5/5  .dedup.statsmSRR6502338.dedup.stats\n         pairtools | Found 5 reports\n     write_results | Data        : None\n     write_results | Report      : Fibroblasts_all.dedup_multiqc_report.html\n           multiqc | MultiQC complete\n\n\n\nfrom IPython.display import IFrame\n\nIFrame(src='../data/QC/Fibroblasts_all.dedup_multiqc_report.html', width=1200, height=800)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#dedup-the-pairs-and-visualize-stats-again",
    "href": "notebooks/02_open2c_framework.html#dedup-the-pairs-and-visualize-stats-again",
    "title": "Open2C framework",
    "section": "Dedup the pairs and visualize stats again",
    "text": "Dedup the pairs and visualize stats again\nThe pairs was deduplicated with a gwf workflow gwf_bwamem.py\n\n%%bash \n\ncd ../steps/bwa/PE/pairs/sorted\n\nmultiqc -i fibroblast.dedup --no-data-dir *.stats\n\n\n/// d=271458;https://multiqc.info\u001b\\MultiQC;;\u001b\\ 🔍 v1.25.1\n\n     update_config | Report title: fibroblast.dedup\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/sorted/SRR6502335.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/sorted/SRR6502336.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/sorted/SRR6502337.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/sorted/SRR6502338.dedup.stats\n       file_search | Search path: /faststorage/project/hic-spermatogenesis/people/sojern/hic-spermatogenesis/steps/bwa/PE/pairs/sorted/SRR6502339.dedup.stats\n         searching | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 5/5  0/5  \n         pairtools | Found 5 reports\n     write_results | Data        : None\n     write_results | Report      : fibroblast.dedup_multiqc_report.html\n           multiqc | MultiQC complete\n\n\n\nfrom IPython.display import IFrame\n\nIFrame(src='../data/QC/fibroblast.dedup_multiqc_report.html', width=1200, height=800, style=\"border:2px solid black\")",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#introduction",
    "href": "notebooks/02_open2c_framework.html#introduction",
    "title": "Open2C framework",
    "section": "Introduction",
    "text": "Introduction\nFirst, we have to check the data output from HiCExplorer. The output is a .cool file, which is a binary format for storing Hi-C data. The file contains the binned contact matrix and the genomic coordinates of the bins.\nThe cooler package is a Python library for working with .cool files. It provides tools for reading, writing, and manipulating Hi-C data. The cooltools package is a collection of tools for analyzing Hi-C data, including normalization, visualization, and interaction calling.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#follow-cooler-walkthrough-from-the-documentation",
    "href": "notebooks/02_open2c_framework.html#follow-cooler-walkthrough-from-the-documentation",
    "title": "Open2C framework",
    "section": "Follow cooler walkthrough from the documentation",
    "text": "Follow cooler walkthrough from the documentation\n\n# Import the packages we will use\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas\nimport h5py\n\nimport cooler\n\n\n# The following directive activates inline plotting\n%matplotlib inline\n\n\n# Define the filepath (I choose the uncorrected matrix)\n\nfilepath = \"../steps/bowtie2/local/matrices/filtered_pooled_10kb.cool\"\n\n\nDirect access with h5py\n\nh5 = h5py.File(filepath, 'r')\nh5\n\n&lt;HDF5 file \"filtered_pooled_10kb.cool\" (mode r)&gt;\n\n\n\nh5.keys()\n\n&lt;KeysViewHDF5 ['bins', 'chroms', 'indexes', 'pixels']&gt;\n\n\n\nh5['pixels']\n\n&lt;HDF5 group \"/pixels\" (3 members)&gt;\n\n\n\nlist(h5['pixels'].keys())\n\n['bin1_id', 'bin2_id', 'count']\n\n\nh5py dataset objects are views onto the data on disk\n\nh5['pixels']['bin2_id']\n\n&lt;HDF5 dataset \"bin2_id\": shape (117090191,), type \"&lt;i4\"&gt;\n\n\nSlicing or indexing returns a numpy array in memory.\n\nh5['pixels']['bin2_id'][:10]\n\narray([   0,    9,   30,   33,  124,  127,  145,  756, 1167, 2416],\n      dtype=int32)\n\n\n\nh5['pixels']['count'][:10]\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\n\n\nh5.close()\n\nThe Python cooler package is just a thin wrapper over h5py.\n\nIt lets you access the data tables as Pandas data frames and series.\nIt also provides a matrix abstraction: letting you query the upper triangle pixel table as if it were a full rectangular sparse matrix via SciPy.\n\n\n\nThe Cooler class\nAccepts a file path or an open HDF5 file object.\nNOTE: Using a filepath allows the Cooler object to be serialized/pickled since the file is only opened when needed\n\nc = cooler.Cooler(filepath)\n\n\nc.info\n\n{'bin-size': 10000,\n 'bin-type': 'fixed',\n 'creation-date': '2024-09-24T21:20:38.656143',\n 'format': 'HDF5::Cooler',\n 'format-url': 'https://github.com/mirnylab/cooler',\n 'format-version': 3,\n 'generated-by': 'HiCMatrix-17.2',\n 'generated-by-cooler-lib': 'cooler-0.10.2',\n 'genome-assembly': 'unknown',\n 'metadata': {'format': 'HDF5::Cooler',\n  'format-url': 'https://github.com/mirnylab/cooler',\n  'generated-by': 'HiCMatrix-17.2',\n  'generated-by-cooler-lib': 'cooler-0.10.2',\n  'tool-url': 'https://github.com/deeptools/HiCMatrix'},\n 'nbins': 285406,\n 'nchroms': 22,\n 'nnz': 117090191,\n 'storage-mode': 'symmetric-upper',\n 'sum': 193589731.0,\n 'tool-url': 'https://github.com/deeptools/HiCMatrix'}\n\n\n\nc.chroms()\n\n&lt;cooler.core._selectors.RangeSelector1D at 0x146a5acf1cd0&gt;\n\n\nThe return value is a selector or “view” on a table that accepts column and range queries (“slices”).\n\nColumn selections return a new view.\nRange selections return pandas DataFrames or Series.\n\n\n# Get a slice of the chromosomes\nc.chroms()[0:5]\n\n# Or the whole dict\n#c.chroms()[:]\n\n\n\n\n\n\n\n\nname\nlength\n\n\n\n\n0\nchr1\n223616942\n\n\n1\nchr2\n196197964\n\n\n2\nchr3\n185288947\n\n\n3\nchr4\n169963040\n\n\n4\nchr5\n187317192\n\n\n\n\n\n\n\n\n# Convenience\nc.chromnames, c.chromsizes\n\n(['chr1',\n  'chr2',\n  'chr3',\n  'chr4',\n  'chr5',\n  'chr6',\n  'chr7',\n  'chr8',\n  'chr9',\n  'chr10',\n  'chr11',\n  'chr12',\n  'chr13',\n  'chr14',\n  'chr15',\n  'chr16',\n  'chr17',\n  'chr18',\n  'chr19',\n  'chr20',\n  'chrX',\n  'chrY'],\n name\n chr1     223616942\n chr2     196197964\n chr3     185288947\n chr4     169963040\n chr5     187317192\n chr6     179085566\n chr7     169868564\n chr8     145679320\n chr9     134124166\n chr10     99517758\n chr11    133066086\n chr12    130043856\n chr13    108737130\n chr14    128056306\n chr15    113283604\n chr16     79627064\n chr17     95433459\n chr18     74474043\n chr19     58315233\n chr20     77137495\n chrX     153388924\n chrY      11753682\n Name: length, dtype: int32)\n\n\n\n# Access bins\nc.bins()[:10]\n\n\n\n\n\n\n\n\nchrom\nstart\nend\n\n\n\n\n0\nchr1\n0\n10000\n\n\n1\nchr1\n10000\n20000\n\n\n2\nchr1\n20000\n30000\n\n\n3\nchr1\n30000\n40000\n\n\n4\nchr1\n40000\n50000\n\n\n5\nchr1\n50000\n60000\n\n\n6\nchr1\n60000\n70000\n\n\n7\nchr1\n70000\n80000\n\n\n8\nchr1\n80000\n90000\n\n\n9\nchr1\n90000\n100000\n\n\n\n\n\n\n\nSelecting a list of columns returns a new DataFrame view on that subset of columns\n\nbins = c.bins()[['chrom', 'start', 'end']]\nbins\n\n&lt;cooler.core._selectors.RangeSelector1D at 0x146a60464a40&gt;\n\n\n\nbins[:5]\n\n\n\n\n\n\n\n\nchrom\nstart\nend\n\n\n\n\n0\nchr1\n0\n10000\n\n\n1\nchr1\n10000\n20000\n\n\n2\nchr1\n20000\n30000\n\n\n3\nchr1\n30000\n40000\n\n\n4\nchr1\n40000\n50000\n\n\n\n\n\n\n\nThe pixel table contains the non-zero upper triangle entries of the contact map.\n\n# Use the join=True option if you would like to expand the bin IDs into genomic bin coordinates by joining the output with the bin table.\n\ndisplay(c.pixels()[:10], c.pixels(join=True)[:10])\n\n\n\n\n\n\n\n\nbin1_id\nbin2_id\ncount\n\n\n\n\n0\n0\n0\n1.0\n\n\n1\n0\n9\n1.0\n\n\n2\n0\n30\n1.0\n\n\n3\n0\n33\n1.0\n\n\n4\n0\n124\n1.0\n\n\n5\n0\n127\n1.0\n\n\n6\n0\n145\n1.0\n\n\n7\n0\n756\n1.0\n\n\n8\n0\n1167\n1.0\n\n\n9\n0\n2416\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nchrom1\nstart1\nend1\nchrom2\nstart2\nend2\ncount\n\n\n\n\n0\nchr1\n0\n10000\nchr1\n0\n10000\n1.0\n\n\n1\nchr1\n0\n10000\nchr1\n90000\n100000\n1.0\n\n\n2\nchr1\n0\n10000\nchr1\n300000\n310000\n1.0\n\n\n3\nchr1\n0\n10000\nchr1\n330000\n340000\n1.0\n\n\n4\nchr1\n0\n10000\nchr1\n1240000\n1250000\n1.0\n\n\n5\nchr1\n0\n10000\nchr1\n1270000\n1280000\n1.0\n\n\n6\nchr1\n0\n10000\nchr1\n1450000\n1460000\n1.0\n\n\n7\nchr1\n0\n10000\nchr1\n7560000\n7570000\n1.0\n\n\n8\nchr1\n0\n10000\nchr1\n11670000\n11680000\n1.0\n\n\n9\nchr1\n0\n10000\nchr1\n24160000\n24170000\n1.0\n\n\n\n\n\n\n\nDump any table selection with pandas to tabular\n\ndf = c.pixels(join=True)[:100]\n\n# df.to_csv('data/myselection.txt'), sep='\\t', index=False, header=False) \n\n\n\nBin annotation\nAnother way to annotate the bins in a data frame of pixels is to use cooler.annotate. It does a left outer join from the bin1_id and bin2_id columns onto a data frame indexed by bin ID that describes the bins.\n\nbins = c.bins()[:] # fetch all\npix = c.pixels()[100:110] # select some pixels\npix\n\n\n\n\n\n\n\n\nbin1_id\nbin2_id\ncount\n\n\n\n\n100\n2\n481\n1.0\n\n\n101\n2\n500\n1.0\n\n\n102\n2\n519\n1.0\n\n\n103\n2\n557\n1.0\n\n\n104\n2\n580\n1.0\n\n\n105\n2\n594\n1.0\n\n\n106\n2\n606\n1.0\n\n\n107\n2\n621\n1.0\n\n\n108\n2\n625\n1.0\n\n\n109\n2\n646\n1.0\n\n\n\n\n\n\n\n\ncooler.annotate(pix, bins)\n\n\n\n\n\n\n\n\nchrom1\nstart1\nend1\nchrom2\nstart2\nend2\nbin1_id\nbin2_id\ncount\n\n\n\n\n100\nchr1\n20000\n30000\nchr1\n4810000\n4820000\n2\n481\n1.0\n\n\n101\nchr1\n20000\n30000\nchr1\n5000000\n5010000\n2\n500\n1.0\n\n\n102\nchr1\n20000\n30000\nchr1\n5190000\n5200000\n2\n519\n1.0\n\n\n103\nchr1\n20000\n30000\nchr1\n5570000\n5580000\n2\n557\n1.0\n\n\n104\nchr1\n20000\n30000\nchr1\n5800000\n5810000\n2\n580\n1.0\n\n\n105\nchr1\n20000\n30000\nchr1\n5940000\n5950000\n2\n594\n1.0\n\n\n106\nchr1\n20000\n30000\nchr1\n6060000\n6070000\n2\n606\n1.0\n\n\n107\nchr1\n20000\n30000\nchr1\n6210000\n6220000\n2\n621\n1.0\n\n\n108\nchr1\n20000\n30000\nchr1\n6250000\n6260000\n2\n625\n1.0\n\n\n109\nchr1\n20000\n30000\nchr1\n6460000\n6470000\n2\n646\n1.0\n\n\n\n\n\n\n\n\ncooler.annotate(pix, bins[['start']], replace=False)\n\n\n\n\n\n\n\n\nstart1\nstart2\nbin1_id\nbin2_id\ncount\n\n\n\n\n100\n20000\n4810000\n2\n481\n1.0\n\n\n101\n20000\n5000000\n2\n500\n1.0\n\n\n102\n20000\n5190000\n2\n519\n1.0\n\n\n103\n20000\n5570000\n2\n557\n1.0\n\n\n104\n20000\n5800000\n2\n580\n1.0\n\n\n105\n20000\n5940000\n2\n594\n1.0\n\n\n106\n20000\n6060000\n2\n606\n1.0\n\n\n107\n20000\n6210000\n2\n621\n1.0\n\n\n108\n20000\n6250000\n2\n625\n1.0\n\n\n109\n20000\n6460000\n2\n646\n1.0\n\n\n\n\n\n\n\n\n\nEnter the Matrix\nFinally, the matrix method provides a 2D-sliceable view on the data. It allows you to query the data on file as a full rectangular contact matrix.\n\nc.matrix()\n\n&lt;cooler.core._selectors.RangeSelector2D at 0x146a5ad44470&gt;\n\n\n\narr = c.matrix(balance=False)[1000:1200, 1000:1200]\narr\n\narray([[ 57.,  33.,   9., ...,   0.,   1.,   0.],\n       [ 33.,  88.,  33., ...,   1.,   0.,   0.],\n       [  9.,  33.,  74., ...,   0.,   0.,   0.],\n       ...,\n       [  0.,   1.,   0., ..., 104.,  27.,  12.],\n       [  1.,   0.,   0., ...,  27., 118.,  46.],\n       [  0.,   0.,   0., ...,  12.,  46., 135.]])\n\n\n\n# Use sparse=True to return a scipy.sparse.coo_matrix in stead\n\nmat = c.matrix(balance=False, sparse=True)[1000:1200,1000:1200]\nmat\n\n&lt;200x200 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n    with 26544 stored elements in COOrdinate format&gt;\n\n\nConvert to a 2D numpy array\n\narr = mat.toarray()\narr\n\narray([[ 57.,  33.,   9., ...,   0.,   1.,   0.],\n       [ 33.,  88.,  33., ...,   1.,   0.,   0.],\n       [  9.,  33.,  74., ...,   0.,   0.,   0.],\n       ...,\n       [  0.,   1.,   0., ..., 104.,  27.,  12.],\n       [  1.,   0.,   0., ...,  27., 118.,  46.],\n       [  0.,   0.,   0., ...,  12.,  46., 135.]])\n\n\nNotice that tha lower triangle has automatically been filled\n\n# Plot\nfig = plt.figure(figsize=(10,10))\nax  = fig.add_subplot(111)\nim  = ax.matshow(np.log1p(arr), cmap='Reds')\nfig.colorbar(im)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#use-the-new-pairs",
    "href": "notebooks/02_open2c_framework.html#use-the-new-pairs",
    "title": "Open2C framework",
    "section": "Use the new pairs",
    "text": "Use the new pairs\n\n# Import the packages we will use\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas\nimport h5py\n\nimport cooler\n\n# The following directive activates inline plotting\n%matplotlib inline\n\n\nfilepath = \"../steps/bwa/PE/pairs/cool/SRR6502335.nodups.10000.cool\"\n\n\nc = cooler.Cooler(filepath)\nc.info\n\n{'bin-size': 10000,\n 'bin-type': 'fixed',\n 'creation-date': '2024-10-08T14:31:29.159937',\n 'format': 'HDF5::Cooler',\n 'format-url': 'https://github.com/open2c/cooler',\n 'format-version': 3,\n 'generated-by': 'cooler-0.10.2',\n 'genome-assembly': 'rheMac10',\n 'metadata': {},\n 'nbins': 298615,\n 'nchroms': 2939,\n 'nnz': 67535020,\n 'storage-mode': 'symmetric-upper',\n 'sum': 115865253}\n\n\n\nc.bins()[:100]\n\n\n\n\n\n\n\n\nchrom\nstart\nend\n\n\n\n\n0\nchr1\n0\n10000\n\n\n1\nchr1\n10000\n20000\n\n\n2\nchr1\n20000\n30000\n\n\n3\nchr1\n30000\n40000\n\n\n4\nchr1\n40000\n50000\n\n\n...\n...\n...\n...\n\n\n95\nchr1\n950000\n960000\n\n\n96\nchr1\n960000\n970000\n\n\n97\nchr1\n970000\n980000\n\n\n98\nchr1\n980000\n990000\n\n\n99\nchr1\n990000\n1000000\n\n\n\n\n100 rows × 3 columns\n\n\n\n\nc.matrix()\n\n&lt;cooler.core._selectors.RangeSelector2D at 0x14fc849042c0&gt;\n\n\n\narr = c.matrix(balance=False).fetch('chrX')\narr\n\narray([[39,  0,  4, ...,  0,  0,  0],\n       [ 0,  9,  3, ...,  0,  0,  0],\n       [ 4,  3, 29, ...,  0,  0,  0],\n       ...,\n       [ 0,  0,  0, ...,  7,  0,  0],\n       [ 0,  0,  0, ...,  0,  0,  0],\n       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int32)\n\n\n\n# Plot with matplotlib\nfig = plt.figure(figsize=(10,10))\nax =  fig.add_subplot(111)\nim =  ax.matshow(np.log1p(arr), cmap=\"Reds\")\nfig.colorbar(im)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#merge-the-replicates-according-to-sra-id",
    "href": "notebooks/02_open2c_framework.html#merge-the-replicates-according-to-sra-id",
    "title": "Open2C framework",
    "section": "Merge the replicates according to SRA ID",
    "text": "Merge the replicates according to SRA ID\n\nFirst, subset the chromosomes to only the real chromosomes\n\nprint(filepath)\nprint(filepath.replace('nodups', 'subset.nodups'))\n\n../steps/bwa/PE/pairs/cool/SRR6502335.nodups.10000.cool\n../steps/bwa/PE/pairs/cool/SRR6502335.subset.nodups.10000.cool\n\n\n\nMake a loop\n\nimport cooler\nimport os.path as op\nfrom pprintpp import pprint as pp\n\ncoolers = [f\"../steps/bwa/PE/pairs/cool/SRR650233{n}.nodups.10000.cool\" for n in range(5,10)]\nprint(f\"Subsetting coolers and merging replicates from\")\npp(coolers)\n\nfor cool in coolers:\n    # Filenames\n    cool_file = cool\n    output_cool_file = cool_file.replace('nodups', 'subset.nodups')\n\n    if op.exists(output_cool_file):\n        print(f\"Skipping {cool_file} (exists)\")\n        continue\n\n    print(f\"Input: {cool_file} \\nOutput: {output_cool_file}\\n\\nInitializing cooler from input...\")\n    \n    # Load the original .cool file\n    c = cooler.Cooler(cool_file)\n    \n    # Define the chromosomes to keep (e.g., excluding unplaced scaffolds/contigs)\n    chroms_to_keep = c.chroms()[0:22]['name']\n    \n    # Filter the bins to include only the selected chromosomes\n    print(\"Filtering bins...\")\n    \n    bins = c.bins()[:]\n    filtered_bins = bins[bins['chrom'].isin(chroms_to_keep)]\n    \n    # Filter the pixels to include only the selected bins\n    print(\"Filtering pixels...\")\n    \n    bin_ids_to_keep = set(filtered_bins.index)\n    pixels = c.pixels()[:]\n    filtered_pixels = pixels[pixels['bin1_id'].isin(bin_ids_to_keep) & pixels['bin2_id'].isin(bin_ids_to_keep)]\n\n    # Subset the coolers\n\n    print(\"Creating subsetted cooler...\")\n\n    cooler.create_cooler(\n        cool_uri=output_cool_file,\n        bins=filtered_bins,\n        pixels=filtered_pixels,\n        assembly='rheMac10',  # Optional: specify the genome assembly\n        ordered=True,  # Assuming the input chunks are in the correct order\n        symmetric_upper=True,  # Assuming the input data references the upper triangle of a symmetric matrix\n        mode='w',  # Write mode\n        ensure_sorted=True,  # Ensure that each input chunk is properly sorted\n        boundscheck=True,  # Check that all bin IDs lie in the expected range\n        dupcheck=True,  # Check that no duplicate pixels exist within any chunk\n        triucheck=True  # Check that bin1_id &lt;= bin2_id when creating coolers in symmetric-upper mode\n    )\n\n    print(f\"Subset .cool file created: {output_cool_file}\")\n\nSubsetting coolers and merging replicates from\n[\n    '../steps/bwa/PE/pairs/cool/SRR6502335.nodups.10000.cool',\n    '../steps/bwa/PE/pairs/cool/SRR6502336.nodups.10000.cool',\n    '../steps/bwa/PE/pairs/cool/SRR6502337.nodups.10000.cool',\n    '../steps/bwa/PE/pairs/cool/SRR6502338.nodups.10000.cool',\n    '../steps/bwa/PE/pairs/cool/SRR6502339.nodups.10000.cool',\n]\nSkipping ../steps/bwa/PE/pairs/cool/SRR6502335.nodups.10000.cool (exists)\nSkipping ../steps/bwa/PE/pairs/cool/SRR6502336.nodups.10000.cool (exists)\nSkipping ../steps/bwa/PE/pairs/cool/SRR6502337.nodups.10000.cool (exists)\nSkipping ../steps/bwa/PE/pairs/cool/SRR6502338.nodups.10000.cool (exists)\nSkipping ../steps/bwa/PE/pairs/cool/SRR6502339.nodups.10000.cool (exists)\n\n\n\n# Merge rep1\nrep1_out = \"../steps/bwa/PE/pairs/cool/fib_rep1.10000.cool\"\nif not op.exists(rep1_out):\n    cooler.merge_coolers(output_uri = rep1_out,\n                         input_uris = [\"../steps/bwa/PE/pairs/cool/SRR6502335.subset.nodups.10000.cool\",\n                                      \"../steps/bwa/PE/pairs/cool/SRR6502336.subset.nodups.10000.cool\"],\n                         mergebuf = 20000000)\nelse:\n    print(f\"{rep1_out} already exists\")\n\n../steps/bwa/PE/pairs/cool/fib_rep1.10000.cool already exists\n\n\n\n# Merge rep2\nrep2_out = \"../steps/bwa/PE/pairs/cool/fib_rep2.10000.cool\"\nif not op.exists(rep2_out):\n    cooler.merge_coolers(output_uri = rep2_out,\n                         input_uris = [\"../steps/bwa/PE/pairs/cool/SRR6502337.subset.nodups.10000.cool\",\n                                      \"../steps/bwa/PE/pairs/cool/SRR6502338.subset.nodups.10000.cool\",\n                                      \"../steps/bwa/PE/pairs/cool/SRR6502339.subset.nodups.10000.cool\"],\n                         mergebuf = 20000000)\nelse:\n    print(f\"{rep1_out} already exists\")\n\n../steps/bwa/PE/pairs/cool/fib_rep1.10000.cool already exists\n\n\n\nc_rep1 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.10000.cool\")\nc_rep2 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep2.10000.cool\")\n\npp(c_rep1.info) \npp(c_rep2.info)\n\n{\n    'bin-size': 10000,\n    'bin-type': 'fixed',\n    'creation-date': '2024-10-08T21:02:38.036175',\n    'format': 'HDF5::Cooler',\n    'format-url': 'https://github.com/open2c/cooler',\n    'format-version': 3,\n    'generated-by': 'cooler-0.10.2',\n    'genome-assembly': 'rheMac10',\n    'metadata': {},\n    'nbins': 285406,\n    'nchroms': 22,\n    'nnz': 112572916,\n    'storage-mode': 'symmetric-upper',\n    'sum': 211718459,\n}\n{\n    'bin-size': 10000,\n    'bin-type': 'fixed',\n    'creation-date': '2024-10-08T21:52:32.813516',\n    'format': 'HDF5::Cooler',\n    'format-url': 'https://github.com/open2c/cooler',\n    'format-version': 3,\n    'generated-by': 'cooler-0.10.2',\n    'genome-assembly': 'rheMac10',\n    'metadata': {},\n    'nbins': 285406,\n    'nchroms': 22,\n    'nnz': 117207943,\n    'storage-mode': 'symmetric-upper',\n    'sum': 211294810,\n}",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#zoomify-the-merged-replicates",
    "href": "notebooks/02_open2c_framework.html#zoomify-the-merged-replicates",
    "title": "Open2C framework",
    "section": "zoomify the merged replicates",
    "text": "zoomify the merged replicates\nGenerate an .mcool file containing coarser resolution to be called.\n\nimport cooler\nimport os.path as op\n\ncool_paths = {'rep1': \"../steps/bwa/PE/pairs/cool/fib_rep1.10000.cool\",\n              'rep2': \"../steps/bwa/PE/pairs/cool/fib_rep2.10000.cool\"}\n\nmcool_paths = {'rep1': \"../steps/bwa/PE/pairs/cool/fib_rep1.mcool\",\n               'rep2': \"../steps/bwa/PE/pairs/cool/fib_rep2.mcool\"}\n\nfor cool,path in cool_paths.items():\n    if op.exists(mcool_paths[cool]):\n        print(f\"Skipping: {mcool_paths[cool]} already exists\")\n        continue\n\n    print(f\"Zoomifying cooler: \\n\\t   {path}\\n\\t-&gt; {mcool_paths[cool]}\", end=\"\\n\")\n    \n    cooler.zoomify_cooler(base_uris = path,\n                          outfile = mcool_paths[cool],\n                          resolutions = [10000,50000,100000,500000],\n                          chunksize = 10000000,\n                          nproc = 4)\n    print(\" --&gt; done\")\n\nSkipping: ../steps/bwa/PE/pairs/cool/fib_rep1.mcool already exists\nSkipping: ../steps/bwa/PE/pairs/cool/fib_rep2.mcool already exists\n\n\n\n# to print which resolutions are stored in the mcool, use list_coolers\ncooler.fileops.list_coolers(mcool_paths['rep1'])\n\n['/resolutions/10000',\n '/resolutions/50000',\n '/resolutions/100000',\n '/resolutions/500000']",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#visualize-the-matrices",
    "href": "notebooks/02_open2c_framework.html#visualize-the-matrices",
    "title": "Open2C framework",
    "section": "Visualize the matrices",
    "text": "Visualize the matrices\n\nPlot the uncorrected matrix\n\nc1 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/100000\")\nc2 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep2.mcool::resolutions/100000\")\n\n\nc1.info\n\n{'bin-size': 100000,\n 'bin-type': 'fixed',\n 'creation-date': '2024-10-08T22:48:20.327186',\n 'format': 'HDF5::Cooler',\n 'format-url': 'https://github.com/open2c/cooler',\n 'format-version': 3,\n 'generated-by': 'cooler-0.10.2',\n 'genome-assembly': 'unknown',\n 'metadata': {},\n 'nbins': 28550,\n 'nchroms': 22,\n 'nnz': 52382089,\n 'storage-mode': 'symmetric-upper',\n 'sum': 211718459}\n\n\n\narr1 = c1.matrix(balance=False).fetch('chrX')\narr2 = c2.matrix(balance=False).fetch('chrX')\n\n\n# Plot with matplotlib\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\n# Plot the first replicate\nim1 = ax1.matshow(np.log1p(arr1), cmap=\"Reds\")\nax1.set_title('Replicate 1')\nfig.colorbar(im1, ax=ax1)\n\n# Plot the second replicate\nim2 = ax2.matshow(np.log1p(arr2), cmap=\"Reds\")\nax2.set_title('Replicate 2')\nfig.colorbar(im2, ax=ax2)\n\nplt.show()\n\n\n\n\nThe X chromosome in 100kb bins and the first 3 PCs below. UNCORRECTED. Made with cooler and matplotlib.\n\n\n\n\n\nFollow `cooltools´ suggestion/guide\n\nimport cooler\n\nc1 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/500000\")\nclr = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/100000\")\nc2 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/50000\")\n\n\n### to print chromosomes and binsize for this cooler\nprint(f'chromosomes: {c1.chromnames}, binsize: {c1.binsize}')\nprint(f'chromosomes: {clr.chromnames}, binsize: {clr.binsize}')\nprint(f'chromosomes: {c2.chromnames}, binsize: {c2.binsize}')\n\n### to make a list of chromosome start/ends in bins:\nchromstarts = []\nchromstarts500kb = []\nchromstarts50kb = []\nfor i in clr.chromnames:\n    chromstarts500kb.append(c1.extent(i)[0])\n    chromstarts.append(clr.extent(i)[0])\n    chromstarts50kb.append(c2.extent(i)[0])\n\nchromosomes: ['chr1', 'chr2', 'chr5', 'chr3', 'chr6', 'chr4', 'chr7', 'chrX', 'chr8', 'chr9', 'chr11', 'chr12', 'chr14', 'chr15', 'chr13', 'chr10', 'chr17', 'chr16', 'chr20', 'chr18', 'chr19', 'chrY'], binsize: 500000\nchromosomes: ['chr1', 'chr2', 'chr5', 'chr3', 'chr6', 'chr4', 'chr7', 'chrX', 'chr8', 'chr9', 'chr11', 'chr12', 'chr14', 'chr15', 'chr13', 'chr10', 'chr17', 'chr16', 'chr20', 'chr18', 'chr19', 'chrY'], binsize: 100000\nchromosomes: ['chr1', 'chr2', 'chr5', 'chr3', 'chr6', 'chr4', 'chr7', 'chrX', 'chr8', 'chr9', 'chr11', 'chr12', 'chr14', 'chr15', 'chr13', 'chr10', 'chr17', 'chr16', 'chr20', 'chr18', 'chr19', 'chrY'], binsize: 50000\n\n\n\n# to plot ticks in terms of megabases we use the EngFormatter\n# https://matplotlib.org/gallery/api/engineering_formatter.html\n# Also, here we fetch the chromosomes directly from within the plot\n# Import the packages we will use\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas\nimport h5py\n\n# The following directive activates inline plotting\n%matplotlib inline\n\nfrom matplotlib.ticker import EngFormatter\nbp_formatter = EngFormatter('b')\n\ndef format_ticks(ax, x=True, y=True, rotate=True):\n    if y:\n        ax.yaxis.set_major_formatter(bp_formatter)\n    if x:\n        ax.xaxis.set_major_formatter(bp_formatter)\n        ax.xaxis.tick_bottom()\n    if rotate:\n        ax.tick_params(axis='x',rotation=45)\n\n\nf, axs = plt.subplots(\n    figsize=(14,4),\n    ncols=3)\n\nax = axs[0]\nim = ax.matshow(np.log1p(c1.matrix(balance=False)[:]), \n                #vmax=2500, \n                cmap='Reds');\nplt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\nax.set_xticks(chromstarts500kb)\nax.set_xticklabels(c1.chromnames, fontsize=6)\nax.set_yticks(chromstarts500kb)\nax.set_yticklabels(c1.chromnames, fontsize=6)\nax.xaxis.tick_bottom()\nax.tick_params(axis='x',rotation=90)\nax.set_title('All data')\n\nax = axs[1]\nim = ax.matshow(\n    np.log1p(clr.matrix(balance=False).fetch('chrX')),\n    cmap='Reds',\n    #vmax=2500,\n    extent=(0,clr.chromsizes['chrX'], clr.chromsizes['chrX'], 0)\n);\nplt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\nax.set_title('chrX', y=1.08)\nax.set_ylabel('position, Mb')\nformat_ticks(ax)\n\nax = axs[2]\nstart, end = 60_000_000, 70_000_000\nregion = ('chrX', start, end)\nim = ax.matshow(\n    np.log1p(c2.matrix(balance=False).fetch(region)),\n    #vmax=2500,\n    cmap='Reds',\n    extent=(start, end, end, start)\n);\nax.set_title(f'chrX:{start:,}-{end:,}', y=1.08)\nplt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\nformat_ticks(ax)\nplt.tight_layout()\n\n\n\n\nRaw matrix. Left: All chromosomes plotted in 100kb bins. Middle: chrX in 100kb bins. Right: chrX:60Mb-70Mb in 50 kb bins",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#balance-the-matrices-iterative-correction",
    "href": "notebooks/02_open2c_framework.html#balance-the-matrices-iterative-correction",
    "title": "Open2C framework",
    "section": "Balance the matrices (iterative correction)",
    "text": "Balance the matrices (iterative correction)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/02_open2c_framework.html#visualize-weights-as-well",
    "href": "notebooks/02_open2c_framework.html#visualize-weights-as-well",
    "title": "Open2C framework",
    "section": "Visualize weights as well",
    "text": "Visualize weights as well\n\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas\nimport h5py\nimport cooltools.lib.plotting\n\n\n# The following directive activates inline plotting\n%matplotlib inline\n\nfrom matplotlib.ticker import EngFormatter\nfrom matplotlib.colors import LogNorm\n\nbp_formatter = EngFormatter('b')\n\ndef format_ticks(ax, x=True, y=True, rotate=True):\n    if y:\n        ax.yaxis.set_major_formatter(bp_formatter)\n    if x:\n        ax.xaxis.set_major_formatter(bp_formatter)\n        ax.xaxis.tick_bottom()\n    if rotate:\n        ax.tick_params(axis='x',rotation=45)\n\n\nimport cooler\n\nc100 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/100000\")\nc50 = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/50000\")\n\n\n%%capture matrix_weights\n\n### plot the raw and corrected data in logscale ###\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# Initialize the plot grid: rows, cols, rel_widths etc.\nplt_width=4\nf, axs = plt.subplots(\n    figsize=( plt_width+plt_width+2, plt_width+plt_width+1),\n    ncols=4,\n    nrows=3,\n    gridspec_kw={'height_ratios':[4,4,1],\"wspace\":0.01,'width_ratios':[1,.05,1,.05]},\n    constrained_layout=True\n)\n\n# Set the colorscale to fit the log scale\nnorm = LogNorm(vmax=0.1)\nnorm_raw = LogNorm(vmin=1, vmax=10_000)\n\n# Set the first cell in the grid\nax = axs[0,0]\nim = ax.matshow(\n    c100.matrix(balance=False).fetch('chrX'),\n    norm=norm_raw,\n    cmap='fall',\n    aspect='auto',\n    extent=(0,c100.chromsizes['chrX'], c100.chromsizes['chrX'], 0)\n);\nax.xaxis.set_visible(False)\nax.set_title('chr X')\nax.set_ylabel('raw', fontsize=16)\nformat_ticks(ax, x=False,y=True)\n\n# Set the colorbar next to the plot\ncax = axs[0,1]\nplt.colorbar(im, cax=cax, label='raw counts')\n\n# Second row, 1st column\nax = axs[1,0]\nim = ax.matshow(\n    c100.matrix().fetch('chrX'),\n    norm=norm,\n    cmap='fall',\n    extent=(0,c100.chromsizes['chrX'], c100.chromsizes['chrX'], 0)\n);\nax.xaxis.set_visible(False)\nax.set_ylabel('balanced', fontsize=16)\nformat_ticks(ax, x=False,y=True)\n\n# Set colorbar\ncax = axs[1,1]\nplt.colorbar(im, cax=cax, label='corrected freqs')\n\n# 3rd row, 1st col (weights)\nax1 = axs[2,0]\nweights = c100.bins().fetch('chrX')['weight'].values\nax1.plot(\n    np.linspace(0, c100.chromsizes['chrX'], len(weights)),\n    weights\n)\nax1.set_xlim([0, c100.chromsizes['chrX']])\nax1.set_xlabel('position, bp')\nformat_ticks(ax1, y=False)\n\nax1 = axs[2,1]\nax1.set_visible(False)\n\n\n# 2nd column\nstart = 60_000_000\nend = 70_000_000\nregion = ('chrX', start, end)\n\n# Unbalanced\nax = axs[0,2]\nim = ax.matshow(\n    c50.matrix(balance=False).fetch(region),\n    norm=norm_raw,\n    cmap='fall',\n    extent=(start, end, end, start)\n);\nax.set_title(f'chrX:{start:,}-{end:,}')\nax.xaxis.set_visible(False)\n\ncax = axs[0,3]\nplt.colorbar(im, cax=cax, label='raw counts');\n\n# Balanced\nax = axs[1,2]\nim = ax.matshow(\n    c50.matrix().fetch(region),\n    norm=norm,\n    cmap='fall',\n    extent=(start, end, end, start)\n);\nax.xaxis.set_visible(False)\n\ncax = axs[1,3]\nplt.colorbar(im, cax=cax, label='corrected frequencies');\n\nax1 = axs[2,2]\nweights = c50.bins().fetch(region)['weight'].values\nax1.plot(\n    np.linspace(start, end, len(weights)),\n    weights\n)\nformat_ticks(ax1, y=False, rotate=False)\nax1.set_xlim(start, end);\nax1.set_xlabel('chrX position, bp')\n\nax1 = axs[2,3]\nax1.set_visible(False)\n\n# NB The output is captured and saved to a callable variable\n\n\nmatrix_weights()\n\n\n\n\nRep1 interaction matrix with weights visualized. Top: raw counts. Bottom: corrected frequencies. Left: whole chrX. Right: chrX60:70Mb\n\n\n\n\n\nCoverage (distinct from the weights)\n\n%%capture matrix_weights_coverage\n\nclr = cooler.Cooler(\"../steps/bwa/PE/pairs/cool/fib_rep1.mcool::resolutions/500000\")\ncis_coverage, tot_coverage = cooltools.coverage(clr, nproc=4)\n\nf, ax = plt.subplots(\n    figsize=(15, 10),\n)\n\nnorm = LogNorm(vmax=0.1)\n\nim = ax.matshow(\n    clr.matrix()[:],\n    norm=norm,\n    cmap='fall'\n);\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\nplt.colorbar(im, cax=cax, label='corrected frequencies');\nax.set_title('full matrix')\nax.xaxis.set_visible(False)\n\nax1 = divider.append_axes(\"bottom\", size=\"25%\", pad=0.1, sharex=ax)\nweights = clr.bins()[:]['weight'].values\nax1.plot( cis_coverage, label='cis')\nax1.plot( tot_coverage, label='total')\nax1.set_xlim([0, len(clr.bins()[:])])\nax1.set_ylabel('Coverage')\nax1.legend()\nax1.set_xticks([])\n\nax2 = divider.append_axes(\"bottom\", size=\"25%\", pad=0.1, sharex=ax)\nax2.plot( cis_coverage/ tot_coverage)\nax2.set_xlim([0, len(clr.bins()[:])])\nax2.set_ylabel('coverage ratio')\n\n# NB plot is captured to variable\n\nINFO:root:creating a Pool of 4 workers\n\n\n\nmatrix_weights_coverage.outputs[1]\n\n\n\n\nRep1 chrX interaction matrix with coverage for cis and total as well as cis/total coverage ratio.\n\n\n\n\n\n\nSmoothing and interpolation\n\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas\nimport h5py\nimport cooltools.lib.plotting\n\n\n# The following directive activates inline plotting\n%matplotlib inline\n\nfrom matplotlib.ticker import EngFormatter\nfrom matplotlib.colors import LogNorm\n\nbp_formatter = EngFormatter('b')\n\ndef format_ticks(ax, x=True, y=True, rotate=True):\n    if y:\n        ax.yaxis.set_major_formatter(bp_formatter)\n    if x:\n        ax.xaxis.set_major_formatter(bp_formatter)\n        ax.xaxis.tick_bottom()\n    if rotate:\n        ax.tick_params(axis='x',rotation=45)\n\n\n%%capture smoothed_interpolated\n\nfrom cooltools.lib.numutils import adaptive_coarsegrain, interp_nan\n\nclr_10kb = c50\n\nstart = 60_000_000\nend = 70_000_000\nregion = ('chrX', start, end)\nextents = (start, end, end, start)\n\ncg = adaptive_coarsegrain(clr_10kb.matrix(balance=True).fetch(region),\n                              clr_10kb.matrix(balance=False).fetch(region),\n                              cutoff=3, max_levels=8)\n\ncgi = interp_nan(cg)\n\nf, axs = plt.subplots(\n    figsize=(18,5),\n    nrows=1,\n    ncols=3,\n    sharex=True, sharey=True)\n\nax = axs[0]\nim = ax.matshow(clr_10kb.matrix(balance=True).fetch(region), cmap='fall', norm=norm, extent=extents)\nax.set_title('corrected')\n\nax = axs[1]\nim2 = ax.matshow(cg, cmap='fall', norm=norm, extent=extents)\nax.set_title(f'adaptively coarsegrained')\n\nax = axs[2]\nim3 = ax.matshow(cgi, cmap='fall', norm=norm, extent=extents)\nax.set_title(f'interpolated')\n\nfor ax in axs:\n    format_ticks(ax, rotate=False)\n\nplt.colorbar(im3, ax=axs, fraction=0.046, label='corrected frequencies')\n\n\nsmoothed_interpolated.outputs[1]\n\n\n\n\nNormal, smoothed, and interpolated views of the interaction matrix. Functions provided by cooltools.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Open2C framework</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html",
    "href": "notebooks/03_compartments.html",
    "title": "Compartments Analysis",
    "section": "",
    "text": "Working with coolers\nIn this notebook, we use files generated by the workflow master_workflow that, in short, does the following:\nWe will:",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html#overview",
    "href": "notebooks/03_compartments.html#overview",
    "title": "Compartments Analysis",
    "section": "Overview",
    "text": "Overview\n\nData (Accessions)\n\n\nTo get an overview of the data accessions used in this analysis, we will first summarize the SRA-runtable.tsv that contains the accession numbers and some metadata for each sample (Table 14.1).\n\n\n\n\n\n\nTable 5.1: The most relevant columns of the SRA-runtable.tsv file\n\n\n\n\n\n\n\n\n \nsource_name\nBioSample\nRun\nGB\nBases\nReads\n\n\n\n\n16\nfibroblast\nSAMN08375237\nSRR6502335\n29.771059\n73,201,141,800\n244,003,806\n\n\n17\nfibroblast\nSAMN08375237\nSRR6502336\n22.755361\n65,119,970,100\n217,066,567\n\n\n18\nfibroblast\nSAMN08375236\nSRR6502337\n21.434722\n52,769,196,300\n175,897,321\n\n\n19\nfibroblast\nSAMN08375236\nSRR6502338\n21.420030\n52,378,949,100\n174,596,497\n\n\n20\nfibroblast\nSAMN08375236\nSRR6502339\n10.207410\n28,885,941,600\n96,286,472\n\n\n9\nfibroblast\nSAMN08375237\nSRR7349189\n52.729173\n139,604,854,200\n465,349,514\n\n\n10\nfibroblast\nSAMN08375236\nSRR7349190\n53.085520\n142,008,353,400\n473,361,178\n\n\n21\npachytene spermatocyte\nSAMN08375234\nSRR6502342\n60.258880\n150,370,993,500\n501,236,645\n\n\n22\npachytene spermatocyte\nSAMN08375234\nSRR6502344\n27.146048\n65,697,684,300\n218,992,281\n\n\n23\npachytene spermatocyte\nSAMN08375234\nSRR6502345\n26.202707\n63,490,538,700\n211,635,129\n\n\n0\npachytene spermatocyte\nSAMN09427370\nSRR7345458\n55.970557\n153,281,577,900\n510,938,593\n\n\n1\npachytene spermatocyte\nSAMN09427370\nSRR7345459\n53.982492\n144,993,841,200\n483,312,804\n\n\n11\npachytene spermatocyte\nSAMN08375235\nSRR7349191\n51.274476\n137,821,979,100\n459,406,597\n\n\n24\nround spermatid\nSAMN08375232\nSRR6502351\n20.924497\n55,095,075,300\n183,650,251\n\n\n25\nround spermatid\nSAMN08375232\nSRR6502352\n41.133960\n115,578,475,800\n385,261,586\n\n\n26\nround spermatid\nSAMN08375232\nSRR6502353\n36.444117\n96,195,161,400\n320,650,538\n\n\n2\nround spermatid\nSAMN09427369\nSRR7345460\n38.244654\n104,105,827,200\n347,019,424\n\n\n3\nround spermatid\nSAMN09427369\nSRR7345461\n53.996261\n144,532,309,500\n481,774,365\n\n\n12\nround spermatid\nSAMN08375232\nSRR7349192\n52.384556\n140,431,608,000\n468,105,360\n\n\n29\nsperm\nSAMN08375229\nSRR6502360\n26.653940\n64,752,370,800\n215,841,236\n\n\n30\nsperm\nSAMN08375228\nSRR6502362\n23.973440\n58,369,232,700\n194,564,109\n\n\n13\nsperm\nSAMN08375229\nSRR7349193\n52.806276\n141,148,572,300\n470,495,241\n\n\n14\nsperm\nSAMN08375229\nSRR7349195\n22.444378\n60,523,788,600\n201,745,962\n\n\n15\nsperm\nSAMN08375229\nSRR7349196\n38.253606\n104,119,671,000\n347,065,570\n\n\n27\nspermatogonia\nSAMN08375231\nSRR6502356\n22.845286\n58,909,579,800\n196,365,266\n\n\n28\nspermatogonia\nSAMN08375231\nSRR6502357\n17.947471\n46,888,332,900\n156,294,443\n\n\n4\nspermatogonia\nSAMN09427379\nSRR7345462\n18.686342\n52,032,780,000\n173,442,600\n\n\n5\nspermatogonia\nSAMN09427379\nSRR7345463\n29.956561\n82,384,836,000\n274,616,120\n\n\n6\nspermatogonia\nSAMN09427379\nSRR7345464\n39.145759\n105,153,716,100\n350,512,387\n\n\n7\nspermatogonia\nSAMN09427378\nSRR7345465\n35.816184\n96,048,594,600\n320,161,982\n\n\n8\nspermatogonia\nSAMN09427378\nSRR7345467\n28.396816\n77,248,140,900\n257,493,803\n\n\n\n\n\n\n\n\n\n\n\n\nTable 5.2: Summary of the data accessions used in this analysis\n\n\n\n\n\n\n\n\n\n\nsource_name\nGB\nBases\nReads\n\n\n\n\n0\nfibroblast\n211.403275\n553,968,406,500\n1,846,561,355\n\n\n1\npachytene spermatocyte\n274.835160\n715,656,614,700\n2,385,522,049\n\n\n2\nround spermatid\n243.128044\n655,938,457,200\n2,186,461,524\n\n\n3\nsperm\n164.131640\n428,913,635,400\n1,429,712,118\n\n\n4\nspermatogonia\n192.794420\n518,665,980,300\n1,728,886,601\n\n\n\n\n\n\n\n\n\n\n\n\nFolder structure\n\n\nFor ease of mind, here is the folder structure of the project. ../steps/bwa/PE/ is the base directory artificially defined in the master_workflow.py. It ccould be any other directory inside steps. It is defined relative to the master_workflow.py file (inside the worklow), and converted to an absolute path by python.\n\n\n\n\n\n\n../steps/bwa/PE\n├── bamfiles\n│   ├── fibroblast\n│   ├── pachytene_spermatocyte\n│   ├── round_spermatid\n│   ├── sperm\n│   └── spermatogonia\n├── cool\n│   ├── fibroblast\n│   ├── pachytene_spermatocyte\n│   ├── round_spermatid\n│   ├── sperm\n│   └── spermatogonia\n└── pairs\n    ├── fibroblast\n    ├── pachytene_spermatocyte\n    ├── round_spermatid\n    ├── sperm\n    └── spermatogonia\n\n18 directories\n\n\n\nFigure 5.1",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html#fullmerge-pool-all-from-each-source_name",
    "href": "notebooks/03_compartments.html#fullmerge-pool-all-from-each-source_name",
    "title": "Compartments Analysis",
    "section": "FullMerge (pool all from each source_name)",
    "text": "FullMerge (pool all from each source_name)\n\n\nWe will use cooler merge to merge all samples in each sub-folder (cell type) to just one interaction matrix for each cell type. The reason for that is that we choose to trust (Wang et al. 2019) when they say that compartments are highly reproducible between replicates, and by merging all replicates, we will have a more robust signal.\nThus, we will merge all samples from the same source_name into a single cooler file. The coolers are produced to only contain the real chromosomes (1-22, X, Y), and not the mitochondrial DNA or the unplaced contigs (~2,900), as they would not bring any information to the analysis.\nOverview of this section:\n\nLocate the coolers (glob –&gt; dictionary)\nMerge the coolers (cooler.merge_coolers)\nZoomify the merged cooler (cooler.zoomify_cooler) to resolutions: 10kb, 50kb, 100kb, 500kb.\nBalance the matrices (!cooler balance) (use the CLI, as it is more easily parallelized)\n\n\n\n\nCreate cooler dictionary (glob)\n\n\nFirst, we will create a dictionary with the paths to the coolers for each sample. We use glob.glob to fetch all the coolers in each sub-folder that remain after filtering and (automatic) quality control (those are the ones with nodups in their names).\n\n\n\nimport glob\nimport os.path as op\nfrom pprint import pprint as pp\nimport pandas as pd\n\n# Get the list of cell type dirs\nbase_dir = '../steps/bwa/PE/cool'\nfolders = glob.glob(op.join(base_dir, '*'))\n\nfiles_dict = {f:glob.glob(f\"{f}/*.nodups.*\") for f in folders}\ncooler_dict = {op.basename(k): [op.basename(f) for f in v] for k,v in files_dict.items()}\n#pp(cooler_dict)\ndf = pd.DataFrame.from_dict(cooler_dict, orient='index').T.fillna('-')\ndf[['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']]\n\n\n\nTable 5.3: Dictionary of coolers for each cell type\n\n\n\n\n\n\n\n\n\n\nfibroblast\nspermatogonia\npachytene_spermatocyte\nround_spermatid\nsperm\n\n\n\n\n0\nSRR6502339.nodups.10000.cool\nSRR6502357.nodups.10000.cool\nSRR7345459.nodups.10000.cool\nSRR7349192.nodups.10000.cool\nSRR7349196.nodups.10000.cool\n\n\n1\nSRR7349190.nodups.10000.cool\nSRR7345467.nodups.10000.cool\nSRR6502344.nodups.10000.cool\nSRR6502353.nodups.10000.cool\nSRR6502362.nodups.10000.cool\n\n\n2\nSRR7349189.nodups.10000.cool\nSRR6502356.nodups.10000.cool\nSRR6502342.nodups.10000.cool\nSRR6502352.nodups.10000.cool\nSRR7349193.nodups.10000.cool\n\n\n3\nSRR6502335.nodups.10000.cool\nSRR7345464.nodups.10000.cool\nSRR7345458.nodups.10000.cool\nSRR6502351.nodups.10000.cool\nSRR6502360.nodups.10000.cool\n\n\n4\nSRR6502338.nodups.10000.cool\nSRR7345462.nodups.10000.cool\nSRR6502345.nodups.10000.cool\nSRR7345460.nodups.10000.cool\nSRR7349195.nodups.10000.cool\n\n\n5\nSRR6502336.nodups.10000.cool\nSRR7345465.nodups.10000.cool\nSRR7349191.nodups.10000.cool\nSRR7345461.nodups.10000.cool\n-\n\n\n6\nSRR6502337.nodups.10000.cool\nSRR7345463.nodups.10000.cool\n-\n-\n-\n\n\n\n\n\n\n\n\n\n\n\n\nMerge coolers\n\n\nThe coolers are merged by summing each bin in the matrices, meaning we can only merge matrices with same dimensions. We iterate through the dictionary and merge the coolers with cooler merge. The mergebuf parameter should be adjusted if you don’t have 32G memory. Default: mergebuf = 20000000. Below, we also check if the output file already exists. If it does, we skip the merge.\n\n\n\n# NB adjust `mergebuf` if you don't have 32G of RAM\n\nimport cooler\n\nfor folder,cooler_list in cooler_dict.items():\n    in_uris = [op.join(base_dir, folder, file) for file in cooler_list]\n    out_uri = op.join(base_dir, folder, f'{folder}.fullmerge.cool')\n\n    if op.exists(out_uri):\n        print(f\"Skipping {out_uri}: exists...\")\n        continue\n\n    print(f\"Creating {out_uri} by \\nMerging {len(cooler_list)} coolers into one:\", end=\" \")\n    print(\"\\t\",[file.split('.')[0] for file in cooler_list])\n    cooler.merge_coolers(output_uri=out_uri,\n                         input_uris=in_uris,\n                         mergebuf=int(5e7),\n                         )\n    print(\"... Done!\")\n\nSkipping ../steps/bwa/PE/cool/round_spermatid/round_spermatid.fullmerge.cool: exists...\nSkipping ../steps/bwa/PE/cool/spermatogonia/spermatogonia.fullmerge.cool: exists...\nSkipping ../steps/bwa/PE/cool/sperm/sperm.fullmerge.cool: exists...\nSkipping ../steps/bwa/PE/cool/fibroblast/fibroblast.fullmerge.cool: exists...\nSkipping ../steps/bwa/PE/cool/pachytene_spermatocyte/pachytene_spermatocyte.fullmerge.cool: exists...\n\n\n\n\nZoomify the merged cooler files\n\n\nAfter merging the coolers, we will zoomify them to resolutions: 10kb, 50kb, 100kb, 500kb. It will recursively create the zoom levels for the cooler file from the ‘base’ resolution (in our case 10kb bins) to the ‘max’ resolution (in our case 500kb bins), and save all zoom levels in a multi-resolution cooler (.mcool) file. The resolutions are stored under the resolutions key in the cooler file (e.g. cell_type.mcool::/resolutions/10000).\nHere, we also check if the output file already exists. If it does, we skip the zoomify. Again, can tailor the chunksize (pixels loaded per process) parameter according to memory availability. I found that the command stalled completely (without quitting) when the memory allocation was not sufficient, as I started out with 32 cores and 32G of RAM. I did not test what was more time-efficient; increasing number of processes or chunksize. After all, it didn’t take long to run anyways.\nFinally, I list the resolutions in the mcool file.\n\n\n\n# NB 8 cores and 32G of RAM was used\n\nimport glob\nimport cooler\nimport os.path as op\n\nbase_dir = '../steps/bwa/PE/cool'\nmerged_coolers = glob.glob(op.join(base_dir, '*/*.fullmerge.cool'))\n\n\nfor clr in merged_coolers:\n    out_uri = clr.replace('.fullmerge.cool', '.mcool')\n    if op.exists(out_uri):\n        print(f\"Skipping {out_uri}: exists...\")\n        continue\n\n    print(f\"Zoomifying cooler: \\n\\t   {clr}\\n\\t-&gt; {out_uri}\", end=\"\")\n    \n    cooler.zoomify_cooler(base_uris = clr,\n                          outfile = out_uri,\n                          resolutions = [10000,50000,100000,500000],\n                          chunksize = 10000000,\n                          nproc = 8)\n    print(\" --&gt; done\")\n\nSkipping ../steps/bwa/PE/cool/round_spermatid/round_spermatid.mcool: exists...\nSkipping ../steps/bwa/PE/cool/spermatogonia/spermatogonia.mcool: exists...\nSkipping ../steps/bwa/PE/cool/sperm/sperm.mcool: exists...\nSkipping ../steps/bwa/PE/cool/fibroblast/fibroblast.mcool: exists...\nSkipping ../steps/bwa/PE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool: exists...\n\n\n\nimport glob\nimport cooler\nmcools = glob.glob(\"../steps/bwa/PE/cool/*/*.mcool\")\n\nfor mcool in mcools:\n    print(f\"{mcool}:\")\n    print(cooler.fileops.list_coolers(mcool))\n    print()\n\n../steps/bwa/PE/cool/round_spermatid/round_spermatid.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/PE/cool/spermatogonia/spermatogonia.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/PE/cool/sperm/sperm.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/PE/cool/fibroblast/fibroblast.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/PE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n\n\n\n\nBalance the matrices\n\n\nFinally, we balance the matrices using the cooler CLI. We use the cooler balance command with the default options using 32 cores, which iteratively balances the matrix (Iterative Corecction). It is first described as a method for bias correction of Hi-C matrices in (Imakaev et al. 2012), where it is paired with eigenvector decomposition (ICE). Here the eigenvector decomposition of the obtained maps is shown to provide insights into local chromatin states.\nAccording to cooler documentation, we have to balance the matrices on each resolution, and thus it cannot be done prior to zoomifying. The argument is that the balancing weights are resolution-specific and will no longer retain its meaning when binned with other weights. Therefore, we use a nested for-loop that iterates through all the .mcools and all the resolutions in each .mcool. cooler balance will create a new column in the bins group of each cooler , weight, which can then be included or not in the downstream analysis. This means we will have access to both the balanced and the unbalanced matrix.\nThe default mode uses genome-wide data to calculate the weights for each bin. It would maybe be more suitable to calculate the weights for cis contacts only, and that is possible through the --cis-only flag, and that can be added to another column, so that we can compare the difference between the two methods easily. However, we will only use the default mode for now. The default options are:\n\nignore-diags: 2 (ignore the diagonals (-1,0,1))\nmad-max: 5 (median absolute deviation threshold)\nmin-nnz: 10 (minimum number of non-zero entries before exclusion)\n\nConveniently, cooler balance automatically checks if there is already a weight column, and skips the balancing if it already exists. We can overwrite with --force.\n\n\n\n%%capture balance_out --no-stderr\n\nimport sys\nimport glob\n\nmcools = glob.glob(\"../steps/bwa/PE/cool/*/*.mcool\")\nresolutions = [10000, 50000, 100000, 500000]\n\nfor mcool in mcools:\n    print(f\"Balancing {mcool}:\", file=sys.stderr)\n    for res in resolutions:\n        full_name = f\"{mcool}::resolutions/{res}\"\n        print(f\"\\tresolution {res}...\", end=\" \", file=sys.stderr)\n        # First, just default values\n        !cooler balance -p 32 {full_name}\n        # With only cis-contacts, save column seprately in the cooler file\n        #!cooler balance -p 32 -c 20000000 --cis-only -n cis_weights {full_name}\n        print(\"--&gt; Done!\", file=sys.stderr)\n\nBalancing ../steps/bwa/PE/cool/round_spermatid/round_spermatid.mcool:\n    resolution 10000... --&gt; Done!\n    resolution 50000... --&gt; Done!\n    resolution 100000... --&gt; Done!\n    resolution 500000... --&gt; Done!\nBalancing ../steps/bwa/PE/cool/spermatogonia/spermatogonia.mcool:\n    resolution 10000... --&gt; Done!\n    resolution 50000... --&gt; Done!\n    resolution 100000... --&gt; Done!\n    resolution 500000... --&gt; Done!\nBalancing ../steps/bwa/PE/cool/sperm/sperm.mcool:\n    resolution 10000... --&gt; Done!\n    resolution 50000... --&gt; Done!\n    resolution 100000... --&gt; Done!\n    resolution 500000... --&gt; Done!\nBalancing ../steps/bwa/PE/cool/fibroblast/fibroblast.mcool:\n    resolution 10000... --&gt; Done!\n    resolution 50000... --&gt; Done!\n    resolution 100000... --&gt; Done!\n    resolution 500000... --&gt; Done!\nBalancing ../steps/bwa/PE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool:\n    resolution 10000... --&gt; Done!\n    resolution 50000... --&gt; Done!\n    resolution 100000... --&gt; Done!\n    resolution 500000... --&gt; Done!\n\n\n\n# Display the balancing stdout if you want (but it is up to 200 lines per cooler)\n#balance_out()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html#repmerge-pool-all-from-each-biosample-id",
    "href": "notebooks/03_compartments.html#repmerge-pool-all-from-each-biosample-id",
    "title": "Compartments Analysis",
    "section": "RepMerge (pool all from each BioSample ID)",
    "text": "RepMerge (pool all from each BioSample ID)\n\n\nInitially, I planned to re-create the replicates that they used in the paper, but I reason that it is not necessary and might even be better to pool all the samples in stead. They state alredy that their compartments are highly repdoducible between replicates, so I choose to trust that and not bother with the replicates.\nTherefore, this section was only briefly initialized, and now it is commented out.\n\n\n\n#df.groupby(['source_name','BioSample'])['Reads'].sum()\n\n\n# from pprintpp import pprint as pp\n\n# grouped_df = df.groupby(['source_name','BioSample'])\n\n# # Initialize an empty dictionary\n# rep_dict = {}\n\n# # Iterate over each group\n# for (source_name, BioSample), group in grouped_df:\n#     # Extract the 'Run' column and convert it to a list\n#     run_list = group['Run'].tolist()\n    \n#     # Populate the nested dictionary\n#     if source_name not in rep_dict:\n#         rep_dict[source_name] = {}\n#     rep_dict[source_name][BioSample] = run_list\n\n# pp(rep_dict)\n\n\n# for source_name, BioSample_dict in rep_dict.items():\n#     print(f\"source_name: {source_name}\")\n#     print(f\"Changing working dir: {source_name}/\")\n#     for BioSample, run_list in BioSample_dict.items():\n#         print(f\"Merging samples for BioSample: {BioSample}: {run_list}\")",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html#kb-resolution",
    "href": "notebooks/03_compartments.html#kb-resolution",
    "title": "Compartments Analysis",
    "section": "500kb resolution",
    "text": "500kb resolution\n\nExample with a single sample\n\n\nFirst, I will explore the visualization pipeline for a single cooler at 500kb resolution. I will modify the plot to be ‘stairs’ in stead of just a regular line plot, as it is both a more accurate representation of the data and it is more aesthetically pleasing with less spiky lines and holes.\nIn practice, the length of the dataframe is doubled, as it now contains an E1 value for both the start and end position for each bin in stead of only for the start. However, I first make the regular line plot to show the difference.\n\n\n\nImports\n\n# import standard python libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nimport os, subprocess\n\n\n# Import python package for working with cooler files and tools for analysis\nimport cooler\nimport cooltools.lib.plotting\nimport cooltools\n\n\n\nLoad cooler\n\nmclr = \"../steps/bwa/PE/cool/fibroblast/fibroblast.mcool\"\n\nclr = cooler.Cooler(f\"{mclr}::resolutions/500000\")\n\n\n\nCalculate gc covariance (from the reference genome)\n\n\nI will use bioframe to load the reference and calculate the GC content of each bin in the cooler file. The convention in Hi-C is to use GC content as a phasing track to orient eigenvector track to positively correlated with the GC content. In this subsection, I calculate the GC content for all chromosomes and filter afterwards to only include the ‘X’ chromosome. I will do that smarter in the next subsection.\n\n\n\nimport bioframe\nimport os\n\nbins = clr.bins()[:]\nrheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\ngc_cov_csv = '../steps/rheMac10_gc_cov_500kb.tsv'\nif not os.path.exists(gc_cov_csv):\n    print('Calculate the fraction of GC basepairs for each bin')\n    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n    gc_cov.to_csv(gc_cov_csv, index=False, sep='\\t')\n    display(gc_cov)\nelse: \n    print(\"Already exists, just read from file:\")\n    gc_cov = pd.read_csv(gc_cov_csv, sep='\\t')\n    display(gc_cov)\n\nAlready exists, just read from file:\n\n\n\n\n\n\n\n\n\nchrom\nstart\nend\nGC\n\n\n\n\n0\nchr1\n0\n500000\n0.424508\n\n\n1\nchr1\n500000\n1000000\n0.378836\n\n\n2\nchr1\n1000000\n1500000\n0.388272\n\n\n3\nchr1\n1500000\n2000000\n0.445226\n\n\n4\nchr1\n2000000\n2500000\n0.439485\n\n\n...\n...\n...\n...\n...\n\n\n5715\nchrY\n9500000\n10000000\n0.399518\n\n\n5716\nchrY\n10000000\n10500000\n0.396028\n\n\n5717\nchrY\n10500000\n11000000\n0.395280\n\n\n5718\nchrY\n11000000\n11500000\n0.382006\n\n\n5719\nchrY\n11500000\n11753682\nNaN\n\n\n\n\n5720 rows × 4 columns\n\n\n\n\n\nCalculate the E1 compartments\n\n\nHere, I will calculate the E1 compartments for the ‘X’ chromosome in the fibroblast cooler at 500kb resolution. I will use the cooltools package to do eigendecomposition and calculate the E1 compartments. I use the GC content (gc_cov obtained above) as a phasing track.\nI will only calculate the within-chromosomes compartmentalization (cis contacts). I use cooltools.eigs_cis that decorrelate the contact-frequency by distance before performing the eigendecomposition.\nI this example, I will use the simplest ‘view’ (chromosome-wide) of the chromosome to calculate the E1 values, but later I will explore how partitioning the chromosome affects the E1 values. As the GC content was calculated for all chromosomes, the eigenvectors are also calculated for the whole matrix. This will also be optimized in the next subsection, as we only ever look at the ‘X’ chromosome.\n\n\n\n# Make the full view frame\nview_df = pd.DataFrame(\n    {\n    'chrom': clr.chromnames,\n    'start': 0,\n    'end': clr.chromsizes.values,\n    'name': clr.chromnames\n    }\n                      )\n#display(view_df)\n\n\n# obtain first 3 eigenvectors\ncis_eigs = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df,\n                        n_eigs=3,\n                        )\n\n# cis_eigs[0] returns eigenvalues, here we focus on eigenvectors\neigenvector_track = cis_eigs[1][['chrom','start','end','E1']]\nlen(eigenvector_track)\n\n5720\n\n\n\n# full track\neigenvector_track\n\n\n\n\n\n\n\n\nchrom\nstart\nend\nE1\n\n\n\n\n0\nchr1\n0\n500000\n-0.756052\n\n\n1\nchr1\n500000\n1000000\n-1.001063\n\n\n2\nchr1\n1000000\n1500000\n-0.928042\n\n\n3\nchr1\n1500000\n2000000\n-0.507579\n\n\n4\nchr1\n2000000\n2500000\n0.123708\n\n\n...\n...\n...\n...\n...\n\n\n5715\nchrY\n9500000\n10000000\n-0.499798\n\n\n5716\nchrY\n10000000\n10500000\n-0.588820\n\n\n5717\nchrY\n10500000\n11000000\n-0.988677\n\n\n5718\nchrY\n11000000\n11500000\n-0.566585\n\n\n5719\nchrY\n11500000\n11753682\nNaN\n\n\n\n\n5720 rows × 4 columns\n\n\n\n\n\nAs I have made myself a detour and calculated the eigenvectors for all chromosomes, I will now filter the eigenvector track to only include the ‘X’ chromosome. Then, I will (in the name of explicitness) construct an array of all the indices where the E1 values change sign. This is the simplest way to save the coordinates of the compartment boundaries. It can later on be saved to .csv or whatever for comparison between different samples. Also, it will be simplified in the next subsection.\n\n\n\n# subset the chrX   \neigenvector_track_chrX = eigenvector_track.loc[eigenvector_track['chrom'] == 'chrX']\nnbins = len(eigenvector_track_chrX)\neigenvector_track_chrX\ne1X_values = eigenvector_track_chrX['E1'].values\n\n\n# Where does the E1 change sign\nnp.where(np.diff( (cis_eigs[1][cis_eigs[1]['chrom']=='chrX']['E1']&gt;0).astype(int)))[0]\n\narray([  1,   6,  16,  26,  29,  40,  42,  49,  54,  55,  59,  60,  61,\n        62,  74,  83,  86, 101, 102, 103, 104, 108, 123, 124, 129, 138,\n       141, 142, 147, 149, 185, 188, 194, 196, 197, 201, 206, 209, 211,\n       215, 222, 224, 228, 233, 238, 240, 250, 253, 256, 265, 273, 274,\n       288, 289, 290, 293, 296, 302])\n\n\n\n\nPlot E1 and matrix\n\n\nFinally, I will plot the matrix, the GC content, and the E1 compartments for the ‘X’ chromosome in the fibroblast cooler at 500kb resolution. I will use the cooltools package to plot the matrix and the compartments. I will use the matplotlib package to plot the GC content.\nI will plot the matrix as a heatmap, the GC content as a line plot, and the E1 compartments as a line plot. I will also plot the compartment boundaries as vertical lines. The compartments are colored according to the sign of the E1 values.\nFollowing the cooltools recommendation, the colorbar itself will be log-transformed, as otherwise the balanced interaction matrix (values from 0 to 1) will be hard to interpret. The E1 values are (as is the colorbar) added to the axis with an AxesDivider.append_axes object to make them match the axes of the matrix.\nI’m testing out the %%capture magic to capture the plot to a variable, then displaying it in the next cell. Initially, the plot took a while to generate, and I wanted to avoid re-generating when adjusting graphics on cell level with the YAML options. Now it is not necessary, but I keep it for the sake of the example.\n\n\n\n%%capture chrX_matrix_e1_500kb\n\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nf, ax = plt.subplots(\n    figsize=(15, 10),\n)\n\nnorm = LogNorm(vmax=0.1)\n\nim = ax.matshow(\n    clr.matrix().fetch('chrX'),\n    norm=norm,\n    cmap='fall',\n);\nplt.axis([0,nbins,nbins,0])\n\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\nplt.colorbar(im, cax=cax, label='corrected frequencies');\nax.set_ylabel('chrX:500kb bins, #bin')\nax.xaxis.set_visible(False)\n\nax1 = divider.append_axes(\"top\", size=\"20%\", pad=0.05, sharex=ax)\n#weights = clr.bins()[:]['weight'].values\n#ax1.plot([0,nbins],[0,0],'k',lw=0.25)\n\n#ax1.plot(e1X_values, label='E1')\n\n# Fill between the line and 0\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &gt; 0), color='tab:red')\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &lt; 0), color='tab:blue')\n\nax1.set_ylabel('E1')\nax1.set_xticks([]);\nax1.get_subplotspec()\n\n\nfor i in np.where(np.diff( (cis_eigs[1][cis_eigs[1]['chrom']=='chrX']['E1']&gt;0).astype(int)))[0]:\n    # Horisontal lines where E1 intersects 0\n    ax.plot([0,nbins],[i,i],'k',lw=0.4)\n\n    # Vertical lines where E1 intersects 0\n    ax.plot([i,i],[0,nbins],'k',lw=0.4)\n\n\nchrX_matrix_e1_500kb.outputs[0]\n\n\n\n\n\n\n\nFigure 6.1: chrX interaction matrix with E1 eigenvector values in 500kb resolution. The sign change of the E1 is overlayed as thin black lines, making it more easily interpretable. We should qualitatively determine how well the E1 values capture the plaid pattern in the matrix.\n\n\n\n\n\nMarkdown: Figure 12.2\n\n\nWe observe that the E1 values only somewhat captures the plaid pattern in the matrix Figure 12.2, but it is not related to the size of the compartments, as both small and large compartments can be observed. The B-compartment that starts from around bin 150 (75.000.000 bp) seems to have squares that are not captured by the E1 values. Maybe it could be captures by TAD calling, but that is not the scope of this analysis.\n\n\n\nimport matplotlib.pyplot as plt\n\nf, ax1 = plt.subplots(\n    figsize=(10, 2),\n)\n\n# Fill between the line and 0\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &gt; 0), color='tab:red')\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &lt; 0), color='tab:blue')\n\n#ax1.set_ylabel('E1')\nax1.set_xticks([])\nax1.set_yticks([])\n\n# Remove borders\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\nax1.spines['left'].set_visible(False)\nax1.spines['bottom'].set_visible(False)\n\nplt.tight_layout()\n\n# Save the plot as a SVG file\n#plt.savefig('e1_plot.svg', bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 6.2: 500kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.\n\n\n\n\n\nMarkdown the next plot: Figure 9.3 that is\n\n\nStairs plot of the E1 compartments\n(Less spiky, more smooth)\n\nimport matplotlib.pyplot as plt\n\nf, (ax1, ax2) = plt.subplots(2,1,\n    figsize=(10, 4)\n)\n\nchrom_start = eigenvector_track_chrX['start'].values\nwindow_size = chrom_start[1] - chrom_start[0]\n\n# Fill between the line and 0\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &gt; 0), color='tab:red')\nax1.fill_between(range(len(e1X_values)), e1X_values, 0, where=(e1X_values &lt; 0), color='tab:blue')\n\n# Create stairs\nx = np.zeros(2*chrom_start.size)\ny = np.zeros(2*chrom_start.size)\nx[0::2] = chrom_start\nx[1::2] = chrom_start + window_size\ny[0::2] = e1X_values\ny[1::2] = e1X_values\n\n# Layout\nax1.set_ylabel('Spiky E1')\nax2.set_ylabel('Stairs E1')\nax1.set_xticks([])\nax1.set_yticks([])\nax2.set_xticks([])\nax2.set_yticks([])\nax2.set_ylim(-1, 1)\n\n# Remove borders\nax1.spines[:].set_visible(False)\nax2.spines[:].set_visible(False)\n\nax2.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\nax2.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n\nplt.tight_layout()\n# Save the plot as a high-resolution PNG file\n#plt.savefig('../steps/e1_plot.png', dpi=320, bbox_inches='tight')\n\n\n\n\n\n500kb binned E1 eigenvector values for chrX.\n\n\n\n\n\n\n\nAll 5 full merges\n\nLoad coolers\n\nimport glob\nimport os.path as op\nimport cooler\n\nmcools = glob.glob(\"../steps/bwa/PE/cool/*/*.mcool\")\nres = \"::resolutions/500000\"\n\nclrs = {op.basename(op.dirname(mcool)): cooler.Cooler(mcool+res) for mcool in mcools}\n\nchron_order = ['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']\n\nclrs = {key: clrs[key] for key in chron_order}\nclrs\n\n{'fibroblast': &lt;Cooler \"fibroblast.mcool::/resolutions/500000\"&gt;,\n 'spermatogonia': &lt;Cooler \"spermatogonia.mcool::/resolutions/500000\"&gt;,\n 'pachytene_spermatocyte': &lt;Cooler \"pachytene_spermatocyte.mcool::/resolutions/500000\"&gt;,\n 'round_spermatid': &lt;Cooler \"round_spermatid.mcool::/resolutions/500000\"&gt;,\n 'sperm': &lt;Cooler \"sperm.mcool::/resolutions/500000\"&gt;}\n\n\n\n\nCalculate gc covariance (from the reference genome)\nDo this with any of the clrs - it just needs the bins positions.\n\n# Try with only the gc_cov for chrX\n\nimport bioframe\nimport pandas as pd\nimport os.path as op\n\nbins = clrs['fibroblast'].bins().fetch('chrX')[:]\nout_name = '../steps/rheMac10_gc_cov_X_500kb.tsv'\n\nrheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\nif not op.exists(out_name):\n    print('Calculate the fraction of GC basepairs for each bin')\n    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n    gc_cov.to_csv(out_name, index=False,sep='\\t')\n    print(gc_cov.info())\nelse: \n    print(\"Already exists, read from file\")\n    gc_cov = pd.read_csv(out_name, sep='\\t')\n    print(gc_cov.info())\n\nAlready exists, read from file\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 307 entries, 0 to 306\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   chrom   307 non-null    object \n 1   start   307 non-null    int64  \n 2   end     307 non-null    int64  \n 3   GC      307 non-null    float64\ndtypes: float64(1), int64(2), object(1)\nmemory usage: 9.7+ KB\nNone\n\n\n\n\nCalculate the E1 compartments\nLoop: view_df, cis_eigs, e1_values\n\nPlot GC covariance\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(\n    figsize=(10, 2),\n)\n\nax.plot(gc_cov['start'],gc_cov['GC'])\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nChromosome restricted E1 compartments\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\nimport pandas as pd\n\neigs_full = {}\ne1_values_full = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Divide into chromosome arms\nclr = clrs['fibroblast']\nview_df_full = pd.DataFrame(\n    {\n    'chrom': 'chrX',\n    'start': 0,\n    'end': chrX_size,\n    'name': 'chrX'\n    }, index=[0]\n                      )\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}, size {clr.binsize}\")\n    cis_eigs_full = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df_full,\n                        n_eigs=3,\n                        )\n    eigs_full[name] = cis_eigs_full[1]\n    e1_track_full = cis_eigs_full[1][['chrom','start','end','E1']]\n    e1_values_full[name] = e1_track_full['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nChromosome arms restricted\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\nimport pandas as pd\n\neigs = {}\ne1_values = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Divide into chromosome arms\nview_df = pd.DataFrame(\n    {\n    'chrom': 'chrX',\n    'start': [0, 59_000_001],\n    'end': [59_000_000, chrX_size],\n    'name': ['X_short', 'X_long']\n    }, index=[0,1]\n                      )\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}\")\n    cis_eigs = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df,\n                        n_eigs=3,\n                        )\n    eigs[name] = cis_eigs[1]\n    e1_track = cis_eigs[1][['chrom','start','end','E1']]\n    e1_values[name] = e1_track['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast\nCalculating eigenvectors for spermatogonia\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte\nCalculating eigenvectors for round_spermatid\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nRefined: 10Mb windows restricted\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\n\neigs_10mb = {}\ne1_values_10mb = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Calculate in 1Mb windows\n# Define the window size (1Mb)\n\nwindow_size = 10_000_000\n\n# Generate the start and end positions for each window\nstart_positions = list(range(0, chrX_size, window_size))\nend_positions = [min(start + window_size, chrX_size) for start in start_positions]\n# Create the DataFrame\nview_df_10mb = pd.DataFrame({\n    'chrom': ['chrX'] * len(start_positions),\n    'start': start_positions,\n    'end': end_positions,\n    'name': [f'X_{i}' for i in range(len(start_positions))]\n})\n#display(view_df)\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}\")\n    cis_eigs_10mb = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df_10mb,\n                        n_eigs=3,\n                        )\n    eigs_10mb[name] = cis_eigs_10mb[1]\n    e1_track_10mb = cis_eigs_10mb[1][['chrom','start','end','E1']]\n    e1_values_10mb[name] = e1_track_10mb['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nSave the A compartment coordinates\n\n### Just testing for a single sample\n\n# import numpy as np\n# import pandas as pd\n\n# e1 = pd.Series(e1_values_full['sperm'])\n# res = 500_000\n\n# e1_filled = e1.ffill(limit=2,limit_area='inside')\n\n# # Type is preserved for boolean arrays, so the result will contain \n# # False when consecutive elements are the same and True when they differ.\n# # We then use np.where to get the indices where the values change sign\n# sign_change_coords = np.where(np.diff((e1_filled &gt; 0).astype(int)))[0]\n# # Filter out the indices that point to a NaN value\n# sign_change_coords = sign_change_coords[~e1_filled.isna().iloc[sign_change_coords].values]\n\n# a_start_bin = sign_change_coords[e1_filled[sign_change_coords+1] &gt; 0]\n# a_end_bin = sign_change_coords[e1_filled[sign_change_coords] &gt; 0]\n\n# # if a_start_bin[0] &gt; b_start_bin[0]:\n# #     a_start_bin = np.insert(a_start_bin, 0, 0)\n# #     b_start_bin = np.insert(b_start_bin, len(b_start_bin), len(e1))\n\n\n# display(sign_change_coords)\n# print(f\"A compartment start {len(a_start_bin)}:\", a_start_bin)\n# print(f\"A compartment end {len(a_end_bin)}:\", a_end_bin)\n\n# display(e1_filled[:20])\n\n\n\n\nThis is copied to hicstuff.py as a function for later import\n\n# ###### Restriction: full chromosome E1 values #######\n\n# import pandas as pd\n# import numpy as np\n# import os.path as op\n\n# for name,e1 in e1_values_full.items():\n#     e1 = pd.Series(e1)\n#     e1_filled = e1.ffill(limit=2)\n#     sign_change_coords = np.where(np.diff((e1_filled &gt; 0).astype(int)))[0]\n\n#     a_start_bin = sign_change_coords[e1_filled[sign_change_coords+1] &gt; 0]\n#     a_end_bin = sign_change_coords[e1_filled[sign_change_coords] &gt; 0]\n\n#     print(f\"Calculating A-compartment intervals for {name}\")\n#     print(len(a_start_bin), len(a_end_bin))\n\n#     if e1_filled.iloc[-1] &gt; 0:\n#         print(\"Last bin is A, appending end bin\")\n#         a_end_bin = np.append(a_end_bin, len(e1_filled)-1)\n#         print(len(a_start_bin), len(a_end_bin))\n    \n#     df = pd.DataFrame({\n#         'chrom': ['chrX'] * len(a_start_bin),\n#         'bin_start': a_start_bin,\n#         'bin_end': a_end_bin,\n#         'start': a_start_bin*res,\n#         'end': a_end_bin*res,\n#         'length': (a_end_bin-a_start_bin)*res\n#     })\n#     csv_name = f'../results/{name}_a_comp_coords_{int(res*0.001)}kb_full.csv'\n#     print(csv_name)\n#     if not op.exists(csv_name):\n#         df[['chrom', 'start', 'end']].to_csv(csv_name, index=False)\n#     else:\n#         print(\"Already exists, skipping\")\n#     print()\n\n\n\n######## Restriction: chromosome arm E1 values ########\nimport importlib\nimport hicstuff\nimport os\nimportlib.reload(hicstuff)\nfrom hicstuff import extract_a_coordinates\n\n\n# Binsize in bp\nres = 500_000\noutdir = '../results/compartments/'\nif not os.path.exists(outdir):\n    os.makedirs(outdir)\n    \n\n######## Restriction: full chromosome E1 values ########\nrestriction = 'full'\nfor name, e1 in e1_values_full.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\n######## Restriction: chromosome arm E1 values ########\nrestriction = 'arms'\nfor name, e1 in e1_values.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\n######## Restriction: 10Mb E1 values ########\nrestriction = '10Mb'\nfor name, e1 in e1_values_10mb.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_500kb_full.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_500kb_full.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_500kb_full.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_500kb_full.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_500kb_full.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_500kb_arms.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_500kb_arms.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_500kb_arms.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_500kb_arms.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_500kb_arms.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_500kb_10Mb.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_500kb_10Mb.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_500kb_10Mb.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_500kb_10Mb.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_500kb_10Mb.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\n\n\n\n\nPlot NaN histogram\n\n# Check the number of NaN values in the E1 column\nimport numpy as np\n\n# Check the number of NaN values in the E1 column and create a DataFrame\nnan_counts = {k: {'length': len(v), 'NaNs': np.isnan(v).sum()} for k, v in e1_values.items()}\n#display(pd.DataFrame.from_dict(nan_counts, orient='index'))\n\n# Locate the NaN values (histogram)\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(1, 5, figsize=(20,2))\nfor i, (name, track) in enumerate(eigs.items()):\n    e1 = track['E1'].values\n    # Locate NaN values\n    e1_nan = np.where(np.isnan(e1))\n    # Plot histogram\n    ax[i].hist(e1_nan, bins=100)\n    \n    # Plot median line\n    median_pos = np.median(e1_nan)\n    ax[i].axvline(median_pos, color='r')\n\n    # Layout\n    ax[i].set_title(name)\n    xticks = np.linspace(0, len(e1), num=5)\n    xticks = np.append(xticks, median_pos)  # Add median position to xticks\n    ax[i].set_xticks(xticks)\n    xticklabels = np.linspace(0, len(e1) * 0.5, num=5, dtype = 'int').tolist()\n    xticklabels.append(median_pos*0.5)  # Add median label\n    ax[i].set_xticklabels(xticklabels, rotation=45)\n    ax[i].set_xlabel('Position (Mbp)')\n                     \n\n\n\n\nHistogram of NaN values in the E1 eigenvector for each cell type.\n\n\n\n\n\n\n\nPlot the E1 compartments\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.patches import Rectangle\n\nres = 500_000\nnames_abbr = {'fibroblast': 'Fibroblast', 'spermatogonia': 'Spermatogonia', 'pachytene_spermatocyte': 'Pachytene Spermatogonia', 'round_spermatid': 'Round Spermatid', 'sperm': 'Sperm'}\n\nchrom_start = e1_track_full['start'].values\nchrom_end = e1_track_full['end'].values-1\n\nf, axs = plt.subplots(5, 3, figsize=(18, 8), sharex=True, sharey=True)\n\n# Populate the first column\naxs[0,0].set_title('E1: Full-chromosome restricted')\nfor i, (name, e1) in enumerate(e1_values_full.items()):\n    ax = axs[i,0]\n    ax.set_ylabel(names_abbr[name])\n\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', linewidth=0)\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', linewidth=0)\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_full.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Populate the second column\naxs[0,1].set_title('E1: Chromosome-arms restricted')\nfor i, (name, e1) in enumerate(e1_values.items()):\n    ax = axs[i,1]\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', linewidth=0)\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', linewidth=0)\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_arms.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Populate the third column\naxs[0,2].set_title('E1: 10Mb restricted (refined)')\nfor i, (name, e1) in enumerate(e1_values_10mb.items()):\n    ax = axs[i,2]\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', linewidth=0)\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', linewidth=0)\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_10Mb.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Set y-limits for all subplots\nfor ax in axs.flat:\n    ax.set_ylim(-0.8, 0.8)\n    ax.spines[:].set_visible(False)\n    ax.set_yticks([])\n    ax.set_xticks([])\n\nplt.tight_layout()\nplt.savefig('../steps/e1_plot_full.svg', bbox_inches='tight')\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution. Left: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.\n\n\n\n\n\n\nPlot matrices with compartments (round spermatid)\n\nimport cooltools.lib.plotting\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom cooltools.lib.numutils import adaptive_coarsegrain, interp_nan\n\n\n\nclr = clrs['round_spermatid']\nchrom_start, chrom_end = e1_track_full['start'].values, e1_track_full['end'].values-1\ne1 = e1_values_10mb['round_spermatid']\nnbins = len(clr.bins().fetch('chrX'))\n\nf, ax = plt.subplots(\n    figsize=(9,6),\n)\n\nnorm = LogNorm(vmax=0.1)\n\n\ne1_list = [e1_values_10mb['round_spermatid'], e1_values['round_spermatid'], e1_values_full['round_spermatid']]\ne1_names = ['10Mb', 'Arms', 'Full']\ncolors = ['tab:red', 'tab:blue', 'tab:green']\n\n\n\nim = ax.matshow(\n    clr.matrix().fetch('chrX'),\n    norm=norm,\n    cmap='fall',\n);\nplt.axis([0,nbins,nbins,0])\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nplt.colorbar(im, cax=cax, label='corrected frequencies');\nax.set_ylabel('chrX:500kb bins, #bin')\nax.xaxis.set_visible(False)\n\nfor i, e1 in enumerate(e1_list):\n    ax1 = divider.append_axes(\"top\", size=\"10%\", pad=0.05, sharex = ax)\n    # weights = clr.bins()[:]['weight'].values\n\n    # ax1.plot(e1, label='E1')\n\n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    #smooth_y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start/500_000\n    x[1::2] = chrom_end/500_000\n    y[0::2] = e1\n    y[1::2] = e1\n    # smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n    # smooth_y[0::2] = smooth_e1\n    # smooth_y[1::2] = smooth_e1\n\n\n    ax1.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\n    ax1.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n\n    ax1.set_ylabel(e1_names[i], rotation=70)\n    ax1.set_ylim(-0.8, 0.8)\n    ax1.set_xticks([])\n\nax1.set_title('Round Spermatid: 500kb bins')\n\n\n#    # Plot the sign changes on the matrix \n#     col = colors[i]\n#     for i in np.where(np.diff( (pd.Series(e1)&gt;0).astype(int)))[0]:\n#         # Horisontal lines where E1 intersects 0\n#         ax.plot([0,nbins],[i,i],col,lw=0.5)\n\n#         # Vertical lines where E1 intersects 0\n#         ax.plot([i,i],[0,nbins],col,lw=0.5)\n\nplt.tight_layout()\nf.canvas.draw()\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution for round spermatid, as well as the interaction matrix. E1 was restricted to top: Full-chromosome, middle: Chromosome-arms, bottom: 10Mb window.\n\n\n\n\n\n\nSliding window summed E1 compartments\nTo mimic the smoothing applied in the Wang et al. 2019 paper, where they slide a 400kb window in 100kb steps on the obs/exp matrix, we will similarly slide a 400kb window in 100kb steps directly on the E1 compartments.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport pandas as pd\nfrom scipy.signal.windows import triang\n\nresolution = 500_000\nwindow_size = 2_500_000\nstep_size = window_size // resolution\n\nchrom_start = e1_track['start'].values\nchrom_end = e1_track['end'].values-1\n\nf, axs = plt.subplots(5, 2, figsize=(30, 10), sharex=True)\n\naxs[0, 0].set_title('Chromosome-arm E1 (arm restricted)')\naxs[0, 1].set_title('Smoothed by summation')\n\nfor i, (name, e1) in enumerate(e1_values.items()):\n    # print(i, name, e1.size)\n    smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))\n\n    ax0 = axs[i, 0]\n    ax1 = axs[i, 1]\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    smooth_y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n    smooth_y[0::2] = smooth_e1['value'].values\n    smooth_y[1::2] = smooth_e1['value'].values\n\n\n    ax0.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\n    ax0.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n    \n    # Overlay the smoothed line (divided by 5 to make it a mean)\n    ax0.plot(x, smooth_y/5, color='C1')\n\n    ax1.fill_between(x, smooth_y, 0, where=(smooth_y &gt; 0), color='tab:red')\n    ax1.fill_between(x, smooth_y, 0, where=(smooth_y &lt; 0), color='tab:blue')\n\n    ax0.set_ylabel(name)\n    ylim = 1.5\n    #ax0.set_ylim(-ylim, ylim)\n    #ax1.set_ylim(-ylim*4, ylim*4)\n\nfor ax in axs.flat:\n    ax.spines[:].set_visible(False)\n    ax.set_xticks([])\n    #ax.set_yticks([])\n\n# plt.tight_layout()\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution with rolling summation, with window size 2.5Mb, step size 500Kb: Each value is now the sum of the surrounding n=5 bins.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/03_compartments.html#kb-resolution-1",
    "href": "notebooks/03_compartments.html#kb-resolution-1",
    "title": "Compartments Analysis",
    "section": "100kb resolution",
    "text": "100kb resolution\n\nAll 5 full merges\n\nLoad coolers\n\nimport glob\nimport os.path as op\nimport cooler\n\nmcools = glob.glob(\"../steps/bwa/PE/cool/*/*.mcool\")\nres = \"::resolutions/100000\"\n\nclrs = {op.basename(op.dirname(mcool)): cooler.Cooler(mcool+res) for mcool in mcools}\n\nchron_order = ['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']\n\nclrs = {key: clrs[key] for key in chron_order}\nclrs\n\nnames_abbr = {'fibroblast': 'Fibroblast', 'spermatogonia': 'Spermatogonia', 'pachytene_spermatocyte': 'Pachytene Spermatogonia', 'round_spermatid': 'Round Spermatid', 'sperm': 'Sperm'}\n\n# Calculate chromstart and chromend for each bin on chrX\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\nchrom_start = clrs['fibroblast'].bins().fetch('chrX')['start'].values\nchrom_end = clrs['fibroblast'].bins().fetch('chrX')['end'].values-1\nnbins = len(clrs['fibroblast'].bins().fetch('chrX'))\nbinsize = clrs['fibroblast'].binsize\n\n\n\nCalculate gc covariance (from the reference genome)\nDo this with any of the clrs - it just needs the bins positions.\n\n# Try with only the gc_cov for chrX\n\nimport bioframe\nimport pandas as pd\nimport os.path as op\n\nbins = clrs['fibroblast'].bins().fetch('chrX')[:]\nout_name = '../steps/rheMac10_gc_cov_X_100kb.tsv'\n\nrheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\nif not op.exists(out_name):\n    print('Calculate the fraction of GC basepairs for each bin')\n    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n    gc_cov.to_csv(out_name, index=False,sep='\\t')\n    print(gc_cov.info())\nelse: \n    print(\"Already exists, read from file\")\n    gc_cov = pd.read_csv(out_name, sep='\\t')\n    print(gc_cov.info())\n\nAlready exists, read from file\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1534 entries, 0 to 1533\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   chrom   1534 non-null   object \n 1   start   1534 non-null   int64  \n 2   end     1534 non-null   int64  \n 3   GC      1533 non-null   float64\ndtypes: float64(1), int64(2), object(1)\nmemory usage: 48.1+ KB\nNone\n\n\n\n\nCalculate the E1 compartments\nLoop: view_df, cis_eigs, e1_values\n\nPlot GC covariance\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize=(10, 2))\n\nax.plot(gc_cov['start'],gc_cov['GC'])\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nCreate viewframes: full, arms, 10Mb windows\n\nimport pandas as pd\n\n# Fetch the chromsize of X from one of the coolers\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\nviews = {}\n\n# Make the full view frame\nviews['full'] = pd.DataFrame({\n    'chrom': 'chrX',\n    'start': 0,\n    'end': chrX_size,\n    'name': 'chrX'}, index=[0])\n\n# Divide into chromosome arms\nviews['arms'] = pd.DataFrame({\n    'chrom': 'chrX',\n    'start': [0, 59_000_001],\n    'end': [59_000_000, chrX_size],\n    'name': ['X_short', 'X_long']}, index=[0,1])\n\n# Calculate in 10Mb windows\nwindow_size = 10_000_000\nstart_positions = list(range(0, chrX_size, window_size))\nend_positions = [min(start + window_size, chrX_size) for start in start_positions]\n\n# Create the DataFrame\nviews['10Mb'] = pd.DataFrame({\n    'chrom': ['chrX'] * len(start_positions),\n    'start': start_positions,\n    'end': end_positions,\n    'name': [f'X_{i}' for i in range(len(start_positions))]\n})\n\n\n\nCalulate the E1 compartments\n\nimport cooltools\n\neigs = {}\ne1_values = {}\n\nfor name, clr in clrs.items():\n    if name not in eigs or name not in e1_values:\n        eigs[name] = {} \n        e1_values[name] = {}\n    for view, view_df in views.items():\n        print(f\"Calculating eigenvectors for {name} at {view}\")\n        cis_eigs = cooltools.eigs_cis(\n                            clr,\n                            gc_cov,\n                            view_df=view_df,\n                            n_eigs=1)\n        eigs[name][view] = cis_eigs[1]\n        e1_values[name][view] = cis_eigs[1]['E1'].values\n        \n\n\nCalculating eigenvectors for fibroblast at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for fibroblast at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for fibroblast at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\n\nExtract the A compartment coordinates\n\nimport importlib\nimport hicstuff\nimportlib.reload(hicstuff)\nfrom hicstuff import extract_a_coordinates\n\n\nres = 100_000\noutdir = '../results/compartments/'\n\nfor name, view_df in e1_values.items():\n    print(f\"Calculating A-compartment intervals for {name}\")\n    for view, e1 in view_df.items():\n        print(view)\n        extract_a_coordinates(\n            e1=e1,\n            name=name,\n            restriction=view,\n            chrom='chrX',\n            res=res,\n            csv=True,\n            output_dir=outdir,\n            force=True\n        )\n        extract_a_coordinates(\n            e1=e1,\n            name=name,\n            restriction=view,\n            chrom='chrX',\n            res=res,\n            csv=True,\n            output_dir=outdir,\n            smooth=True,\n            force=True\n        )\n    \n\nCalculating A-compartment intervals for fibroblast\nfull\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_full.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_arms.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_10Mb.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/fibroblast_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/compartments/fibroblast_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nfull\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_full.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_arms.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_10Mb.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/spermatogonia_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/compartments/spermatogonia_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nfull\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_full.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_arms.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_10Mb.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/pachytene_spermatocyte_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/compartments/pachytene_spermatocyte_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nfull\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_full.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_arms.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_10Mb.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/round_spermatid_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/compartments/round_spermatid_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nfull\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_full.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_arms.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_10Mb.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/compartments/sperm_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/compartments/sperm_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\n\n\n\n\nPlot the E1 compartments\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nf, axs = plt.subplots(5, 3, figsize=(18, 8), sharex=True, sharey=True)\n\n# Loop through eigs and e1_values to plot the E1 values\nfor i, (name, e1_dict) in enumerate(e1_values.items()):\n    axs[i,0].set_ylabel(names_abbr[name])\n    for j, (view, e1) in enumerate(e1_dict.items()):\n        ax = axs[i, j]\n\n        if i==0:\n            ax.set_title(view)\n\n        # Create stairs\n        x = np.zeros(2*chrom_start.size)\n        y = np.zeros(2*chrom_start.size)\n        smooth_y = np.zeros(2*chrom_start.size)\n        x[0::2] = chrom_start\n        x[1::2] = chrom_end\n        y[0::2] = e1\n        y[1::2] = e1\n        smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n        smooth_y[0::2] = smooth_e1\n        smooth_y[1::2] = smooth_e1\n\n\n        # ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\n        # ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n        # ax.plot(x, smooth_y/5, color='C1', linewidth=0.5)\n\n        ax.fill_between(x, smooth_y, 0, where=(smooth_y &gt; 0), color='tab:red')\n        ax.fill_between(x, smooth_y, 0, where=(smooth_y &lt; 0), color='tab:blue')\n\n        # Test to see how well my coordinates match the e1 values\n        coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_100kb_{view}_smoothed.csv')\n        # Iterate over each interval in the DataFrame\n        for start, end in zip(coords['start'], coords['end']):\n            rect = Rectangle((start, 0.4), width=end-start, height=0.5, color='k', linewidth=0.05)\n            ax.add_patch(rect)\n\n# Set y-limits for all subplots\nfor ax in axs.flat:\n    ax.set_ylim(-4, 4)\n    ax.spines[:].set_visible(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.savefig('../steps/e1_plot_full_100kb_smoothed.svg', bbox_inches='tight')\n        \n    \n\n\n\n\nE1 eigenvector values for all merged samples at 100kb resolution. Left: Chromosomes (not restricted) Middle: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.Values are smoothed with a sliding window of 5 bins, step size 1 bin.\n\n\n\n\n\n\nPlot matrices with compartments\n\nimport cooltools.lib.plotting\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom cooltools.lib.numutils import adaptive_coarsegrain, interp_nan\n\nf, axs = plt.subplots(1,5,\n    figsize=(25,10)\n)\n\nnorm = LogNorm(vmax=0.1)\n\n# Loop through the clrs and its matrix: plot the matrix on its axis\nfor i, (name, e1_dict) in enumerate(e1_values.items()):\n    ax = axs[i]\n\n    im = ax.matshow(\n        clr.matrix().fetch('chrX'),\n        norm=norm,\n        cmap='fall',\n    );\n    ax.set_xlim(0, nbins)\n    ax.set_ylim(nbins, 0)\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\n    plt.colorbar(im, cax=cax, label='corrected frequencies');\n    ax.set_ylabel('chrX:100kb bins, #bin')\n    ax.xaxis.set_visible(False)\n\n    for j, (view, e1) in enumerate(e1_dict.items()):\n        ax1 = divider.append_axes(\"top\", size=\"10%\", pad=0.1, sharex = ax)\n\n        # ax1.plot(e1, label='E1')\n\n        # Create stairs\n        x = np.zeros(2*chrom_start.size)\n        y = np.zeros(2*chrom_start.size)\n        #smooth_y = np.zeros(2*chrom_start.size)\n        x[0::2] = chrom_start/binsize\n        x[1::2] = chrom_end/binsize\n        y[0::2] = e1\n        y[1::2] = e1\n        # smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n        # smooth_y[0::2] = smooth_e1\n        # smooth_y[1::2] = smooth_e1\n\n\n        ax1.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\n        ax1.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n\n        ax1.set_ylabel(view, rotation=-70)\n        ax1.set_ylim(-0.8, 0.8)\n        ax1.set_xticks([])\n\n    ax1.set_title(name)\n\n#    # Plot the sign changes on the matrix \n#     col = colors[i]\n#     for i in np.where(np.diff( (pd.Series(e1)&gt;0).astype(int)))[0]:\n#         # Horisontal lines where E1 intersects 0\n#         ax.plot([0,nbins],[i,i],col,lw=0.5)\n\n#         # Vertical lines where E1 intersects 0\n#         ax.plot([i,i],[0,nbins],col,lw=0.5)\n\n# Now show the plot\nf.set_layout_engine('compressed')\nf.canvas.draw()\nplt.show()\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution for round spermatid, as well as the interaction matrix. E1 was restricted to top: Full-chromosome, middle: Chromosome-arms, bottom: 10Mb window.\n\n\n\n\n\n\n\nSmooth the Observed/Expected matrix\nWang et al. 2019 used a 400Kb window with a step size of 100Kb to smooth the O/E matrix before calculating the E1. I have tried various different methods to smooth the interaction matrix, but I can’t get dimensions of the pixels to match with the bins. Also, cooltools.eigs_cis need a full cooler to fetch data from, and I can’t get it to work without a pixels object.\nThus, I will try smoothing the E1 values instead, as I can’t really rationalize what biological difference it would make. I think I need help figuring that out.\n\n# import glob\n# import os.path as op\n# import cooler\n\n# mcools = glob.glob(\"../steps/bwa/PE/cool/*/*.mcool\")\n# res = \"::resolutions/100000\"\n\n# clrs100kb = {op.basename(op.dirname(mcool)): cooler.Cooler(mcool+res) for mcool in mcools}\n\n# chron_order = ['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']\n\n# clrs100kb = {key: clrs100kb[key] for key in chron_order}\n# clrs100kb\n\n\nCalculate gc covariance (from the reference genome)\nDo this with any of the clrs - it just needs the bins positions.\n\n# import bioframe\n# import pandas as pd\n# import os.path as op\n\n# bins = clrs100kb['fibroblast'].bins().fetch('chrX')[:]\n# out_name = 'rheMac10_gc_cov_X_100kb.tsv'\n\n# rheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\n# if not op.exists(out_name):\n#     print('Calculate the fraction of GC basepairs for each bin')\n#     gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n#     gc_cov.to_csv(out_name, index=False,sep='\\t')\n#     print(gc_cov.info())\n# else: \n#     print(\"Already exists, read from file\")\n#     gc_cov = pd.read_csv(out_name, sep='\\t')\n#     print(gc_cov.info())\n\n\n# import cooler\n# import numpy as np\n\n# def smooth_matrix(matrix, window_size=4, step_size=1):\n#     n = matrix.shape[0]\n#     smoothed_matrix = np.zeros_like(matrix)\n    \n#     for i in range(0, n - window_size + 1, step_size):\n#         for j in range(0, n - window_size + 1, step_size):\n#             window = matrix[i:i+window_size, j:j+window_size]\n#             smoothed_matrix[i:i+window_size, j:j+window_size] = np.sum(window)\n    \n#     return smoothed_matrix\n\n# # Load the Hi-C interaction matrix from a multi-resolution .mcool file\n# cooler_file = '../steps/bwa/PE/cool/fibroblast/fibroblast.mcool'\n# clr = cooler.Cooler(cooler_file + '::resolutions/100000')\n\n# # Extract the matrix\n# matrix = clr.matrix(balance=True).fetch('chrX')[:]\n\n# # Smooth the matrix\n# smoothed_matrix = smooth_matrix(matrix, window_size=4, step_size=1)\n\n\n# #clr.bins().fetch('chrX')[:]\n# clr.pixels().fetch('chrX')[:]\n# #print(matrix.shape)\n# #print(smoothed_matrix.shape)\n\n\n\n\n\n\n\n\nbin1_id\nbin2_id\ncount\n\n\n\n\n145469195\n26898\n26898\n2013\n\n\n145469196\n26898\n26899\n171\n\n\n145469197\n26898\n26901\n75\n\n\n145469198\n26898\n26902\n100\n\n\n145469199\n26898\n26903\n187\n\n\n...\n...\n...\n...\n\n\n146369705\n28431\n28532\n2\n\n\n146369706\n28431\n28533\n1\n\n\n146369707\n28431\n28534\n2\n\n\n146369708\n28431\n28539\n1\n\n\n146369709\n28431\n28544\n1\n\n\n\n\n900515 rows × 3 columns\n\n\n\n\n# import pandas as pd\n# import cooler\n# import numpy as np\n\n# pixels = pd.DataFrame(smoothed_matrix).stack().rename_axis(['bin1_id', 'bin2_id']).reset_index(name='count')\n# pixels = pixels[pixels['bin1_id'] &lt;= pixels['bin2_id']]\n# pixels.sort_values(['bin1_id', 'bin2_id'])[['bin1_id', 'bin2_id', 'count']].reset_index(drop=True)\n\n\n# # Get the eigs\n\n# import cooltools\n# import pandas as pd\n\n# eigvecs, eigvals = cooltools.lib.numutils.get_eig(matrix, n=1)\n\n\n# # create a cooler for the smoothed matrix\n\n# import cooler\n# import numpy as np\n\n# # Create a new cooler file for the smoothed matrix\n# smoothed_cooler_file = cooler_file.replace('.mcool', '.smoothed.mcool')\n\n# # Create a new cooler object\n# cooler.create_cooler(smoothed_cooler_file, bins=clr.bins()[:], pixels=smoothed_matrix) \n\n\n\n\n\nImakaev, Maxim, Geoffrey Fudenberg, Rachel Patton McCord, Natalia Naumova, Anton Goloborodko, Bryan R Lajoie, Job Dekker, and Leonid A Mirny. 2012. “Iterative Correction of Hi-C Data Reveals Hallmarks of Chromosome Organization.” Nature Methods 9 (10): 999–1003. https://doi.org/10.1038/nmeth.2148.\n\n\nWang, Yao, Hanben Wang, Yu Zhang, Zhenhai Du, Wei Si, Suixing Fan, Dongdong Qin, et al. 2019. “Reprogramming of Meiotic Chromatin Architecture During Spermatogenesis.” Molecular Cell 73 (3): 547–561.e6. https://doi.org/10.1016/j.molcel.2018.11.019.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Compartments Analysis</span>"
    ]
  },
  {
    "objectID": "notebooks/04_genomicintervals.html",
    "href": "notebooks/04_genomicintervals.html",
    "title": "E1 vs. ECH",
    "section": "",
    "text": "The genomic regions in question\nIn 03_compartments.ipynb we extracted the genomic intervals of A compartments on all cell types in all combinations of the following parameters:\nThe following parameter was only changed for 100kb resolution:\nResulting in 45 .csv files. They are saved to ../results/compartments/.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>E1 vs. ECH</span>"
    ]
  },
  {
    "objectID": "notebooks/04_genomicintervals.html#the-genomic-regions-in-question",
    "href": "notebooks/04_genomicintervals.html#the-genomic-regions-in-question",
    "title": "E1 vs. ECH",
    "section": "",
    "text": "Cell type: fibroblast, spermatocyte, pachytene spermatocyte, round spermatid, sperm\nChromosome: X\nE1 restriction: full-chromosome, chromosome arms, 10Mb windows\nResolution: 100 kb, 500 kb\n\n\n\nSmoothing: No smoothing, 5 bins (500kb)\n\n\n\nLoad the data\n\nimport pandas as pd\nimport os\n\n# Directory containing your .csv files\ncsv_dir = '../results/compartments/'\n\n# Create a dictionary to store the DataFrames\ndataframes = {}\n\n# Iterate over all .csv files in the directory\nfor filename in os.listdir(csv_dir):\n    if filename.endswith('.csv'):  # Check for .csv files\n        # Construct the full file path\n        filepath = os.path.join(csv_dir, filename)\n        \n        # Load the CSV into a DataFrame\n        # Use the filename (without extension) as the dictionary key\n        key = filename.replace('_a_comp_coords_', '_')\n        key = os.path.splitext(key)[0]\n        dataframes[key] = pd.read_csv(filepath)\n        dataframes[key]['length'] = dataframes[key]['end'] - dataframes[key]['start']\n\n# The `dataframes` dictionary now contains the DataFrames\ndataframes.keys()\n\nech90 = pd.read_csv('../data/ech90_human_Mmul_10.csv')\nech90['length'] = ech90['end'] - ech90['start']",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>E1 vs. ECH</span>"
    ]
  },
  {
    "objectID": "notebooks/04_genomicintervals.html#time-to-unleash-genominterv-on-the-.csv-files",
    "href": "notebooks/04_genomicintervals.html#time-to-unleash-genominterv-on-the-.csv-files",
    "title": "E1 vs. ECH",
    "section": "Time to unleash genominterv on the .csv files",
    "text": "Time to unleash genominterv on the .csv files\n\nDefine a plotting function\n\n# Kaspers plotting function\n \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%config InlineBackend.figure_format = 'svg'\n\ndef plot_intervals(query=None, annot=None, **kwargs):\n\n    tups = []\n    if query is not None:\n        tups.append(('query', query))\n    if annot is not None:\n        tups.append(('annot', annot))\n    tups.extend(kwargs.items())\n    tups = reversed(tups)\n\n    df_list = []\n    labels = []\n    for label, df in tups:\n        labels.append(label)\n        df['label'] = label\n        df_list.append(df)\n    bigdf = pd.concat(df_list)\n\n    bigdf['chrom'] = pd.Categorical(bigdf['chrom'], bigdf['chrom'].unique())\n    bigdf['label'] = pd.Categorical(bigdf['label'], bigdf['label'].unique())\n\n    gr = bigdf.groupby('chrom', observed=False)\n    fig, axes = plt.subplots(gr.ngroups, 1, figsize=(8, 1.5*gr.ngroups), \n                            sharey=True\n                            #  sharex=True\n                             )\n    if type(axes) is not np.ndarray:\n        # in case there is only one axis so it not returned as a list\n        axes = np.array([axes])\n    \n    # with plt.style.context(('default')):\n\n    for i, chrom in enumerate(gr.groups):\n        _df = gr.get_group(chrom)\n        _gr = _df.groupby('label', observed=False)\n        for y, label in enumerate(_gr.groups):\n            try:\n                df = _gr.get_group(label)\n            except KeyError:\n                continue\n            y = np.repeat(y, df.index.size)\n            axes[i].hlines(y, df.start.tolist(), df.end.tolist(), alpha=0.5, lw=5, colors=f'C{y[0]}')\n            delta = len(labels)/10\n            axes[i].vlines(df.start.tolist(), y-delta, y+delta, alpha=0.5, lw=2, colors=f'C{y[0]}')\n            axes[i].vlines(df.end.tolist(), y-delta, y+delta, alpha=0.5, lw=2, colors=f'C{y[0]}')\n\n        axes[i].spines['top'].set_visible(False)\n        axes[i].spines['left'].set_visible(False)\n        axes[i].spines['right'].set_visible(False)\n\n        axes[i].set_yticks(list(range(len(labels))), labels)\n        axes[i].tick_params(axis='y', which='both', left=False)\n        axes[i].set_ylim(-1, len(labels)-0.7)\n        # axes[i].set_xlim(df.start.min()-delta, df.end.max()+delta)\n        if i != gr.ngroups-1:\n            axes[i].tick_params(axis='x', which='both', bottom=False)\n\n        axes[i].set_title(chrom, loc='left', fontsize=10)\n    plt.tight_layout()\n\n\n# My plotting function\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Rectangle\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom genominterv import interval_intersect\n\n%config InlineBackend.figure_format = 'svg'\n\n\n\ndef plot_regions(query=None, annot=None, intersect=None):\n    chrom = annot['chrom'].unique()[0]\n    chromsize = pd.read_csv('../data/rheMac10.filtered.chrom.sizes', sep='\\t', header=None, names=['chrom', 'size'])\n    chromsize = chromsize[chromsize['chrom'] == chrom]['size'].values[0]\n    \n    # Define the plot\n    height = 1 + (1 if query is not None else 0) + (1 if intersect is not None else 0)\n    height = height * 0.75\n\n    f, ax = plt.subplots(figsize=(10, height), sharex=True)\n    ax.spines[:].set_visible(False)\n\n    # Plot the annot\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(annot['start'], annot['end']):\n        rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:red', linewidth=0, alpha=0.6)\n        ax.add_patch(rect)\n        ax.spines['bottom'].set_visible(True)\n        lbl = annot['label'].unique()[0] if 'label' in annot.columns else 'A-Comp'\n        ax.set_ylabel(lbl, rotation=0, fontsize=10, labelpad=30)\n\n    \n    divider = make_axes_locatable(ax)\n\n    if query is not None:\n        qax = divider.append_axes(\"top\", size=\"100%\", pad=0.2, sharex=ax)\n        qax.xaxis.set_visible(False)\n        # Plot the query\n        for start, end in zip(query['start'], query['end']):\n            rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:blue', linewidth=0, alpha=0.6)\n            qax.add_patch(rect)\n            qax.spines[:].set_visible(False)\n            qax.set_yticks([]) \n            qax.set_title(chrom, loc='left', fontsize=10)\n            qax.set_ylabel('ECH90', rotation=0, fontsize=10, labelpad=30)\n    \n    if intersect is not None:\n        iax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.2, sharex=ax)\n        # Invisible x-axis for 'annot' (intersect ie below) \n        ax.xaxis.set_visible(False)\n        # Plot the intersect\n        for start, end in zip(intersect['start'], intersect['end']):\n            rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.6)\n            iax.add_patch(rect)\n            iax.spines[:].set_visible(False)\n            iax.set_yticks([]) \n            ax.spines['bottom'].set_visible(False)\n            iax.spines['bottom'].set_visible(True)\n            iax.set_ylabel('Intersect', rotation=0, fontsize=10, labelpad=30)\n\n\n\n    ax.set_yticks([])\n    ax.set_xlim(0, chromsize)\n    ticks = np.linspace(0, chromsize, num=5)\n    ax.set_xticks(ticks) \n    ax.set_xticklabels([f'{int(t/1e6)} Mbp' for t in ticks])\n    plt.tight_layout()\n    return f, ax\n\n\n\n\nTest with a subsample of the data\n\n\nannot = dataframes['round_spermatid_100kb_arms']\nquery = ech90\nintersect = interval_intersect(annot, query)\n\nplot_intervals(query, annot, intersection=intersect)\nplot_regions(query, annot, intersect)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom genominterv import proximity_test, interval_collapse, interval_diff, interval_intersect, jaccard_stat\n\nannot = dataframes['round_spermatid_100kb_arms']\nquery = ech90\n\n#plot_intervals(query=query, annot=annot)\n\nfor key,annot in dataframes.items():\n    # Filter out subset\n    if ('round_spermatid_100') in key and not 'full' in key:\n        # Plot the intervals\n        intersection = interval_intersect(query, annot)\n        plot_intervals(query=query, annot=annot, intersection=intersection)\n        plt.title(key)\n\n        # Do a proximity test\n        print(f\"Tests for {key}\")\n        annot_collapsed = interval_collapse(annot)\n        non_ovl_query = interval_diff(query, annot_collapsed)\n        print(\"Proximity:\", proximity_test(non_ovl_query, annot_collapsed))\n        print(\"Jaccard:\", jaccard_stat(query, annot))\n        print()\n\n\nTests for round_spermatid_100kb_arms_smoothed\nProximity: TestResult(statistic=0.20566666666666641, pvalue=0.105)\nJaccard: 0.03319511172796144\n\nTests for round_spermatid_100kb_arms\nProximity: TestResult(statistic=0.49242857142857144, pvalue=0.0004)\nJaccard: 0.03916232332293147\n\nTests for round_spermatid_100kb_10Mb\nProximity: TestResult(statistic=0.3223076923076922, pvalue=0.0209)\nJaccard: 0.04512778341139746\n\nTests for round_spermatid_100kb_10Mb_smoothed\nProximity: TestResult(statistic=0.4658333333333337, pvalue=0.0017)\nJaccard: 0.04494391747197651\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap to get a p-value\n\nfrom genominterv import bootstrap\n\nannot = dataframes['round_spermatid_100kb_arms']\nchromsizes = (\n    pd.read_csv('../data/rheMac10.filtered.chrom.sizes', \n                sep='\\t', \n                index_col='chrom', \n                header=None, \n                names=['chrom','size'])\n    .to_dict()['size']\n)\n#display(chromsizes)\n\n@bootstrap(chromsizes, samples=1000)\ndef jaccard_bootstrap(query, annot):\n    return jaccard_stat(query, annot)\n\njacccard_stat, p_value = jaccard_bootstrap(query, annot)\n\n\njacccard_stat, p_value\n\n(0.03916232332293147, 0.31)\n\n\n\n\nPartition the A-compartments into regions around the edges\n\ndf = dataframes['round_spermatid_100kb_arms']\n\nstart_edge = pd.DataFrame({\n    'chrom': df['chrom'],\n    'start': df['start']-1*df['resolution'],\n    'end': df['start']+1*df['resolution'],\n    'resolution': df['resolution'],\n    'label': 'start_edge'\n})\nend_edge = pd.DataFrame({\n    'chrom': df['chrom'],\n    'start': df['end']-1*df['resolution'],\n    'end': df['end']+1*df['resolution'],\n    'resolution': df['resolution'],\n    'label': 'end_edge'\n})\n\n#df\ntest_df = pd.concat([start_edge, end_edge]).sort_values(['chrom', 'start', 'end'])\ninterval_collapse(test_df)\n\n\n\n\n\n\n\n\nstart\nend\nchrom\n\n\n\n\n0\n800000\n1000000\nchrX\n\n\n1\n2500000\n2700000\nchrX\n\n\n2\n3100000\n3300000\nchrX\n\n\n3\n3400000\n3600000\nchrX\n\n\n4\n6500000\n6800000\nchrX\n\n\n...\n...\n...\n...\n\n\n86\n147000000\n147200000\nchrX\n\n\n87\n148800000\n149400000\nchrX\n\n\n88\n150800000\n151000000\nchrX\n\n\n89\n152200000\n152400000\nchrX\n\n\n90\n153200000\n153400000\nchrX\n\n\n\n\n91 rows × 3 columns\n\n\n\n\nimport os\n\nfor key, df in dataframes.items():\n    outdir = '../results/edges'\n    edge_csv_name = os.path.join(outdir,f'{key+'_edges.csv'}')\n    if not os.path.exists(edge_csv_name):\n        res = df['resolution'].unique()[0]\n\n        start_edge = pd.DataFrame({\n            'chrom': df['chrom'],\n            'start': df['start']-1*df['resolution'],\n            'end': df['start']+1*df['resolution'],\n            'resolution': df['resolution'],\n            'label': 'start_edge'\n        })\n        end_edge = pd.DataFrame({\n            'chrom': df['chrom'],\n            'start': df['end']-1*df['resolution'],\n            'end': df['end']+1*df['resolution'],\n            'resolution': df['resolution'],\n            'label': 'end_edge'\n        })\n\n        if not os.path.exists(outdir):\n            os.makedirs(outdir)\n\n        tmp = pd.concat([start_edge, end_edge]).sort_values(['chrom', 'start', 'end'])\n        interval_collapse(tmp).assign(resolution=res).to_csv(edge_csv_name, index=False)\n\n\n\nImport edges\n\nimport pandas as pd\nimport os\n\n# Directory containing your .csv files\ncsv_dir = '../results/edges/'\n\n# Create a dictionary to store the DataFrames\nedges = {}\n\n# Iterate over all .csv files in the directory\nfor filename in os.listdir(csv_dir):\n    if filename.endswith('.csv'):  # Check for .csv files\n        # Construct the full file path\n        filepath = os.path.join(csv_dir, filename)\n        \n        # Load the CSV into a DataFrame\n        # Use the filename (without extension) as the dictionary key\n        key = filename.replace('_edges_', '')\n        key = os.path.splitext(key)[0]\n        edges[key] = pd.read_csv(filepath)\n        edges[key]['length'] = edges[key]['end'] - edges[key]['start']\n\n# The `edges` dictionary now contains the DataFrames\nprint(edges.keys())\nprint(edges['fibroblast_100kb_10Mb_edges'].columns)\n\n#ech90 = pd.read_csv('../data/ech90_human_Mmul_10.csv')\n\ndict_keys(['sperm_100kb_arms_smoothed_edges', 'spermatogonia_500kb_full_edges', 'pachytene_spermatocyte_100kb_10Mb_smoothed_edges', 'spermatogonia_100kb_arms_edges', 'fibroblast_500kb_full_edges', 'round_spermatid_500kb_10Mb_edges', 'fibroblast_100kb_arms_edges', 'spermatogonia_100kb_full_smoothed_edges', 'round_spermatid_100kb_full_smoothed_edges', 'round_spermatid_100kb_full_edges', 'fibroblast_100kb_10Mb_edges', 'round_spermatid_500kb_arms_edges', 'fibroblast_100kb_full_smoothed_edges', 'spermatogonia_100kb_10Mb_edges', 'sperm_500kb_arms_edges', 'spermatogonia_100kb_10Mb_smoothed_edges', 'sperm_100kb_full_edges', 'pachytene_spermatocyte_500kb_10Mb_edges', 'pachytene_spermatocyte_100kb_full_smoothed_edges', 'pachytene_spermatocyte_100kb_full_edges', 'pachytene_spermatocyte_500kb_arms_edges', 'fibroblast_100kb_10Mb_smoothed_edges', 'sperm_500kb_10Mb_edges', 'round_spermatid_100kb_10Mb_smoothed_edges', 'spermatogonia_500kb_arms_edges', 'spermatogonia_100kb_full_edges', 'spermatogonia_100kb_arms_smoothed_edges', 'fibroblast_500kb_arms_edges', 'round_spermatid_100kb_10Mb_edges', 'fibroblast_100kb_full_edges', 'sperm_100kb_full_smoothed_edges', 'fibroblast_100kb_arms_smoothed_edges', 'round_spermatid_100kb_arms_edges', 'fibroblast_500kb_10Mb_edges', 'round_spermatid_500kb_full_edges', 'round_spermatid_100kb_arms_smoothed_edges', 'spermatogonia_500kb_10Mb_edges', 'sperm_500kb_full_edges', 'sperm_100kb_10Mb_smoothed_edges', 'sperm_100kb_arms_edges', 'pachytene_spermatocyte_100kb_arms_smoothed_edges', 'pachytene_spermatocyte_100kb_10Mb_edges', 'pachytene_spermatocyte_100kb_arms_edges', 'pachytene_spermatocyte_500kb_full_edges', 'sperm_100kb_10Mb_edges'])\nIndex(['chrom', 'start', 'end', 'resolution', 'label', 'length'], dtype='object')\n\n\n\nfrom genominterv import interval_intersect\n\nsample = 'round_spermatid_100kb_arms'\n\nfull_df = dataframes[sample]\nfull_intersect = interval_intersect(full_df, ech90).assign(length=lambda x: x['end'] - x['start'])\nedge_df = edges[f'{sample}_edges']\n\n# Plot full\nplot_regions(ech90, full_df, full_intersect)\nplt.suptitle('All edges')\n\nText(0.5, 0.98, 'All edges')\n\n\n\n\n\n\n\n\n\n\n### Some stats about the data and intersections ###\n\n# Determine the proportion of total regions in ECH90 that lies on compartment edges\n\nprint(\"Proportion of ECH90 on edges (#count)\")\n\n# Proportion of ECH90 on full regions\nprint(f'\\t{full_intersect.shape[0] / ech90.shape[0]}')\n\n\nprint(\"\\nProportion of ECH90 on edges (#bpairs)\")\n\n# Proportion of ECH90 on full regions\nprint(f'\\t{full_intersect['length'].sum() / ech90['length'].sum()}')\n\n\n# What is the total length of ech90 regions\nprint(\"\\nTotal length of:\")\nprint(f'\\tECH90:  {(ech90['end'] - ech90['start']).sum()} bp')\nprint(f'\\tEdges: {(edge_df[\"end\"] - edge_df[\"start\"]).sum()} bp')\n\nProportion of ECH90 on edges (#count)\n    0.631578947368421\n\nProportion of ECH90 on edges (#bpairs)\n    0.3932398045966063\n\nTotal length of:\n    ECH90:  5511675 bp\n    Edges: 28800000 bp\n\n\n\nf, ax = plot_regions(edge_df, ech90, full_intersect)\n\nfor ax in list(f.axes):\n    if ax.get_ylabel() == 'ECH90':\n        ax.set_ylabel('edge_df', rotation=0, fontsize=10, labelpad=30)\n    if ax.get_ylabel() == \"query\":\n        ax.set_ylabel('ECH90', rotation=0, fontsize=10, labelpad=30)\n    if ax.get_ylabel() == 'Intersect':\n        #ax.set_ylabel('end_edge \\nintersect', rotation=0, fontsize=10, labelpad=30)\n        pass\n\n        \n\n\n\n\n\n\n\n\n\n\nDo testing of the edges\n\n%%capture\n# Define what we are testing\n\nprint(\"\"\"\nGoal: To test whether ECH90 regions are enriched in compartment edges\nQuery: ECH90\nAnnotation: Start and end edges of compartments\n\nHypothesis: \n      ECH90 regions are enriched in compartment edges\nNull hypothesis: \n      ECH90 regions are not enriched in compartment edges\n\nTests: \n* Proximity test: \n      tests whether the query regions are closer to \n      the annotation regions than expected by chance. \n      NB regions can not overlap, so we need to collapse the annotation regions\n\n* Jaccard index: \n      tests the similarity between the query and annotation regions, \n      where a value of 1 indicates perfect overlap\n\"\"\")\n\n\n### Proximity test ###\n\nfrom genominterv import proximity_test, interval_collapse, interval_diff, interval_intersect\n\n# Define the query and annotation\nquery = ech90\nannot = full_intersect\n\n# Calculate the non-overlapping query regions\nnon_ovl_query_full = interval_diff(query, annot)\n\n# Perform the proximity test\nproximity_full = proximity_test(non_ovl_query_full, annot, two_sided=False)\n\n\nprint(\"Proximity test results: All edges\")\nprint(f\"\\tstatistic: {proximity_full.statistic}, \\n\\tp-value: {proximity_full.pvalue}\")\n\nProximity test results: All edges\n    statistic: 0.6821666666666665, \n    p-value: 0.0\n\n\n\n### Jaccard index ###\n\nfrom genominterv import jaccard_stat, bootstrap\n\nchromsizes = (pd.read_csv(\n    '../data/rheMac10.filtered.chrom.sizes', \n    sep='\\t', \n    index_col='chrom', \n    header=None, \n    names=['chrom','size'])\n.to_dict()['size']\n)\n\n# # Calculate the Jaccard index\n# jaccard_start = jaccard_stat(query, annot_start)\n# jaccard_end = jaccard_stat(query, annot_end)\n# jaccard_concat = jaccard_stat(query, annot_concat)\n\n# print(\"\\nJaccard index results\")\n# print(f\"Start edge: {jaccard_start}\")\n# print(f\"End edge: {jaccard_end}\")\n# print(f\"Concat edge: {jaccard_concat}\")\n\n# Test with bootstrap decorator\n@bootstrap(chromsizes, samples=1000)\ndef jaccard_bootstrap(query, annot):\n    return jaccard_stat(query, annot)\n\njaccard_stat_full, p_value_full = jaccard_bootstrap(query,annot)\n\nprint(f\"Jaccard index: {jaccard_stat_full}, p-value: {p_value_full}\")\n\nJaccard index: 0.3932398045966063, p-value: 0.0\n\n\np-value is zero smaller than 0.001. Increase nr samples to get actual p-value.\n\n\n\n\nCheck the length of the intervals\n\n# Plot histogram of the lengths of the A compartments from the full regions\n\nfull_df['length'] = full_df['end'] - full_df['start']\nfull_df['length'].mean()\n\nplt.figure()\nfull_df['length'].hist(bins=20)\nplt.show()\n\nplt.figure()\n(ech90['end']-ech90['start']).hist(bins=10)\nplt.show()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>E1 vs. ECH</span>"
    ]
  },
  {
    "objectID": "notebooks/04_genomicintervals.html#bioframe-genomic-intervals-support",
    "href": "notebooks/04_genomicintervals.html#bioframe-genomic-intervals-support",
    "title": "E1 vs. ECH",
    "section": "Bioframe genomic intervals support",
    "text": "Bioframe genomic intervals support\n\nimport bioframe",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>E1 vs. ECH</span>"
    ]
  },
  {
    "objectID": "notebooks/04_genomicintervals.html#geneinfo",
    "href": "notebooks/04_genomicintervals.html#geneinfo",
    "title": "E1 vs. ECH",
    "section": "Geneinfo",
    "text": "Geneinfo\nHow does the edges align with genes?\nThis first plot is just to figure out how to plot with gene_plot.\n\nimport geneinfo as gi\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\n\n\n# Use the proximity test results to plot the ECH90 regions and the compartment edges\n\nstart = full_intersect['start'][2]\nend = full_intersect['end'][5]\n\nrectangles = [Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.6) for start, end in zip(full_intersect['start'][2:6], full_intersect['end'][2:6])]\n\npc = PatchCollection(rectangles, match_original=True)\n\nax = gi.gene_plot('chrX', start-100_000, end+100_000, assembly='rheMac10')\nax.add_collection(pc)\n\n\n\n\n\n\n\n\n\nGet the geneinfo for all intersections between edges and ECH90\nAnd write to a csv file. If the file exists, read it with pandas.\n\n# Use get_genes_region\nimport os.path as op\nimport geneinfo as gi\nimport pandas as pd\n\ngenes_file = '../results/edge_genes/rs_edges_100kb_genes.csv'\n\nif not op.exists(genes_file):\n    genes = pd.concat(\n        full_intersect.apply(\n            lambda x: gi.get_genes_region_dataframe('chrX', x['start'], x['end'], assembly='rheMac10'), \n            axis =1\n            ).to_list(),\n        ignore_index=True\n    )\n    genes.to_csv(genes_file, index=False) \nelse: \n    genes = pd.read_csv(genes_file)\n\n\ngenes_list = genes['name'].unique().tolist()\ngenes_list\n\n['SH3KBP1',\n 'MIR7206',\n 'LANCL3',\n 'XK',\n 'CYBB',\n 'LOC696657',\n 'DYNLT3',\n 'PAGE4',\n 'USP27X',\n 'CLCN5',\n 'LOC114675180',\n 'MIR532',\n 'MIR188',\n 'MIR500A',\n 'MIR362',\n 'MIR501',\n 'MIR500B',\n 'MIR660',\n 'MIR502',\n 'AKAP4',\n 'CCNB3',\n 'LOC114675218',\n 'LOC695959',\n 'CENPVL3',\n 'FAM120C',\n 'WNK3',\n 'LOC114675302',\n 'ZC3H12B',\n 'LAS1L',\n 'MSN',\n 'ATRX',\n 'MAGT1',\n 'LOC114675151',\n 'COX7B',\n 'ATP7A',\n 'ALG13',\n 'RAP2C',\n 'DKC1',\n 'LOC114675231',\n 'MPP1',\n 'SMIM9',\n 'F8']\n\n\n\nimport geneinfo as gi\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\n\n\n# Use the proximity test results to plot the ECH90 regions and the compartment edges\n\nstart_idx = 10\nend_idx = 11\n\nstart = full_intersect['start'][start_idx]\nend = full_intersect['end'][end_idx]\n\nrectangles = [Rectangle(\n    (start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.6) for start, end in zip(full_intersect['start'][start_idx:end_idx+1], full_intersect['end'][start_idx:end_idx+1])]\n\npc = PatchCollection(rectangles, match_original=True)\n\nax = gi.gene_plot('chrX', start-100_000, end+100_000, assembly='rheMac10', \n                  highlight=genes_list,\n                  despine=True,\n                  figsize=(12, 5),\n                  aspect=5,\n                  )\nax.add_collection(pc)\n\n\n\n\n\n\n\n\n\n\nWhat can I do with the list of genes on the edges?\n\nGO enrichment?\n\nmmul_x_genes = gi.get_genes_region_dataframe('chrX', 0, 155_000_000, assembly='rheMac10')\n\n\nmmul_x_genelist = mmul_x_genes['name'].unique().tolist()\n\n\ngene_list = genes['name'].unique().tolist()\ntaxid = 9544\ngi.email('sojernj@gmail.com')\n#gi.go_annotation_table(taxid=taxid)\n\n#gi.show_go_evidence_codes()\n\ngo_terms = gi.get_go_terms_for_genes(gene_list, taxid=taxid)\n\n\nlen(go_terms)\n#gene_list[:5]\n\n98\n\n\n\nresults = gi.go_enrichment(\n    gene_list[:5], \n    # Use human as a start\n    alpha=0.05,\n    terms=go_terms\n    )\n\ngeneinfo_cache/go-basic.obo: fmt(1.2) rel(2024-10-27) 44,017 Terms; optional_attrs(def relationship)\n\n\nCould not map gene symbol \"MIR7206\" to ncbi id",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>E1 vs. ECH</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html",
    "href": "notebooks/05_rec_compartments.html",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "",
    "text": "Working with coolers\nNB: This notebook is a duplicate of 03_compartments but on new coolers with recommended parameters for pairtools parse and cooler cload.\nIn this notebook, we use files generated by workflow.py that, in short, does the following:\nWe will:",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#overview",
    "href": "notebooks/05_rec_compartments.html#overview",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "Overview",
    "text": "Overview\n\nData (Accessions)\n\n\nTo get an overview of the data accessions used in this analysis, we will first summarize the SRA-runtable.tsv that contains the accession numbers and some metadata for each sample (Table 14.1).\n\n\n\n\n\n\nTable 7.1: The most relevant columns of the SRA-runtable.tsv file\n\n\n\n\n\n\n\n\n \nsource_name\nBioSample\nRun\nGB\nBases\nReads\n\n\n\n\n16\nfibroblast\nSAMN08375237\nSRR6502335\n29.771059\n73,201,141,800\n244,003,806\n\n\n17\nfibroblast\nSAMN08375237\nSRR6502336\n22.755361\n65,119,970,100\n217,066,567\n\n\n18\nfibroblast\nSAMN08375236\nSRR6502337\n21.434722\n52,769,196,300\n175,897,321\n\n\n19\nfibroblast\nSAMN08375236\nSRR6502338\n21.420030\n52,378,949,100\n174,596,497\n\n\n20\nfibroblast\nSAMN08375236\nSRR6502339\n10.207410\n28,885,941,600\n96,286,472\n\n\n9\nfibroblast\nSAMN08375237\nSRR7349189\n52.729173\n139,604,854,200\n465,349,514\n\n\n10\nfibroblast\nSAMN08375236\nSRR7349190\n53.085520\n142,008,353,400\n473,361,178\n\n\n21\npachytene spermatocyte\nSAMN08375234\nSRR6502342\n60.258880\n150,370,993,500\n501,236,645\n\n\n22\npachytene spermatocyte\nSAMN08375234\nSRR6502344\n27.146048\n65,697,684,300\n218,992,281\n\n\n23\npachytene spermatocyte\nSAMN08375234\nSRR6502345\n26.202707\n63,490,538,700\n211,635,129\n\n\n0\npachytene spermatocyte\nSAMN09427370\nSRR7345458\n55.970557\n153,281,577,900\n510,938,593\n\n\n1\npachytene spermatocyte\nSAMN09427370\nSRR7345459\n53.982492\n144,993,841,200\n483,312,804\n\n\n11\npachytene spermatocyte\nSAMN08375235\nSRR7349191\n51.274476\n137,821,979,100\n459,406,597\n\n\n24\nround spermatid\nSAMN08375232\nSRR6502351\n20.924497\n55,095,075,300\n183,650,251\n\n\n25\nround spermatid\nSAMN08375232\nSRR6502352\n41.133960\n115,578,475,800\n385,261,586\n\n\n26\nround spermatid\nSAMN08375232\nSRR6502353\n36.444117\n96,195,161,400\n320,650,538\n\n\n2\nround spermatid\nSAMN09427369\nSRR7345460\n38.244654\n104,105,827,200\n347,019,424\n\n\n3\nround spermatid\nSAMN09427369\nSRR7345461\n53.996261\n144,532,309,500\n481,774,365\n\n\n12\nround spermatid\nSAMN08375232\nSRR7349192\n52.384556\n140,431,608,000\n468,105,360\n\n\n29\nsperm\nSAMN08375229\nSRR6502360\n26.653940\n64,752,370,800\n215,841,236\n\n\n30\nsperm\nSAMN08375228\nSRR6502362\n23.973440\n58,369,232,700\n194,564,109\n\n\n13\nsperm\nSAMN08375229\nSRR7349193\n52.806276\n141,148,572,300\n470,495,241\n\n\n14\nsperm\nSAMN08375229\nSRR7349195\n22.444378\n60,523,788,600\n201,745,962\n\n\n15\nsperm\nSAMN08375229\nSRR7349196\n38.253606\n104,119,671,000\n347,065,570\n\n\n27\nspermatogonia\nSAMN08375231\nSRR6502356\n22.845286\n58,909,579,800\n196,365,266\n\n\n28\nspermatogonia\nSAMN08375231\nSRR6502357\n17.947471\n46,888,332,900\n156,294,443\n\n\n4\nspermatogonia\nSAMN09427379\nSRR7345462\n18.686342\n52,032,780,000\n173,442,600\n\n\n5\nspermatogonia\nSAMN09427379\nSRR7345463\n29.956561\n82,384,836,000\n274,616,120\n\n\n6\nspermatogonia\nSAMN09427379\nSRR7345464\n39.145759\n105,153,716,100\n350,512,387\n\n\n7\nspermatogonia\nSAMN09427378\nSRR7345465\n35.816184\n96,048,594,600\n320,161,982\n\n\n8\nspermatogonia\nSAMN09427378\nSRR7345467\n28.396816\n77,248,140,900\n257,493,803\n\n\n\n\n\n\n\n\n\n\n\n\nTable 7.2: Summary of the data accessions used in this analysis\n\n\n\n\n\n\n\n\n \nsource_name\nGB\nBases\nReads\n\n\n\n\n0\nfibroblast\n211.403275\n553,968,406,500\n1,846,561,355\n\n\n1\npachytene spermatocyte\n274.835160\n715,656,614,700\n2,385,522,049\n\n\n2\nround spermatid\n243.128044\n655,938,457,200\n2,186,461,524\n\n\n3\nsperm\n164.131640\n428,913,635,400\n1,429,712,118\n\n\n4\nspermatogonia\n192.794420\n518,665,980,300\n1,728,886,601\n\n\n\n\n\n\n\n\n\n\nFolder structure\n\n\nFor ease of mind, here is the folder structure of the project. ../steps/bwa/recPE/ is the base directory artificially defined in the master_workflow.py. It ccould be any other directory inside steps. It is defined relative to the workflow.py file (inside the worklow with os.path.dirname(__file__)), and converted to an absolute path by python.\n\n\n\n\n\n\n../steps/bwa/recPE\n├── cool\n│   ├── fibroblast\n│   ├── pachytene_spermatocyte\n│   ├── round_spermatid\n│   ├── sperm\n│   └── spermatogonia\n└── pairs\n    ├── fibroblast\n    ├── pachytene_spermatocyte\n    ├── round_spermatid\n    ├── sperm\n    └── spermatogonia\n\n12 directories\n\n\n\nFigure 7.1",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#fullmerge-pool-all-from-each-source_name",
    "href": "notebooks/05_rec_compartments.html#fullmerge-pool-all-from-each-source_name",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "FullMerge (pool all from each source_name)",
    "text": "FullMerge (pool all from each source_name)\n\n\nWe will use cooler merge to merge all samples in each sub-folder (cell type) to just one interaction matrix for each cell type. The reason for that is that we choose to trust (Wang et al. 2019) when they say that compartments are highly reproducible between replicates, and by merging all replicates, we will have a more robust signal.\nThus, we will merge all samples from the same source_name into a single cooler file. The coolers are produced to only contain the real chromosomes (1-22, X, Y), and not the mitochondrial DNA or the unplaced contigs (~2,900), as they would not bring any information to the analysis.\nOverview of this section:\n\nLocate the coolers (glob –&gt; dictionary)\nMerge the coolers (cooler.merge_coolers)\nZoomify the merged cooler (cooler.zoomify_cooler) to resolutions: 10kb, 50kb, 100kb, 500kb.\nBalance the matrices (!cooler balance) (use the CLI, as it is more easily parallelized)\n\n\n\n\nCreate cooler dictionary (glob)\n\n\nFirst, we will create a dictionary with the paths to the coolers for each sample. We use glob.glob to fetch all the coolers in each sub-folder that remain after filtering and (automatic) quality control (those are the ones with nodups in their names).\n\n\n\nimport glob\nimport os.path as op\nfrom pprint import pprint as pp\nimport pandas as pd\n\n# Get the list of cell type dirs\nbase_dir = '../steps/bwa/recPE/cool'\nfolders = glob.glob(op.join(base_dir, '*'))\n\nfiles_dict = {f:glob.glob(f\"{f}/*.nodups.*\") for f in folders}\ncooler_dict = {op.basename(k): [op.basename(f) for f in v] for k,v in files_dict.items()}\n#pp(cooler_dict)\ndf = pd.DataFrame.from_dict(cooler_dict, orient='index').T.fillna('-')\ndf[['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']].map(lambda x: x.split('.')[0])\n\n\n\nTable 7.3: Dictionary of coolers for each cell type\n\n\n\n\n\n\n\n\n\n\nfibroblast\nspermatogonia\npachytene_spermatocyte\nround_spermatid\nsperm\n\n\n\n\n0\nSRR6502338\nSRR6502356\nSRR7345459\nSRR7345461\nSRR7349195\n\n\n1\nSRR7349189\nSRR7345467\nSRR6502344\nSRR6502351\nSRR6502360\n\n\n2\nSRR6502335\nSRR6502357\nSRR6502342\nSRR7345460\nSRR7349193\n\n\n3\nSRR6502339\nSRR7345463\nSRR7345458\nSRR6502352\nSRR7349196\n\n\n4\nSRR7349190\nSRR7345465\nSRR7349191\nSRR7349192\nSRR6502362\n\n\n5\nSRR6502337\nSRR7345462\nSRR6502345\nSRR6502353\n-\n\n\n6\nSRR6502336\nSRR7345464\n-\n-\n-\n\n\n\n\n\n\n\n\n\n\n\n\nMerge coolers\n\n\nThe coolers are merged by summing each bin in the matrices, meaning we can only merge matrices with same dimensions. We iterate through the dictionary and merge the coolers with cooler merge. The mergebuf parameter should be adjusted if you don’t have 32G memory. Default: mergebuf = 20000000. Below, we also check if the output file already exists. If it does, we skip the merge.\n\n\n\n# NB adjust `mergebuf` if you don't have 32G of RAM\n\nimport cooler\n\nfor folder,cooler_list in cooler_dict.items():\n    in_uris = [op.join(base_dir, folder, file) for file in cooler_list]\n    out_uri = op.join(base_dir, folder, f'{folder}.fullmerge.cool')\n\n    if op.exists(out_uri):\n        print(f\"Skipping {out_uri}: exists...\")\n        continue\n\n    print(f\"Creating {out_uri} by \\nMerging {len(cooler_list)} coolers into one:\", end=\" \")\n    print(\"\\t\",[file.split('.')[0] for file in cooler_list])\n    cooler.merge_coolers(output_uri=out_uri,\n                         input_uris=in_uris,\n                         mergebuf=int(5e7),\n                         )\n    print(\"... Done!\")\n\nCreating ../steps/bwa/recPE/cool/pachytene_spermatocyte/pachytene_spermatocyte.fullmerge.cool by \nMerging 6 coolers into one:      ['SRR7345459', 'SRR6502344', 'SRR6502342', 'SRR7345458', 'SRR7349191', 'SRR6502345']\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/dask/dataframe/_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 13.0.0. Please consider upgrading.\n  warnings.warn(\n\n\n... Done!\nCreating ../steps/bwa/recPE/cool/spermatogonia/spermatogonia.fullmerge.cool by \nMerging 7 coolers into one:      ['SRR6502356', 'SRR7345467', 'SRR6502357', 'SRR7345463', 'SRR7345465', 'SRR7345462', 'SRR7345464']\n... Done!\nCreating ../steps/bwa/recPE/cool/fibroblast/fibroblast.fullmerge.cool by \nMerging 7 coolers into one:      ['SRR6502338', 'SRR7349189', 'SRR6502335', 'SRR6502339', 'SRR7349190', 'SRR6502337', 'SRR6502336']\n... Done!\nCreating ../steps/bwa/recPE/cool/round_spermatid/round_spermatid.fullmerge.cool by \nMerging 6 coolers into one:      ['SRR7345461', 'SRR6502351', 'SRR7345460', 'SRR6502352', 'SRR7349192', 'SRR6502353']\n... Done!\nCreating ../steps/bwa/recPE/cool/sperm/sperm.fullmerge.cool by \nMerging 5 coolers into one:      ['SRR7349195', 'SRR6502360', 'SRR7349193', 'SRR7349196', 'SRR6502362']\n... Done!\n\n\n\n\nZoomify the merged cooler files\n\n\nAfter merging the coolers, we will zoomify them to resolutions: 10kb, 50kb, 100kb, 500kb. It will recursively create the zoom levels for the cooler file from the ‘base’ resolution (in our case 10kb bins) to the ‘max’ resolution (in our case 500kb bins), and save all zoom levels in a multi-resolution cooler (.mcool) file. The resolutions are stored under the resolutions key in the cooler file (e.g. cell_type.mcool::/resolutions/10000).\nHere, we also check if the output file already exists. If it does, we skip the zoomify. Again, can tailor the chunksize (pixels loaded per process) parameter according to memory availability. I found that the command stalled completely (without quitting) when the memory allocation was not sufficient, as I started out with 32 cores and 32G of RAM. I did not test what was more time-efficient; increasing number of processes or chunksize. After all, it didn’t take long to run anyways.\nFinally, I list the resolutions in the mcool file.\n\n\n\n# NB 8 cores and 32G of RAM was used\n\nimport glob\nimport cooler\nimport os.path as op\n\nbase_dir = '../steps/bwa/recPE/cool'\nmerged_coolers = glob.glob(op.join(base_dir, '*/*.fullmerge.cool'))\n\n\nfor clr in merged_coolers:\n    out_uri = clr.replace('.fullmerge.cool', '.mcool')\n    if op.exists(out_uri):\n        print(f\"Skipping {out_uri}: exists...\")\n        continue\n\n    print(f\"Zoomifying cooler: \\n\\t   {clr}\\n\\t-&gt; {out_uri}\", end=\"\")\n    \n    cooler.zoomify_cooler(base_uris = clr,\n                          outfile = out_uri,\n                          resolutions = [10000,50000,100000,500000],\n                          chunksize = 10000000,\n                          nproc = 8)\n    print(\" --&gt; done\")\n\nZoomifying cooler: \n       ../steps/bwa/recPE/cool/pachytene_spermatocyte/pachytene_spermatocyte.fullmerge.cool\n    -&gt; ../steps/bwa/recPE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/dask/dataframe/_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 13.0.0. Please consider upgrading.\n  warnings.warn(\n\n\n --&gt; done\nZoomifying cooler: \n       ../steps/bwa/recPE/cool/spermatogonia/spermatogonia.fullmerge.cool\n    -&gt; ../steps/bwa/recPE/cool/spermatogonia/spermatogonia.mcool --&gt; done\nZoomifying cooler: \n       ../steps/bwa/recPE/cool/fibroblast/fibroblast.fullmerge.cool\n    -&gt; ../steps/bwa/recPE/cool/fibroblast/fibroblast.mcool --&gt; done\nZoomifying cooler: \n       ../steps/bwa/recPE/cool/round_spermatid/round_spermatid.fullmerge.cool\n    -&gt; ../steps/bwa/recPE/cool/round_spermatid/round_spermatid.mcool --&gt; done\nZoomifying cooler: \n       ../steps/bwa/recPE/cool/sperm/sperm.fullmerge.cool\n    -&gt; ../steps/bwa/recPE/cool/sperm/sperm.mcool --&gt; done\n\n\n\nimport glob\nimport cooler\nmcools = glob.glob(\"../steps/bwa/recPE/cool/*/*.mcool\")\n\nfor mcool in mcools:\n    print(f\"{mcool}:\")\n    print(cooler.fileops.list_coolers(mcool))\n    print()\n\n../steps/bwa/recPE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/recPE/cool/spermatogonia/spermatogonia.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/recPE/cool/fibroblast/fibroblast.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/recPE/cool/round_spermatid/round_spermatid.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n../steps/bwa/recPE/cool/sperm/sperm.mcool:\n['/resolutions/10000', '/resolutions/50000', '/resolutions/100000', '/resolutions/500000']\n\n\n\n\n\nBalance the matrices\n\n\nFinally, we balance the matrices using the cooler CLI. We use the cooler balance command with the default options using 32 cores, which iteratively balances the matrix (Iterative Corecction). It is first described as a method for bias correction of Hi-C matrices in (Imakaev et al. 2012), where it is paired with eigenvector decomposition (ICE). Here the eigenvector decomposition of the obtained maps is shown to provide insights into local chromatin states.\nAccording to cooler documentation, we have to balance the matrices on each resolution, and thus it cannot be done prior to zoomifying. The argument is that the balancing weights are resolution-specific and will no longer retain its meaning when binned with other weights. Therefore, we use a nested for-loop that iterates through all the .mcools and all the resolutions in each .mcool. cooler balance will create a new column in the bins group of each cooler , weight, which can then be included or not in the downstream analysis. This means we will have access to both the balanced and the unbalanced matrix.\nThe default mode uses genome-wide data to calculate the weights for each bin. It would maybe be more suitable to calculate the weights for cis contacts only, and that is possible through the --cis-only flag, and that can be added to another column, so that we can compare the difference between the two methods easily. However, we will only use the default mode for now. The default options are:\n\nignore-diags: 2 (ignore the diagonals (-1,0,1))\nmad-max: 5 (median absolute deviation threshold)\nmin-nnz: 10 (minimum number of non-zero entries before exclusion)\n\nConveniently, cooler balance automatically checks if there is already a weight column, and skips the balancing if it already exists. We can overwrite with --force.\n\n\n\n%%capture balance_out --no-stderr\n\nimport sys\nimport glob\n\nmcools = glob.glob(\"../steps/bwa/recPE/cool/*/*.mcool\")\nresolutions = [10000, 50000, 100000, 500000]\n\nfor mcool in mcools:\n    print(f\"Balancing {mcool}:\", file=sys.stderr)\n    for res in resolutions:\n        full_name = f\"{mcool}::resolutions/{res}\"\n        print(f\"\\tresolution {res}...\", end=\" \", file=sys.stderr)\n        # First, just default values except chunksize (will write to --name weights)\n        !cooler balance -p 32 {full_name}\n        print(\"--&gt; 'weights' done!\", file=sys.stderr)\n        # With only cis-contacts, write to --name cis_weights : It takes ages, maybe not worth it or submit jobs\n        # !cooler balance -p 32 --cis-only --name cis_weights {full_name}\n        #print(\"... 'cis_weights' done!\", file=sys.stderr)\n\nBalancing ../steps/bwa/recPE/cool/pachytene_spermatocyte/pachytene_spermatocyte.mcool:\n    resolution 10000... --&gt; 'weights' done!\n    resolution 50000... --&gt; 'weights' done!\n    resolution 100000... --&gt; 'weights' done!\n    resolution 500000... --&gt; 'weights' done!\nBalancing ../steps/bwa/recPE/cool/spermatogonia/spermatogonia.mcool:\n    resolution 10000... --&gt; 'weights' done!\n    resolution 50000... --&gt; 'weights' done!\n    resolution 100000... --&gt; 'weights' done!\n    resolution 500000... --&gt; 'weights' done!\nBalancing ../steps/bwa/recPE/cool/fibroblast/fibroblast.mcool:\n    resolution 10000... --&gt; 'weights' done!\n    resolution 50000... --&gt; 'weights' done!\n    resolution 100000... --&gt; 'weights' done!\n    resolution 500000... --&gt; 'weights' done!\nBalancing ../steps/bwa/recPE/cool/round_spermatid/round_spermatid.mcool:\n    resolution 10000... --&gt; 'weights' done!\n    resolution 50000... --&gt; 'weights' done!\n    resolution 100000... --&gt; 'weights' done!\n    resolution 500000... --&gt; 'weights' done!\nBalancing ../steps/bwa/recPE/cool/sperm/sperm.mcool:\n    resolution 10000... --&gt; 'weights' done!\n    resolution 50000... --&gt; 'weights' done!\n    resolution 100000... --&gt; 'weights' done!\n    resolution 500000... --&gt; 'weights' done!\n\n\n\n# Display the balancing stdout if you want (but it is up to 200 lines per cooler)\n#balance_out()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#repmerge-pool-all-from-each-biosample-id",
    "href": "notebooks/05_rec_compartments.html#repmerge-pool-all-from-each-biosample-id",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "RepMerge (pool all from each BioSample ID)",
    "text": "RepMerge (pool all from each BioSample ID)\n\n\nInitially, I planned to re-create the replicates that they used in the paper, but I reason that it is not necessary and might even be better to pool all the samples in stead. They state alredy that their compartments are highly repdoducible between replicates, so I choose to trust that and not bother with the replicates.\nTherefore, this section was only briefly initialized, and now it is commented out.\n\n\n\n#df.groupby(['source_name','BioSample'])['Reads'].sum()\n\n\n# from pprintpp import pprint as pp\n\n# grouped_df = df.groupby(['source_name','BioSample'])\n\n# # Initialize an empty dictionary\n# rep_dict = {}\n\n# # Iterate over each group\n# for (source_name, BioSample), group in grouped_df:\n#     # Extract the 'Run' column and convert it to a list\n#     run_list = group['Run'].tolist()\n    \n#     # Populate the nested dictionary\n#     if source_name not in rep_dict:\n#         rep_dict[source_name] = {}\n#     rep_dict[source_name][BioSample] = run_list\n\n# pp(rep_dict)\n\n\n# for source_name, BioSample_dict in rep_dict.items():\n#     print(f\"source_name: {source_name}\")\n#     print(f\"Changing working dir: {source_name}/\")\n#     for BioSample, run_list in BioSample_dict.items():\n#         print(f\"Merging samples for BioSample: {BioSample}: {run_list}\")",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#kb-resolution",
    "href": "notebooks/05_rec_compartments.html#kb-resolution",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "500kb resolution",
    "text": "500kb resolution\n\nAll 5 full merges\n\nLoad coolers\n\nimport glob\nimport os.path as op\nimport cooler\n\nmcools = glob.glob(\"../steps/bwa/recPE/cool/*/*.mcool\")\nres = \"::resolutions/500000\"\n\nclrs = {op.basename(op.dirname(mcool)): cooler.Cooler(mcool+res) for mcool in mcools}\n\nchron_order = ['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']\nabbr_list = ['Fb', 'SPA', 'PAC', 'RS', 'SP']\nabbr = {key: abbr_list[i] for i,key in enumerate(chron_order)}\n\nclrs = {key: clrs[key] for key in chron_order}\nclrs\n\n{'fibroblast': &lt;Cooler \"fibroblast.mcool::/resolutions/500000\"&gt;,\n 'spermatogonia': &lt;Cooler \"spermatogonia.mcool::/resolutions/500000\"&gt;,\n 'pachytene_spermatocyte': &lt;Cooler \"pachytene_spermatocyte.mcool::/resolutions/500000\"&gt;,\n 'round_spermatid': &lt;Cooler \"round_spermatid.mcool::/resolutions/500000\"&gt;,\n 'sperm': &lt;Cooler \"sperm.mcool::/resolutions/500000\"&gt;}\n\n\n\n\nCalculate gc covariance (from the reference genome)\nDo this with any of the clrs - it just needs the bins positions.\n\n# Try with only the gc_cov for chrX\n\nimport bioframe\nimport pandas as pd\nimport os.path as op\n\nbins = clrs['fibroblast'].bins().fetch('chrX')[:]\nout_name = '../steps/rheMac10_gc_cov_X_500kb.tsv'\n\nrheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\nif not op.exists(out_name):\n    print('Calculate the fraction of GC basepairs for each bin')\n    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n    gc_cov.to_csv(out_name, index=False,sep='\\t')\n    print(gc_cov.info())\nelse: \n    print(\"Already exists, read from file\")\n    gc_cov = pd.read_csv(out_name, sep='\\t')\n    print(gc_cov.info())\n\nAlready exists, read from file\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 307 entries, 0 to 306\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   chrom   307 non-null    object \n 1   start   307 non-null    int64  \n 2   end     307 non-null    int64  \n 3   GC      307 non-null    float64\ndtypes: float64(1), int64(2), object(1)\nmemory usage: 9.7+ KB\nNone\n\n\n\n\nCalculate the E1 compartments\nLoop: view_df, cis_eigs, e1_values\n\nPlot GC covariance\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(\n    figsize=(10, 2),\n)\n\nax.plot(gc_cov['start'],gc_cov['GC'])\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nChromosome restricted E1 compartments\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\nimport pandas as pd\n\neigs_full = {}\ne1_values_full = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Divide into chromosome arms\nclr = clrs['fibroblast']\nview_df_full = pd.DataFrame(\n    {\n    'chrom': 'chrX',\n    'start': 0,\n    'end': chrX_size,\n    'name': 'chrX'\n    }, index=[0]\n                      )\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}, size {clr.binsize}\")\n    cis_eigs_full = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df_full,\n                        n_eigs=3,\n                        )\n    eigs_full[name] = cis_eigs_full[1]\n    e1_track_full = cis_eigs_full[1][['chrom','start','end','E1']]\n    e1_values_full[name] = e1_track_full['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm, size 500000\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nChromosome arms restricted\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\nimport pandas as pd\n\neigs = {}\ne1_values = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Divide into chromosome arms\nview_df = pd.DataFrame(\n    {\n    'chrom': 'chrX',\n    'start': [0, 59_000_001],\n    'end': [59_000_000, chrX_size],\n    'name': ['X_short', 'X_long']\n    }, index=[0,1]\n                      )\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}\")\n    cis_eigs = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df,\n                        n_eigs=3,\n                        )\n    eigs[name] = cis_eigs[1]\n    e1_track = cis_eigs[1][['chrom','start','end','E1']]\n    e1_values[name] = e1_track['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte\nCalculating eigenvectors for round_spermatid\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nRefined: 10Mb windows restricted\n\n# Use gc_cov to calculate eigenvectors with cooltools.eigs_cis\n\nimport cooltools\n\neigs_10mb = {}\ne1_values_10mb = {}\n\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\n# Calculate in 10Mb windows\n# Define the window size (10Mb)\n\nwindow_size = 10_000_000\n\n# Generate the start and end positions for each window\nstart_positions = list(range(0, chrX_size, window_size))\nend_positions = [min(start + window_size, chrX_size) for start in start_positions]\n# Create the DataFrame\nview_df_10mb = pd.DataFrame({\n    'chrom': ['chrX'] * len(start_positions),\n    'start': start_positions,\n    'end': end_positions,\n    'name': [f'X_{i}' for i in range(len(start_positions))]\n})\n#display(view_df)\n\nfor name, clr in clrs.items():\n    print(f\"Calculating eigenvectors for {name}\")\n    cis_eigs_10mb = cooltools.eigs_cis(\n                        clr,\n                        gc_cov,\n                        view_df=view_df_10mb,\n                        n_eigs=3,\n                        )\n    eigs_10mb[name] = cis_eigs_10mb[1]\n    e1_track_10mb = cis_eigs_10mb[1][['chrom','start','end','E1']]\n    e1_values_10mb[name] = e1_track_10mb['E1'].values\n\n#eigs\n\nCalculating eigenvectors for fibroblast\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\nSave the A compartment coordinates, also E1 track\n\n######## Restriction: chromosome arm E1 values ########\nimport importlib\nimport hicstuff\nimport os\nimportlib.reload(hicstuff)\nfrom hicstuff import extract_a_coordinates\n\n\n# Binsize in bp\nres = 500_000\noutdir = '../results/rec_compartments/'\nif not os.path.exists(outdir):\n    os.makedirs(outdir)\n    \n\n######## Restriction: full chromosome E1 values ########\nrestriction = 'full'\nfor name, e1 in e1_values_full.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\n######## Restriction: chromosome arm E1 values ########\nrestriction = 'arms'\nfor name, e1 in e1_values.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\n######## Restriction: 10Mb E1 values ########\nrestriction = '10Mb'\nfor name, e1 in e1_values_10mb.items():\n    extract_a_coordinates(e1=e1, name=name, restriction=restriction, chrom='chrX', res=500_000, csv=True,output_dir=outdir, force=True)\n\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_500kb_full.csv\nFile ../results/rec_compartments/fibroblast_e1_500kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_500kb_full.csv\nFile ../results/rec_compartments/spermatogonia_e1_500kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_full.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_500kb_full.csv\nFile ../results/rec_compartments/round_spermatid_e1_500kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_500kb_full.csv\nFile ../results/rec_compartments/sperm_e1_500kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_500kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_500kb_arms.csv\nFile ../results/rec_compartments/fibroblast_e1_500kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_500kb_arms.csv\nFile ../results/rec_compartments/spermatogonia_e1_500kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_arms.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_500kb_arms.csv\nFile ../results/rec_compartments/round_spermatid_e1_500kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_500kb_arms.csv\nFile ../results/rec_compartments/sperm_e1_500kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_500kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_500kb_10Mb.csv\nFile ../results/rec_compartments/fibroblast_e1_500kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_500kb_10Mb.csv\nFile ../results/rec_compartments/spermatogonia_e1_500kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_10Mb.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_500kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_500kb_10Mb.csv\nFile ../results/rec_compartments/round_spermatid_e1_500kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_500kb_10Mb.csv\nFile ../results/rec_compartments/sperm_e1_500kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_500kb_10Mb.csv already exists. Overwriting.\n\n\n\n\nPlot NaN histogram\n\n# Check the number of NaN values in the E1 column and create a DataFrame\nnan_counts = {k: {'length': len(v), 'NaNs': np.isnan(v).sum()} for k, v in e1_values.items()}\n#display(pd.DataFrame.from_dict(nan_counts, orient='index'))\n\n# Locate the NaN values (histogram)\n#import matplotlib.pyplot as plt\n\nf, ax = plt.subplots(1, 5, figsize=(6,1.8), sharey=True) # dont share x as they have a different median tick!!!\nfor i, (name, track) in enumerate(eigs.items()):\n    e1 = track['E1'].values\n    # Locate NaN values\n    e1_nan = np.where(np.isnan(e1))\n    # Plot histogram\n    ax[i].hist(e1_nan, bins=100)\n    \n    # Plot median line\n    median_pos = np.median(e1_nan) # (1Mb/500Kb) account for binning (res=500kb, target 1Mb y-axis)\n#    mean_pos = round(np.mean(e1_nan), 2)\n    ax[i].axvline(median_pos, color='r', lw=0.5, ls='--')\n#    ax[i].axvline(mean_pos, color='g', lw=0.5, ls='--')\n\n    # Layout\n    ax[i].set_title(abbr[name])\n    xticks = np.linspace(0, len(e1), num=5)\n    xticks = np.append(xticks, median_pos)  # Add median position to xticks\n#    xticks = np.append(xticks, mean_pos)  # Add mean position to xticks\n    ax[i].set_xticks(xticks)\n    xticklabels = np.linspace(0, len(e1) * 0.5, num=5, dtype = 'int').tolist()\n    xticklabels.append(median_pos*0.5)  # Add median label\n#    xticklabels.append(mean_pos*0.5)  # Add mean label\n    ax[i].set_xticklabels(xticklabels, rotation=50, fontsize=6)\n    #ax[i].set_xlabel('Position (Mbp)')\n\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nf.supxlabel('Position (Mbp)')\nplt.show()\n                    \n\n\n\n\n\n\n\nFigure 8.6: Histogram of NaN values in the E1 eigenvector for each cell type. Median position is marked with a red dashed line.\n\n\n\n\n\n\n\n\nPlot the E1 compartments\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.patches import Rectangle\n\nres = 500_000\nnames_abbr = {'fibroblast': 'Fibroblast', 'spermatogonia': 'Spermatogonia', 'pachytene_spermatocyte': 'Pachytene Spermatogonia', 'round_spermatid': 'Round Spermatid', 'sperm': 'Sperm'}\n\nchrom_start = e1_track_full['start'].values\nchrom_end = e1_track_full['end'].values-1\n\nf, axs = plt.subplots(5, 3, figsize=(18, 8), sharex=True, sharey=True)\n\n# Populate the first column\naxs[0,0].set_title('E1: Full-chromosome restricted')\nfor i, (name, e1) in enumerate(e1_values_full.items()):\n    ax = axs[i,0]\n    ax.set_ylabel(names_abbr[name])\n\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', linewidth=0)\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', linewidth=0)\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_full.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Populate the second column\naxs[0,1].set_title('E1: Chromosome-arms restricted')\nfor i, (name, e1) in enumerate(e1_values.items()):\n    ax = axs[i,1]\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', linewidth=0)\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', linewidth=0)\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_arms.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Populate the third column\naxs[0,2].set_title('E1: 10Mb restricted (refined)')\nfor i, (name, e1) in enumerate(e1_values_10mb.items()):\n    ax = axs[i,2]\n    #ax.set_title(name)\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n\n    ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', ec='None')\n    ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', ec='None')\n\n    # Test to see how well my coordinates match the e1 values\n    coords = pd.read_csv(f'../results/compartments/{name}_a_comp_coords_500kb_10Mb.csv')\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(coords['start'], coords['end']):\n        rect = Rectangle((start, 0.2), width=end-start, height=0.05, color='k', linewidth=0.05)\n        ax.add_patch(rect)\n\n# Set y-limits for all subplots\nfor ax in axs.flat:\n    ax.set_ylim(-0.8, 0.8)\n    ax.spines[:].set_visible(False)\n    ax.set_yticks([])\n    ax.set_xticks([])\n\nplt.tight_layout()\nplt.savefig('../steps/rec_e1_plot_full.svg', bbox_inches='tight')\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution. Left: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.\n\n\n\n\n\n\nPlot matrices with compartments (round spermatid)\n\nimport cooltools.lib.plotting\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom cooltools.lib.numutils import adaptive_coarsegrain, interp_nan\n\n\n\nclr = clrs['round_spermatid']\nchrom_start, chrom_end = e1_track_full['start'].values, e1_track_full['end'].values-1\ne1 = e1_values_10mb['round_spermatid']\nnbins = len(clr.bins().fetch('chrX'))\n\nf, ax = plt.subplots(\n    figsize=(3,3),\n)\n\nnorm = LogNorm(vmax=0.1)\n\ne1_list = [e1_values_10mb['round_spermatid'], e1_values['round_spermatid'], e1_values_full['round_spermatid']]\ne1_names = ['10Mb', 'Arms', 'Full']\ncolors = ['tab:red', 'tab:blue', 'tab:green']\n\n# ### Coursegrain and interpolate (beautify)\n# cg = adaptive_coarsegrain(clr.matrix(balance=True).fetch('chrX'),\n#                           clr.matrix(balance=False).fetch('chrX'),\n#                           cutoff=3, max_levels=8, )\n# cgi = interp_nan(cg, method='nearest')\n\nim = ax.matshow(\n    clr.matrix().fetch('chrX'),\n    norm=norm,\n    cmap='fall',\n);\nplt.axis([0,nbins,nbins,0])\n\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"4%\", pad=0.05)\nplt.colorbar(im, cax=cax, label='Corrected frequencies')\nax.set_ylabel('Position (Mbp)')\nax.xaxis.set_visible(False)\nyticks = np.linspace(0, nbins, 5, dtype=int)\nyticklabels = yticks*500_000//1_000_000\nax.set_yticks(yticks)\nax.set_yticklabels(yticklabels)\n\n\n\nfor i, e1 in enumerate(e1_list):\n    ax1 = divider.append_axes(\"top\", size=\"10%\", pad=0.05, sharex = ax)\n\n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    #smooth_y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start/500_000\n    x[1::2] = chrom_end/500_000\n    y[0::2] = e1\n    y[1::2] = e1\n    # smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n    # smooth_y[0::2] = smooth_e1\n    # smooth_y[1::2] = smooth_e1\n\n\n    ax1.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', ec='None')\n    ax1.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', ec='None')\n\n    ax1.set_ylabel(e1_names[i], rotation=0, labelpad=5, ha='right', va='center')\n    ax1.set_ylim(-0.8, 0.8)\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n\n    # if e1_names[i] == '10Mb':\n    #     # Plot the sign changes on the matrix \n    #     col = 'k' #colors[i]\n    #     for i in np.where(np.diff( (pd.Series(e1)&gt;0).astype(int)))[0]:\n    #         # Horisontal lines where E1 intersects 0\n    #         ax.plot([0,nbins],[i,i],col,lw=0.5)\n\n    #         # Vertical lines where E1 intersects 0\n    #         ax.plot([i,i],[0,nbins],col,lw=0.2)\n\nax1.set_title('Round Spermatid: 500kb bins')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nFigure 8.7: E1 eigenvector values for merged round spermatid samples at 500kb resolution, as well as the interaction matrix. E1 was restricted to either Full-chromosome (top), Chromosome-arms (middle), or 10Mb windows (bottom).\n\n\n\n\n\n\n\nSliding window summed E1 compartments\nTo mimic the smoothing applied in the Wang et al. 2019 paper, where they slide a 400kb window in 100kb steps on the obs/exp matrix, we will similarly slide a 400kb window in 100kb steps directly on the E1 compartments.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport pandas as pd\nfrom scipy.signal.windows import triang\n\nresolution = 500_000\nwindow_size = 2_500_000\nstep_size = window_size // resolution\n\nchrom_start = e1_track['start'].values\nchrom_end = e1_track['end'].values-1\n\nf, axs = plt.subplots(5, 2, figsize=(30, 10), sharex=True)\n\naxs[0, 0].set_title('Chromosome-arm E1 (arm restricted)')\naxs[0, 1].set_title('Smoothed by summation')\n\nfor i, (name, e1) in enumerate(e1_values.items()):\n    # print(i, name, e1.size)\n    smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))\n\n    ax0 = axs[i, 0]\n    ax1 = axs[i, 1]\n    \n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    smooth_y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start\n    x[1::2] = chrom_end\n    y[0::2] = e1\n    y[1::2] = e1\n    smooth_y[0::2] = smooth_e1['value'].values\n    smooth_y[1::2] = smooth_e1['value'].values\n\n\n    ax0.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red')\n    ax0.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue')\n    \n    # Overlay the smoothed line (divided by 5 to make it a mean)\n    ax0.plot(x, smooth_y/5, color='C1')\n\n    ax1.fill_between(x, smooth_y, 0, where=(smooth_y &gt; 0), color='tab:red')\n    ax1.fill_between(x, smooth_y, 0, where=(smooth_y &lt; 0), color='tab:blue')\n\n    ax0.set_ylabel(name)\n    ylim = 1.5\n    #ax0.set_ylim(-ylim, ylim)\n    #ax1.set_ylim(-ylim*4, ylim*4)\n\nfor ax in axs.flat:\n    ax.spines[:].set_visible(False)\n    ax.set_xticks([])\n    #ax.set_yticks([])\n\n# plt.tight_layout()\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution with rolling summation, with window size 2.5Mb, step size 500Kb: Each value is now the sum of the surrounding n=5 bins.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#kb-resolution-1",
    "href": "notebooks/05_rec_compartments.html#kb-resolution-1",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "100kb resolution",
    "text": "100kb resolution\n\nAll 5 full merges\n\nLoad coolers\n\nimport glob\nimport os.path as op\nimport cooler\n\nmcools = glob.glob(\"../steps/bwa/recPE/cool/*/*.mcool\")\nres = \"::resolutions/100000\"\n\nclrs = {op.basename(op.dirname(mcool)): cooler.Cooler(mcool+res) for mcool in mcools}\n\nchron_order = ['fibroblast', 'spermatogonia', 'pachytene_spermatocyte', 'round_spermatid', 'sperm']\n\nclrs = {key: clrs[key] for key in chron_order}\nclrs\n\nnames_abbr = {'fibroblast': 'Fib', 'spermatogonia': 'SPA', 'pachytene_spermatocyte': 'PAC', 'round_spermatid': 'RS', 'sperm': 'Sp'}\n\n# Calculate chromstart and chromend for each bin on chrX\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\nchrom_start = clrs['fibroblast'].bins().fetch('chrX')['start'].values\nchrom_end = clrs['fibroblast'].bins().fetch('chrX')['end'].values-1\nnbins = len(clrs['fibroblast'].bins().fetch('chrX'))\nbinsize = clrs['fibroblast'].binsize\n\n\n\nCalculate gc covariance (from the reference genome)\nDo this with any of the clrs - it just needs the bins positions.\n\n# Try with only the gc_cov for chrX\n\nimport bioframe\nimport pandas as pd\nimport os.path as op\n\nbins = clrs['fibroblast'].bins().fetch('chrX')[:]\nout_name = '../steps/rheMac10_gc_cov_X_100kb.tsv'\n\nrheMac10 = bioframe.load_fasta('../data/links/ucsc_ref/rheMac10.fa')\nif not op.exists(out_name):\n    print('Calculate the fraction of GC basepairs for each bin')\n    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], rheMac10)\n    gc_cov.to_csv(out_name, index=False,sep='\\t')\n    print(gc_cov.info())\nelse: \n    print(\"Already exists, read from file\")\n    gc_cov = pd.read_csv(out_name, sep='\\t')\n    print(gc_cov.info())\n\nAlready exists, read from file\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1534 entries, 0 to 1533\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   chrom   1534 non-null   object \n 1   start   1534 non-null   int64  \n 2   end     1534 non-null   int64  \n 3   GC      1533 non-null   float64\ndtypes: float64(1), int64(2), object(1)\nmemory usage: 48.1+ KB\nNone\n\n\n\n\nCalculate the E1 compartments\nLoop: view_df, cis_eigs, e1_values\n\nPlot GC covariance\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize=(10, 2))\n\nax.plot(gc_cov['start'],gc_cov['GC'])\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nCreate viewframes: full, arms, 10Mb windows\n\nimport pandas as pd\n\n# Fetch the chromsize of X from one of the coolers\nchrX_size = clrs['fibroblast'].chromsizes['chrX']\n\nviews = {}\n\n# Make the full view frame\nviews['full'] = pd.DataFrame({\n    'chrom': 'chrX',\n    'start': 0,\n    'end': chrX_size,\n    'name': 'chrX'}, index=[0])\n\n# Divide into chromosome arms\nviews['arms'] = pd.DataFrame({\n    'chrom': 'chrX',\n    'start': [0, 59_000_001],\n    'end': [59_000_000, chrX_size],\n    'name': ['X_short', 'X_long']}, index=[0,1])\n\n# Calculate in 10Mb windows\nwindow_size = 10_000_000\nstart_positions = list(range(0, chrX_size, window_size))\nend_positions = [min(start + window_size, chrX_size) for start in start_positions]\n\n# Create the DataFrame\nviews['10Mb'] = pd.DataFrame({\n    'chrom': ['chrX'] * len(start_positions),\n    'start': start_positions,\n    'end': end_positions,\n    'name': [f'X_{i}' for i in range(len(start_positions))]\n})\n\n\n\nCalulate the E1 compartments\n\nimport cooltools\n\neigs = {}\ne1_values = {}\n\nfor name, clr in clrs.items():\n    if name not in eigs or name not in e1_values:\n        eigs[name] = {} \n        e1_values[name] = {}\n    for view, view_df in views.items():\n        print(f\"Calculating eigenvectors for {name} at {view}\")\n        cis_eigs = cooltools.eigs_cis(\n                            clr,\n                            gc_cov,\n                            view_df=view_df,\n                            n_eigs=1)\n        eigs[name][view] = cis_eigs[1]\n        e1_values[name][view] = cis_eigs[1]['E1'].values\n        \n\n\nCalculating eigenvectors for fibroblast at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for fibroblast at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for fibroblast at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for spermatogonia at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for pachytene_spermatocyte at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for round_spermatid at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at full\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at arms\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\nCalculating eigenvectors for sperm at 10Mb\n\n\n/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/cooltools/lib/common.py:489: UserWarning: less than 50% of valid bins have been assigned a value\n  warnings.warn(\"less than 50% of valid bins have been assigned a value\")\n\n\n\n\n\nExtract the A compartment coordinates as well as E1 track\n\nimport importlib\nimport hicstuff\nimportlib.reload(hicstuff)\nfrom hicstuff import extract_a_coordinates\n\n\nres = 100_000\noutdir = '../results/rec_compartments/'\n\nfor name, view_df in e1_values.items():\n    print(f\"Calculating A-compartment intervals for {name}\")\n    for view, e1 in view_df.items():\n        print(view)\n        extract_a_coordinates(\n            e1=e1,\n            name=name,\n            restriction=view,\n            chrom='chrX',\n            res=res,\n            csv=True,\n            output_dir=outdir,\n            force=True\n        )\n        extract_a_coordinates(\n            e1=e1,\n            name=name,\n            restriction=view,\n            chrom='chrX',\n            res=res,\n            csv=True,\n            output_dir=outdir,\n            smooth=True,\n            force=True\n        )\n    \n\nCalculating A-compartment intervals for fibroblast\nfull\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_full.csv\nFile ../results/rec_compartments/fibroblast_e1_100kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_arms.csv\nFile ../results/rec_compartments/fibroblast_e1_100kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_10Mb.csv\nFile ../results/rec_compartments/fibroblast_e1_100kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/fibroblast_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for fibroblast\nFile ../results/rec_compartments/fibroblast_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nfull\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_full.csv\nFile ../results/rec_compartments/spermatogonia_e1_100kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_arms.csv\nFile ../results/rec_compartments/spermatogonia_e1_100kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_10Mb.csv\nFile ../results/rec_compartments/spermatogonia_e1_100kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/spermatogonia_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for spermatogonia\nFile ../results/rec_compartments/spermatogonia_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nfull\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_full.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_arms.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_10Mb.csv\nFile ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/pachytene_spermatocyte_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for pachytene_spermatocyte\nFile ../results/rec_compartments/pachytene_spermatocyte_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nfull\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_full.csv\nFile ../results/rec_compartments/round_spermatid_e1_100kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_arms.csv\nFile ../results/rec_compartments/round_spermatid_e1_100kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_10Mb.csv\nFile ../results/rec_compartments/round_spermatid_e1_100kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/round_spermatid_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for round_spermatid\nFile ../results/rec_compartments/round_spermatid_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nfull\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_full.csv\nFile ../results/rec_compartments/sperm_e1_100kb_full.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_full.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_full_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_full_smoothed.csv already exists. Overwriting.\narms\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_arms.csv\nFile ../results/rec_compartments/sperm_e1_100kb_arms.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_arms.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_arms_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_arms_smoothed.csv already exists. Overwriting.\n10Mb\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_10Mb.csv\nFile ../results/rec_compartments/sperm_e1_100kb_10Mb.csv already exists. Overwriting.\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_10Mb.csv already exists. Overwriting.\nSaving eigenvector track to: ../results/rec_compartments/sperm_e1_100kb_10Mb_smoothed.csv\nCalculating A-compartment intervals for sperm\nFile ../results/rec_compartments/sperm_a_comp_coords_100kb_10Mb_smoothed.csv already exists. Overwriting.\n\n\n\n\nPlot the E1 compartments\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nset_matplotlib_formats('retina')\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nf, axs = plt.subplots(5, 3, figsize=(10, 5), sharex=True, sharey=True)\n\n# Loop through eigs and e1_values to plot the E1 values\nfor i, (name, e1_dict) in enumerate(e1_values.items()):\n    axs[i,0].set_ylabel(names_abbr[name], fontsize=8)\n    for j, (view, e1) in enumerate(e1_dict.items()):\n        ax = axs[i, j]\n\n        if i==0:\n            ax.set_title(view)\n\n        # Create stairs\n        x = np.zeros(2*chrom_start.size)\n        y = np.zeros(2*chrom_start.size)\n        smooth_y = np.zeros(2*chrom_start.size)\n        x[0::2] = chrom_start\n        x[1::2] = chrom_end\n        y[0::2] = e1\n        y[1::2] = e1\n        smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n        smooth_y[0::2] = smooth_e1\n        smooth_y[1::2] = smooth_e1\n\n\n        ax.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', ec = 'None')\n        ax.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', ec = 'None')\n        # ax.plot(x, smooth_y/5, color='C1', linewidth=0.5)\n\n        # ax.fill_between(x, smooth_y, 0, where=(smooth_y &gt; 0), color='tab:red', ec = 'None')\n        # ax.fill_between(x, smooth_y, 0, where=(smooth_y &lt; 0), color='tab:blue', ec = 'None')\n\n        # # Test to see how well my coordinates match the e1 values\n        # coords = pd.read_csv(f'../results/rec_compartments/{name}_a_comp_coords_100kb_{view}_smoothed.csv')\n        # # Iterate over each interval in the DataFrame\n        # for start, end in zip(coords['start'], coords['end']):\n        #     rect = Rectangle((start, -0.2), width=end-start, height=-0.3, color='k', alpha=0.6, ec = 'None')\n        #     ax.add_patch(rect)\n\n# Set y-limits for all subplots\nfor ax in axs.flat:\n    ax.set_ylim(-1, 1)\n    ax.spines[:].set_visible(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.savefig('../steps/rec_e1_plot_full_100kb_smoothed.svg', bbox_inches='tight')\n        \n    \n\n\n\n\nE1 eigenvector values for all merged samples at 100kb resolution. Left: Chromosomes (not restricted) Middle: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.Values are smoothed with a sliding window of 5 bins, step size 1 bin.\n\n\n\n\n\n\nPlot matrices with compartments\n\nimport cooltools.lib.plotting\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom cooltools.lib.numutils import adaptive_coarsegrain, interp_nan\n\nf, axs = plt.subplots(1,5,\n    figsize=(25,10)\n)\n\nnorm = LogNorm(vmax=0.1)\n\n# Loop through the clrs and its matrix: plot the matrix on its axis\nfor i, (name, e1_dict) in enumerate(e1_values.items()):\n    ax = axs[i]\n\n    im = ax.matshow(\n        clrs[name].matrix().fetch('chrX'),\n        norm=norm,\n        cmap='fall',\n    );\n    ax.set_xlim(0, nbins)\n    ax.set_ylim(nbins, 0)\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\n    plt.colorbar(im, cax=cax, label='corrected frequencies');\n    ax.set_ylabel('chrX:100kb bins, #bin')\n    ax.xaxis.set_visible(False)\n\n    for j, (view, e1) in enumerate(e1_dict.items()):\n        ax1 = divider.append_axes(\"top\", size=\"10%\", pad=0.1, sharex = ax)\n\n        # ax1.plot(e1, label='E1')\n\n        # Create stairs\n        x = np.zeros(2*chrom_start.size)\n        y = np.zeros(2*chrom_start.size)\n        #smooth_y = np.zeros(2*chrom_start.size)\n        x[0::2] = chrom_start/binsize\n        x[1::2] = chrom_end/binsize\n        y[0::2] = e1\n        y[1::2] = e1\n        # smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n        # smooth_y[0::2] = smooth_e1\n        # smooth_y[1::2] = smooth_e1\n\n\n        ax1.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', ec = 'None')\n        ax1.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', ec = 'None')\n\n        ax1.set_ylabel(view, rotation=-70)\n        ax1.set_ylim(-0.8, 0.8)\n        ax1.set_xticks([])\n\n    ax1.set_title(abbr[name])\n\n#    # Plot the sign changes on the matrix \n#     col = colors[i]\n#     for i in np.where(np.diff( (pd.Series(e1)&gt;0).astype(int)))[0]:\n#         # Horisontal lines where E1 intersects 0\n#         ax.plot([0,nbins],[i,i],col,lw=0.5)\n\n#         # Vertical lines where E1 intersects 0\n#         ax.plot([i,i],[0,nbins],col,lw=0.5)\n\n# Now show the plot\nf.set_layout_engine('compressed')\nf.canvas.draw()\nplt.show()\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution for round spermatid, as well as the interaction matrix. E1 was restricted to top: Full-chromosome, middle: Chromosome-arms, bottom: 10Mb window.\n\n\n\n\n\nimport cooltools.lib.plotting\nfrom matplotlib.colors import LogNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n\n\nclr = clrs['round_spermatid']\nnbins = len(clr.bins().fetch('chrX'))\n\nf, ax = plt.subplots(\n    figsize=(3,3),\n)\n\nnorm = LogNorm(vmax=0.1)\n\ne1_dict = e1_values['round_spermatid']\ne1_order = ['10Mb', 'arms', 'full']\ne1_names_abbr = {'10Mb': '10Mb', 'arms': 'Arms', 'full': 'Full'}\ncolors = ['tab:red', 'tab:blue', 'tab:green']\n\n# ### Coursegrain and interpolate (beautify)\n# cg = adaptive_coarsegrain(clr.matrix(balance=True).fetch('chrX'),\n#                           clr.matrix(balance=False).fetch('chrX'),\n#                           cutoff=3, max_levels=8, )\n# cgi = interp_nan(cg, method='nearest')\n\nim = ax.matshow(\n    clr.matrix().fetch('chrX'),\n    norm=norm,\n    cmap='fall',\n);\nplt.axis([0,nbins,nbins,0])\n\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"4%\", pad=0.05)\nplt.colorbar(im, cax=cax, label='corrected frequencies');\nax.set_ylabel('Position (Mbp)')\nax.xaxis.set_visible(False)\nyticks = np.linspace(0, nbins, 5, dtype=int)\nyticklabels = yticks*100_000//1_000_000\nax.set_yticks(yticks)\nax.set_yticklabels(yticklabels)\n\n\n\nfor i, name in enumerate(e1_order):\n    e1 = e1_dict[name]\n    ax1 = divider.append_axes(\"top\", size=\"10%\", pad=0.05, sharex = ax)\n\n    # Create stairs\n    x = np.zeros(2*chrom_start.size)\n    y = np.zeros(2*chrom_start.size)\n    #smooth_y = np.zeros(2*chrom_start.size)\n    x[0::2] = chrom_start/100_000\n    x[1::2] = chrom_end/100_000\n    y[0::2] = e1\n    y[1::2] = e1\n    # smooth_e1 = (lambda x: x.rolling(5, 1, center=True).sum())(pd.DataFrame(e1, columns=['value']))['value'].values\n    # smooth_y[0::2] = smooth_e1\n    # smooth_y[1::2] = smooth_e1\n\n\n    ax1.fill_between(x, y, 0, where=(y &gt; 0), color='tab:red', ec = 'None')\n    ax1.fill_between(x, y, 0, where=(y &lt; 0), color='tab:blue', ec = 'None')\n\n    ax1.set_ylabel(e1_names_abbr[name], rotation=0, labelpad=5, ha='right', va='center')\n    ax1.set_ylim(-0.8, 0.8)\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n\n    # if e1_names[i] == '10Mb':\n    #     # Plot the sign changes on the matrix \n    #     col = 'k' #colors[i]\n    #     for i in np.where(np.diff( (pd.Series(e1)&gt;0).astype(int)))[0]:\n    #         # Horisontal lines where E1 intersects 0\n    #         ax.plot([0,nbins],[i,i],col,lw=0.5)\n\n    #         # Vertical lines where E1 intersects 0\n    #         ax.plot([i,i],[0,nbins],col,lw=0.2)\n\nax1.set_title('Round Spermatid: 100kb bins')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nFigure 8.8: E1 eigenvector values for merged round spermatid samples at 500kb resolution, as well as the interaction matrix. E1 was restricted to either Full-chromosome (top), Chromosome-arms (middle), or 10Mb windows (bottom).",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/05_rec_compartments.html#we-continue-plotting-in-the-next-notebook",
    "href": "notebooks/05_rec_compartments.html#we-continue-plotting-in-the-next-notebook",
    "title": "Compartments Analysis w. recommended parameters",
    "section": "We continue plotting in the next notebook:",
    "text": "We continue plotting in the next notebook:\nLink to notebook: Various Comparisons (07_various_plotting.ipynb)\n\n\n\n\nImakaev, Maxim, Geoffrey Fudenberg, Rachel Patton McCord, Natalia Naumova, Anton Goloborodko, Bryan R Lajoie, Job Dekker, and Leonid A Mirny. 2012. “Iterative Correction of Hi-C Data Reveals Hallmarks of Chromosome Organization.” Nature Methods 9 (10): 999–1003. https://doi.org/10.1038/nmeth.2148.\n\n\nWang, Yao, Hanben Wang, Yu Zhang, Zhenhai Du, Wei Si, Suixing Fan, Dongdong Qin, et al. 2019. “Reprogramming of Meiotic Chromatin Architecture During Spermatogenesis.” Molecular Cell 73 (3): 547–561.e6. https://doi.org/10.1016/j.molcel.2018.11.019.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Compartments Analysis w. recommended parameters</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html",
    "href": "notebooks/06_rec_genomicintervals.html",
    "title": "E1 vs. ECH (recommended params)",
    "section": "",
    "text": "The genomic regions in question\nIn 05_rec_compartments.ipynb we extracted the genomic intervals of A compartments on all cell types in all combinations of the following parameters:\nResulting in 45 .csv files. They are saved to ../results/rec_compartments/.",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#the-genomic-regions-in-question",
    "href": "notebooks/06_rec_genomicintervals.html#the-genomic-regions-in-question",
    "title": "E1 vs. ECH (recommended params)",
    "section": "",
    "text": "Cell type: fibroblast, spermatocyte, pachytene spermatocyte, round spermatid, sperm\nChromosome: X\nE1 restriction: full-chromosome, chromosome arms, 10Mb windows\nResolution: 100 kb, 500 kb, ps500kb (smoothed 100kb)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#setup-inline-backend",
    "href": "notebooks/06_rec_genomicintervals.html#setup-inline-backend",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Setup inline backend",
    "text": "Setup inline backend\n\nInlineBackend.rc\nFor consistent plots that fit with pdf manus.\n\nimport matplotlib.pyplot as plt\n\n# Define my params:\n## Params will comply with my desired layout for the Manuscript (PDF)\n\nnotebook_rcparams = {\n    'font.size': 7,\n    'axes.titlesize': 8,\n    'axes.labelsize': 7,\n    'xtick.labelsize': 6,\n    'ytick.labelsize': 6,\n    'figure.titlesize': 9,\n    'figure.figsize': [6.0, 2.0],\n    'figure.labelsize': 7,\n    'legend.fontsize': 6,\n    \n}\n\n# Apply config\n%matplotlib inline\n%config InlineBackend.figure_formats = ['retina']\n%config InlineBackend.rc = notebook_rcparams\n\n\nprint({key:plt.rcParams[key] for key in notebook_rcparams.keys()})\n\n{'font.size': 10.0, 'axes.titlesize': 'large', 'axes.labelsize': 'medium', 'xtick.labelsize': 'medium', 'ytick.labelsize': 'medium', 'figure.titlesize': 'large', 'figure.figsize': [6.4, 4.8], 'figure.labelsize': 'large', 'legend.fontsize': 'medium'}\n\n\n\n## Apparently IPython needs this twice to understand?? \nimport matplotlib.pyplot as plt\n\n# Define my params:\n## Params will comply with my desired layout for the Manuscript (PDF)\n\nnotebook_rcparams = {\n    'font.size': 7,\n    'axes.titlesize': 8,\n    'axes.labelsize': 7,\n    'xtick.labelsize': 6,\n    'ytick.labelsize': 6,\n    'figure.titlesize': 9,\n    'figure.figsize': [6.0, 2.0],\n    'figure.labelsize': 7,\n    'legend.fontsize': 6,\n    \n}\n\n# Apply config\n%matplotlib inline\n%config InlineBackend.figure_formats = ['retina']\n%config InlineBackend.rc = notebook_rcparams\n\n\nprint({key:plt.rcParams[key] for key in notebook_rcparams.keys()})\n\n{'font.size': 7.0, 'axes.titlesize': 8.0, 'axes.labelsize': 7.0, 'xtick.labelsize': 6.0, 'ytick.labelsize': 6.0, 'figure.titlesize': 9.0, 'figure.figsize': [6.0, 2.0], 'figure.labelsize': 7.0, 'legend.fontsize': 6.0}",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#import-compartments",
    "href": "notebooks/06_rec_genomicintervals.html#import-compartments",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Import compartments",
    "text": "Import compartments\n\nimport pandas as pd\nimport os\n\n# Directory containing your .csv files\ncsv_dir = '../results/rec_compartments/'\n\n# Create a dictionary to store the DataFrames\ndataframes = {}\n\n# Iterate over all .csv files in the directory\nfor filename in os.listdir(csv_dir):\n    if filename.endswith('.csv') and 'e1' not in filename:  # Check for .csv files\n        # Construct the full file path\n        filepath = os.path.join(csv_dir, filename)\n        \n        # Load the CSV into a DataFrame\n        # Use the filename (without extension) as the dictionary key\n        key = filename.replace('_a_comp_coords_', '_')\n        key = os.path.splitext(key)[0]\n        dataframes[key] = pd.read_csv(filepath)\n        dataframes[key]['length'] = dataframes[key]['end'] - dataframes[key]['start']\n\n# The `dataframes` dictionary now contains the DataFrames\ndataframes.keys()\n\nech90 = pd.read_csv('../data/ech90_human_Mmul_10.csv')\nech90['length'] = ech90['end'] - ech90['start']\n\n# Load the chromosome sizes\nchromsizes = (pd.read_csv(\n    '../data/rheMac10.filtered.chrom.sizes', \n    sep='\\t', \n    index_col='chrom', \n    header=None, \n    names=['chrom','size'])\n.to_dict()['size']\n)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#define-a-plotting-function",
    "href": "notebooks/06_rec_genomicintervals.html#define-a-plotting-function",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Define a plotting function",
    "text": "Define a plotting function\n\n# Kaspers plotting function\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%config InlineBackend.figure_format = 'svg'\n\ndef plot_intervals(query=None, annot=None, **kwargs):\n\n    tups = []\n    if query is not None:\n        tups.append(('query', query))\n    if annot is not None:\n        tups.append(('annot', annot))\n    tups.extend(kwargs.items())\n    tups = reversed(tups)\n\n    df_list = []\n    labels = []\n    for label, df in tups:\n        labels.append(label)\n        df['label'] = label\n        df_list.append(df)\n    bigdf = pd.concat(df_list)\n\n    bigdf['chrom'] = pd.Categorical(bigdf['chrom'], bigdf['chrom'].unique())\n    bigdf['label'] = pd.Categorical(bigdf['label'], bigdf['label'].unique())\n\n    gr = bigdf.groupby('chrom', observed=False)\n    fig, axes = plt.subplots(gr.ngroups, 1, figsize=(10, 1.5*gr.ngroups), \n                            sharey=True\n                            #  sharex=True\n                             )\n    if type(axes) is not np.ndarray:\n        # in case there is only one axis so it not returned as a list\n        axes = np.array([axes])\n    \n    # with plt.style.context(('default')):\n\n    for i, chrom in enumerate(gr.groups):\n        _df = gr.get_group(chrom)\n        _gr = _df.groupby('label', observed=False)\n        for y, label in enumerate(_gr.groups):\n            try:\n                df = _gr.get_group(label)\n            except KeyError:\n                continue\n            y = np.repeat(y, df.index.size)\n            axes[i].hlines(y, df.start.tolist(), df.end.tolist(), alpha=0.5, lw=5, colors=f'C{y[0]}')\n            delta = len(labels)/10\n            axes[i].vlines(df.start.tolist(), y-delta, y+delta, alpha=0.5, lw=2, colors=f'C{y[0]}')\n            axes[i].vlines(df.end.tolist(), y-delta, y+delta, alpha=0.5, lw=2, colors=f'C{y[0]}')\n\n        axes[i].spines['top'].set_visible(False)\n        axes[i].spines['left'].set_visible(False)\n        axes[i].spines['right'].set_visible(False)\n\n        axes[i].set_yticks(list(range(len(labels))), labels)\n        axes[i].tick_params(axis='y', which='both', left=False)\n        axes[i].set_ylim(-1, len(labels)-0.7)\n        # axes[i].set_xlim(df.start.min()-delta, df.end.max()+delta)\n        if i != gr.ngroups-1:\n            axes[i].tick_params(axis='x', which='both', bottom=False)\n\n        axes[i].set_title(chrom, loc='left', fontsize=10)\n    plt.tight_layout()\n\n\n# My plotting function\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Rectangle\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom genominterv import interval_intersect\n\n\ndef plot_regions(query=None, annot=None, intersect=None, \n                 track_titles=['query', 'annot', 'intersect'], \n                 figsize=(10, 1)):\n    chrom = annot['chrom'].unique()[0]\n    rhemac_chromsizes = pd.read_csv('../data/rheMac10.filtered.chrom.sizes', sep='\\t', header=None, names=['chrom', 'size'])\n    annot_max = annot['end'].max()\n    query_max = query['end'].max() if query is not None else 0\n    rhemac_chromsize = rhemac_chromsizes.query(f'chrom == \"{chrom}\"').loc[:, 'size'].values[0]\n    chromsize = max([rhemac_chromsize, annot_max, query_max])\n    # Define the plot size\n\n    f, ax = plt.subplots(figsize=figsize, sharex=True)\n    ax.spines[:].set_visible(False)\n\n    # Plot the annot\n    # Iterate over each interval in the DataFrame\n    for start, end in zip(annot['start'], annot['end']):\n        rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:red', linewidth=0, alpha=0.8)\n        ax.add_patch(rect)\n        ax.spines['bottom'].set_visible(True)\n        ax.set_ylabel(track_titles[1], rotation=0, labelpad=10, ha='right')\n\n    \n    divider = make_axes_locatable(ax)\n\n    if query is not None:\n        qax = divider.append_axes(\"top\", size=\"100%\", pad=0.05, sharex=ax)\n        qax.xaxis.set_visible(False)\n        # Plot the query\n        for start, end in zip(query['start'], query['end']):\n            rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:blue', linewidth=0, alpha=0.8)\n            qax.add_patch(rect)\n            qax.spines[:].set_visible(False)\n            qax.set_yticks([]) \n            qax.set_title(chrom, loc='left')\n            qax.set_ylabel(track_titles[0], rotation=0, labelpad=10, ha='right')\n    \n    if intersect is not None:\n        iax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.05, sharex=ax)\n        # Invisible x-axis for 'annot' (intersect ie below) \n        ax.xaxis.set_visible(False)\n        # Plot the intersect\n        for start, end in zip(intersect['start'], intersect['end']):\n            rect = Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.8)\n            iax.add_patch(rect)\n            iax.spines[:].set_visible(False)\n            iax.set_yticks([]) \n            ax.spines['bottom'].set_visible(False)\n            iax.spines['bottom'].set_visible(True)\n            iax.set_ylabel(track_titles[2], rotation=0, labelpad=10, ha='right')\n\n\n\n    ax.set_yticks([])\n    ax.set_xlim(0, chromsize)\n    ticks = np.linspace(0, chromsize, num=5)\n    ax.set_xticks(ticks) \n    ax.set_xticklabels([f'{int(t/1e6)} Mbp' for t in ticks])\n    plt.tight_layout()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#time-to-unleash-genominterv-on-the-.csv-files",
    "href": "notebooks/06_rec_genomicintervals.html#time-to-unleash-genominterv-on-the-.csv-files",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Time to unleash genominterv on the .csv files",
    "text": "Time to unleash genominterv on the .csv files\n\nTest with a subsample of the data\n\n\nannot = dataframes['round_spermatid_100kb_arms']\nquery = ech90\nintersect = interval_intersect(annot, query)\n\nplot_intervals(query, annot, intersection=intersect)\nplot_regions(query, annot, intersect)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom genominterv import proximity_test, interval_collapse, interval_diff, interval_intersect, jaccard_stat\n\nannot = dataframes['round_spermatid_100kb_arms']\nquery = ech90\n\n#plot_intervals(query=query, annot=annot)\n\nfor key,annot in dataframes.items():\n    # Filter out subset\n    if ('round_spermatid_100') in key and not 'full' in key:\n        # Plot the intervals\n        intersection = interval_intersect(query, annot)\n        plot_intervals(query=query, annot=annot, intersection=intersection)\n        plt.title(key)\n\n        # Do a proximity test\n        print(f\"Tests for {key}\")\n        annot_collapsed = interval_collapse(annot)\n        non_ovl_query = interval_diff(query, annot_collapsed)\n        print(\"Proximity:\", proximity_test(non_ovl_query, annot_collapsed))\n        print(\"Jaccard:\", jaccard_stat(query, annot))\n        print()\n\n\nTests for round_spermatid_100kb_arms_smoothed\nProximity: TestResult(statistic=0.3711999999999999, pvalue=0.0204)\nJaccard: 0.03771152626674943\n\nTests for round_spermatid_100kb_10Mb\nProximity: TestResult(statistic=0.51525, pvalue=0.0)\nJaccard: 0.046023479610810235\n\nTests for round_spermatid_100kb_10Mb_smoothed\nProximity: TestResult(statistic=0.46520000000000006, pvalue=0.0049)\nJaccard: 0.042623832902054265\n\nTests for round_spermatid_100kb_arms\nProximity: TestResult(statistic=0.37199999999999966, pvalue=0.0121)\nJaccard: 0.046543092859550536\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap to get a p-value\n\nfrom genominterv import bootstrap\n\nannot = dataframes['round_spermatid_100kb_arms']\nchromsizes = pd.read_csv('../data/rheMac10.filtered.chrom.sizes', sep='\\t', index_col='chrom', header=None, names=['chrom','size']).to_dict()['size']\n#display(chromsizes)\n\n@bootstrap(chromsizes, samples=1000)\ndef jaccard_bootstrap(query, annot):\n    return jaccard_stat(query, annot)\n\njacccard_stat, p_value = jaccard_bootstrap(query, annot)\n\n\njacccard_stat, p_value\n\n(0.046543092859550536, 0.112)\n\n\n\n\nPartition the A-compartments into regions around the edges\n\nfrom genominterv import interval_collapse, interval_union\n\ndf = dataframes['round_spermatid_100kb_arms']\n\nstart_edge = pd.DataFrame({\n    'chrom': df['chrom'],\n    'start': df.apply(lambda x: max(x['start'] - x['resolution'], 0), axis=1),\n    'end': df['start']+1*df['resolution'],\n    'resolution': df['resolution'],\n    'label': 'start_edge'\n})\nend_edge = pd.DataFrame({\n    'chrom': df['chrom'],\n    'start': df['end']-1*df['resolution'],\n    'end': df.apply(lambda x: min(x['end'] + x['resolution'], chromsizes['chrX']), axis=1),\n    'resolution': df['resolution'],\n    'label': 'end_edge'\n})\n\n# The end cannot exceed the chromosome size\ntest_df = pd.concat([start_edge, end_edge]).sort_values(['chrom', 'start', 'end'])\ninterval_collapse(test_df)\n\n\n\n\n\n\n\n\nstart\nend\nchrom\n\n\n\n\n0\n800000\n1000000\nchrX\n\n\n1\n1500000\n1800000\nchrX\n\n\n2\n2500000\n2700000\nchrX\n\n\n3\n2800000\n3300000\nchrX\n\n\n4\n3400000\n3600000\nchrX\n\n\n...\n...\n...\n...\n\n\n91\n148700000\n148900000\nchrX\n\n\n92\n149000000\n149400000\nchrX\n\n\n93\n151100000\n151300000\nchrX\n\n\n94\n152400000\n152600000\nchrX\n\n\n95\n153200000\n153388924\nchrX\n\n\n\n\n96 rows × 3 columns\n\n\n\n\nimport os\nfrom genominterv import interval_collapse\n\nfor key, df in dataframes.items():\n    outdir = '../results/rec_edges'\n    edge_csv_name = os.path.join(outdir,f'{key+'_edges.csv'}')\n    if not os.path.exists(edge_csv_name):\n        res = df['resolution'].unique()[0]\n\n        start_edge = pd.DataFrame({\n            'chrom': df['chrom'],\n            'start': df.apply(lambda x: max(x['start'] - x['resolution'], 0), axis=1),\n            'end': df['start']+1*df['resolution'],\n            'resolution': df['resolution'],\n            'label': 'start_edge'\n        })\n        end_edge = pd.DataFrame({\n            'chrom': df['chrom'],\n            'start': df['end']-1*df['resolution'],\n            'end': df.apply(lambda x: min(x['end'] + x['resolution'], chromsizes['chrX']), axis=1),\n            'resolution': df['resolution'],\n            'label': 'end_edge'\n        })\n\n        if not os.path.exists(outdir):\n            os.makedirs(outdir)\n\n        tmp = pd.concat([start_edge, end_edge]).sort_values(['chrom', 'start', 'end'])\n        interval_collapse(tmp).assign(resolution=res).to_csv(edge_csv_name, index=False)",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#import-edges",
    "href": "notebooks/06_rec_genomicintervals.html#import-edges",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Import edges",
    "text": "Import edges\n\nimport pandas as pd\nimport os\n\n# Directory containing your .csv files\ncsv_dir = '../results/rec_edges/'\n\n# Create a dictionary to store the DataFrames\nedge_df = {}\n\n# Iterate over all .csv files in the directory\nfor filename in os.listdir(csv_dir):\n    if filename.endswith('.csv'):  # Check for .csv files\n        # Construct the full file path\n        filepath = os.path.join(csv_dir, filename)\n        \n        # Load the CSV into a DataFrame\n        # Use the filename (without extension) as the dictionary key\n        key = filename.replace('_edges_', '')\n        key = os.path.splitext(key)[0]\n        edge_df[key] = pd.read_csv(filepath)\n        edge_df[key]['length'] = edge_df[key]['end'] - edge_df[key]['start']\n\n# The `edges` dictionary now contains the DataFrames\nprint(edge_df.keys())\nprint(edge_df['fibroblast_100kb_10Mb_edges'].columns)\n\n#ech90 = pd.read_csv('../data/ech90_human_Mmul_10.csv')\n\ndict_keys(['pachytene_spermatocyte_100kb_arms_smoothed_edges', 'round_spermatid_100kb_arms_smoothed_edges', 'fibroblast_500kb_arms_edges', 'round_spermatid_500kb_10Mb_edges', 'fibroblast_100kb_full_edges', 'round_spermatid_500kb_arms_edges', 'spermatogonia_100kb_arms_smoothed_edges', 'fibroblast_500kb_10Mb_edges', 'round_spermatid_100kb_full_edges', 'spermatogonia_500kb_arms_edges', 'spermatogonia_100kb_full_edges', 'pachytene_spermatocyte_100kb_arms_edges', 'sperm_500kb_full_edges', 'pachytene_spermatocyte_500kb_full_edges', 'sperm_100kb_arms_edges', 'sperm_100kb_arms_smoothed_edges', 'sperm_100kb_10Mb_edges', 'pachytene_spermatocyte_100kb_10Mb_edges', 'fibroblast_100kb_arms_smoothed_edges', 'spermatogonia_500kb_10Mb_edges', 'round_spermatid_100kb_full_smoothed_edges', 'fibroblast_500kb_full_edges', 'round_spermatid_100kb_10Mb_edges', 'pachytene_spermatocyte_100kb_full_smoothed_edges', 'fibroblast_100kb_arms_edges', 'sperm_100kb_10Mb_smoothed_edges', 'round_spermatid_500kb_full_edges', 'fibroblast_100kb_10Mb_edges', 'round_spermatid_100kb_arms_edges', 'fibroblast_100kb_10Mb_smoothed_edges', 'spermatogonia_100kb_full_smoothed_edges', 'spermatogonia_500kb_full_edges', 'spermatogonia_100kb_arms_edges', 'pachytene_spermatocyte_100kb_full_edges', 'sperm_500kb_arms_edges', 'sperm_100kb_full_smoothed_edges', 'pachytene_spermatocyte_100kb_10Mb_smoothed_edges', 'pachytene_spermatocyte_500kb_arms_edges', 'sperm_100kb_full_edges', 'round_spermatid_100kb_10Mb_smoothed_edges', 'spermatogonia_100kb_10Mb_smoothed_edges', 'fibroblast_100kb_full_smoothed_edges', 'pachytene_spermatocyte_500kb_10Mb_edges', 'sperm_500kb_10Mb_edges', 'spermatogonia_100kb_10Mb_edges'])\nIndex(['start', 'end', 'chrom', 'resolution', 'length'], dtype='object')\n\n\n\nfrom genominterv import interval_intersect\n\nsamples = dataframes.keys()\n#samples = ['round_spermatid_100kb_arms', 'round_spermatid_100kb_10Mb', 'sperm_100kb_arms', 'sperm_100kb_10Mb']\n\ncomps = {key:dataframes[key] for key in samples}\nedges = {key:edge_df[f'{key}_edges'] for key in samples}\n\ncomp_intersects = {key:interval_intersect(comp, ech90).assign(length = lambda x: x['end'] - x['start']) for key, comp in comps.items()}\nedge_intersects = {key:interval_intersect(edge, ech90).assign(length = lambda x: x['end'] - x['start']) for key, edge in edges.items()}\n\n\n\n\n## For a single sample only ##\n# sample = 'round_spermatid_100kb_arms'\n\n# full_df = dataframes[sample]\n# full_intersect = interval_intersect(full_df, ech90).assign(length=lambda x: x['end'] - x['start'])\n# edge_intersect = interval_intersect(edge_df[f'{sample}_edges'], ech90).assign(length=lambda x: x['end'] - x['start'])\n\n# edge_df = edge_df[f'{sample}_edges']\n\n# # Plot full\n# plot_regions(ech90, full_df, full_intersect)\n# plt.suptitle('All edges')\n\n# # Plot edge\n# plot_regions(ech90, edge_df, edge_intersect)\n# plt.suptitle('Edges only')\n\n\n### Some stats about the data and intersections ###\n\nstats = pd.DataFrame({\n    'Sample': samples,\n    'Total regions': [comp.shape[0] for comp in comps.values()],\n    'Total regions on ECH90': [comp_intersect.shape[0] for comp_intersect in comp_intersects.values()],\n    'Total regions on edges': [edge_intersect.shape[0] for edge_intersect in edge_intersects.values()],\n    'Prop regions on ECH90': [comp_intersect.shape[0] / ech90.shape[0] for comp, comp_intersect in zip(comps.values(), comp_intersects.values())],\n    'Total bp': [comp['length'].sum() for comp in comps.values()],\n    'Total bp on ECH90': [comp_intersect['length'].sum() for comp_intersect in comp_intersects.values()],\n    'Total bp on edges': [edge_intersect['length'].sum() for edge_intersect in edge_intersects.values()],\n    'Prop bp on ECH90': [comp_intersect['length'].sum() / ech90['length'].sum() for comp, comp_intersect in zip(comps.values(), comp_intersects.values())],\n})\n\n\n#df[['Source', 'Rest']] = df['Sample'].str.extract(r'^(.*?)(_\\d+\\w+.*)')\nstats[['source', 'res', 'view', 'smoothed']] = stats['Sample'].str.extract(r'^(.*?)_(100kb|500kb)_(full|arms|10Mb)(?:_(smoothed))?$')\nstats['smoothed'] = stats['smoothed'].notna() # Convert to boolean\nstats[['source', 'res', 'view', 'smoothed','Prop regions on ECH90', 'Prop bp on ECH90']]\n\n\n\n\n\n\n\n\n\nsource\nres\nview\nsmoothed\nProp regions on ECH90\nProp bp on ECH90\n\n\n\n\n0\nspermatogonia\n500kb\narms\nFalse\n0.421053\n0.489351\n\n\n1\nround_spermatid\n500kb\nfull\nFalse\n0.368421\n0.418981\n\n\n2\nfibroblast\n500kb\nfull\nFalse\n0.684211\n0.529916\n\n\n3\npachytene_spermatocyte\n100kb\narms\nTrue\n0.684211\n0.632145\n\n\n4\npachytene_spermatocyte\n500kb\nfull\nFalse\n0.368421\n0.362651\n\n\n5\npachytene_spermatocyte\n100kb\nfull\nFalse\n0.473684\n0.365265\n\n\n6\nround_spermatid\n100kb\narms\nTrue\n0.631579\n0.412828\n\n\n7\nfibroblast\n100kb\narms\nTrue\n0.684211\n0.499297\n\n\n8\nfibroblast\n100kb\nfull\nFalse\n0.842105\n0.550167\n\n\n9\nround_spermatid\n100kb\nfull\nFalse\n0.421053\n0.472204\n\n\n10\nspermatogonia\n100kb\narms\nFalse\n0.526316\n0.550008\n\n\n11\nspermatogonia\n100kb\n10Mb\nFalse\n0.631579\n0.567910\n\n\n12\nsperm\n100kb\nfull\nFalse\n0.631579\n0.674746\n\n\n13\nsperm\n100kb\narms\nTrue\n0.578947\n0.572887\n\n\n14\nspermatogonia\n500kb\n10Mb\nFalse\n0.684211\n0.689415\n\n\n15\nsperm\n500kb\nfull\nFalse\n0.631579\n0.559567\n\n\n16\nspermatogonia\n100kb\narms\nTrue\n0.526316\n0.549381\n\n\n17\npachytene_spermatocyte\n100kb\n10Mb\nFalse\n0.789474\n0.630109\n\n\n18\nround_spermatid\n100kb\n10Mb\nFalse\n0.684211\n0.519772\n\n\n19\nround_spermatid\n100kb\n10Mb\nTrue\n0.578947\n0.483689\n\n\n20\nfibroblast\n100kb\n10Mb\nFalse\n0.684211\n0.494509\n\n\n21\nfibroblast\n100kb\n10Mb\nTrue\n0.526316\n0.414530\n\n\n22\nfibroblast\n100kb\nfull\nTrue\n0.736842\n0.591105\n\n\n23\nsperm\n100kb\narms\nFalse\n0.736842\n0.578219\n\n\n24\nround_spermatid\n100kb\nfull\nTrue\n0.368421\n0.418981\n\n\n25\nfibroblast\n500kb\n10Mb\nFalse\n0.473684\n0.359088\n\n\n26\nround_spermatid\n500kb\n10Mb\nFalse\n0.578947\n0.496303\n\n\n27\nsperm\n500kb\narms\nFalse\n0.421053\n0.395138\n\n\n28\npachytene_spermatocyte\n100kb\n10Mb\nTrue\n0.631579\n0.665339\n\n\n29\npachytene_spermatocyte\n500kb\n10Mb\nFalse\n0.631579\n0.538153\n\n\n30\npachytene_spermatocyte\n100kb\nfull\nTrue\n0.368421\n0.401552\n\n\n31\nround_spermatid\n500kb\narms\nFalse\n0.684211\n0.655953\n\n\n32\nspermatogonia\n500kb\nfull\nFalse\n0.421053\n0.392944\n\n\n33\nfibroblast\n500kb\narms\nFalse\n0.684211\n0.550729\n\n\n34\nspermatogonia\n100kb\n10Mb\nTrue\n0.631579\n0.580640\n\n\n35\nspermatogonia\n100kb\nfull\nTrue\n0.368421\n0.386720\n\n\n36\nsperm\n500kb\n10Mb\nFalse\n0.526316\n0.438818\n\n\n37\npachytene_spermatocyte\n500kb\narms\nFalse\n0.631579\n0.650289\n\n\n38\npachytene_spermatocyte\n100kb\narms\nFalse\n0.789474\n0.584619\n\n\n39\nsperm\n100kb\n10Mb\nTrue\n0.578947\n0.549366\n\n\n40\nsperm\n100kb\nfull\nTrue\n0.578947\n0.677841\n\n\n41\nfibroblast\n100kb\narms\nFalse\n0.736842\n0.510641\n\n\n42\nspermatogonia\n100kb\nfull\nFalse\n0.473684\n0.374801\n\n\n43\nround_spermatid\n100kb\narms\nFalse\n0.789474\n0.500366\n\n\n44\nsperm\n100kb\n10Mb\nFalse\n0.684211\n0.545798",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#do-testing-of-the-edges",
    "href": "notebooks/06_rec_genomicintervals.html#do-testing-of-the-edges",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Do testing of the edges",
    "text": "Do testing of the edges\n\n%%capture\n# Define what we are testing\n\nprint(\"\"\"\nGoal: To test whether ECH90 regions are enriched in compartment edges\nQuery: ECH90\nAnnotation: Start and end edges of compartments\n\nHypothesis: \n      ECH90 regions are enriched in compartment edges\nNull hypothesis: \n      ECH90 regions are not enriched in compartment edges\n\nTests: \n* Proximity test: \n      tests whether the query regions are closer to \n      the annotation regions than expected by chance. \n      NB regions can not overlap, so we need to collapse the annotation regions\n\n* Jaccard index: \n      tests the similarity between the query and annotation regions, \n      where a value of 1 indicates perfect overlap\n\"\"\")\n\n\nBig test don’t run\n\nParallelized proximity test\nset samples = 100_000\n\nimport os.path as op\nimport pandas as pd\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nfrom genominterv.stats import proximity_test\nfrom genominterv import interval_diff\n\n\ndef process_proximity(sample, nsamples = 100000):\n    query_comp = ech90\n    query_edge = ech90\n    annot_comp = comps[sample]\n    annot_edge = edges[sample]\n\n    # Get non-overlapping query regions\n    non_ovl_query_comp = interval_diff(query_comp, annot_comp)\n    non_ovl_query_edge = interval_diff(query_edge, annot_edge)\n\n    proximity_comp = proximity_test(non_ovl_query_comp, annot_comp, \n                                    nsamples, two_sided=False,\n                                    overlap_as_zero=True)\n    proximity_edge = proximity_test(non_ovl_query_edge, annot_edge, \n                                    nsamples, two_sided=False,\n                                    overlap_as_zero=True,span_as_zero=True)\n\n    results = [\n        {'Sample': sample, 'Query': 'ECH90', 'Comp Statistic': proximity_comp.statistic, \n         'Edge Statistic': proximity_edge.statistic, 'Comp P-value': proximity_comp.pvalue, \n         'Edge P-value': proximity_edge.pvalue}\n    ]\n\n    # Swap query and annotation\n    query_comp, annot_comp = annot_comp, query_comp\n    query_edge, annot_edge = annot_edge, query_edge\n\n    non_ovl_query_comp = interval_diff(query_comp, annot_comp)\n    non_ovl_query_edge = interval_diff(query_edge, annot_edge)\n\n    proximity_comp = proximity_test(non_ovl_query_comp, annot_comp, \n                                    nsamples, two_sided=False,\n                                    overlap_as_zero=True)\n    proximity_edge = proximity_test(non_ovl_query_edge, annot_edge, \n                                    nsamples, two_sided=False,\n                                    overlap_as_zero=True)\n\n    results.append(\n        {'Sample': sample, 'Query': 'Edge', 'Comp Statistic': proximity_comp.statistic, \n         'Edge Statistic': proximity_edge.statistic, 'Comp P-value': proximity_comp.pvalue, \n         'Edge P-value': proximity_edge.pvalue}\n    )\n\n    return results\n\n### End of function definition ###\n\n\nnsamples = 100_000\nproximity_file = f'../results/proximity_test_{nsamples}.csv'\nif op.exists(proximity_file):\n    proximity_res = Parallel(n_jobs=-1)(\n        delayed(process_proximity)(sample, nsamples) for sample in tqdm(samples)\n    )\n\n    # Flatten the results\n    proximity_res = pd.DataFrame([item for sublist in proximity_res for item in sublist])\n    proximity_res.to_csv(proximity_file, index=False)\n\n100%|██████████| 2/2 [00:00&lt;00:00, 120.90it/s]\n\n\n\n---------------------------------------------------------------------------\n_RemoteTraceback                          Traceback (most recent call last)\n_RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sojern/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_2160200/2582913803.py\", line 22, in process_proximity\nTypeError: proximity_test() got an unexpected keyword argument 'span_as_zero'\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\nCell In[15], line 60\n     58 proximity_file = f'../results/proximity_test_{nsamples}.csv'\n     59 if op.exists(proximity_file):\n---&gt; 60     proximity_res = Parallel(n_jobs=-1)(\n     61         delayed(process_proximity)(sample, nsamples) for sample in tqdm(samples)\n     62     )\n     64     # Flatten the results\n     65     proximity_res = pd.DataFrame([item for sublist in proximity_res for item in sublist])\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:2007, in Parallel.__call__(self, iterable)\n   2001 # The first item from the output is blank, but it makes the interpreter\n   2002 # progress until it enters the Try/Except block of the generator and\n   2003 # reaches the first `yield` statement. This starts the asynchronous\n   2004 # dispatch of the tasks to the workers.\n   2005 next(output)\n-&gt; 2007 return output if self.return_generator else list(output)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:1650, in Parallel._get_outputs(self, iterator, pre_dispatch)\n   1647     yield\n   1649     with self._backend.retrieval_context():\n-&gt; 1650         yield from self._retrieve()\n   1652 except GeneratorExit:\n   1653     # The generator has been garbage collected before being fully\n   1654     # consumed. This aborts the remaining tasks if possible and warn\n   1655     # the user if necessary.\n   1656     self._exception = True\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:1754, in Parallel._retrieve(self)\n   1747 while self._wait_retrieval():\n   1748 \n   1749     # If the callback thread of a worker has signaled that its task\n   1750     # triggered an exception, or if the retrieval loop has raised an\n   1751     # exception (e.g. `GeneratorExit`), exit the loop and surface the\n   1752     # worker traceback.\n   1753     if self._aborting:\n-&gt; 1754         self._raise_error_fast()\n   1755         break\n   1757     # If the next job is not ready for retrieval yet, we just wait for\n   1758     # async callbacks to progress.\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:1789, in Parallel._raise_error_fast(self)\n   1785 # If this error job exists, immediately raise the error by\n   1786 # calling get_result. This job might not exists if abort has been\n   1787 # called directly or if the generator is gc'ed.\n   1788 if error_job is not None:\n-&gt; 1789     error_job.get_result(self.timeout)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:745, in BatchCompletionCallBack.get_result(self, timeout)\n    739 backend = self.parallel._backend\n    741 if backend.supports_retrieve_callback:\n    742     # We assume that the result has already been retrieved by the\n    743     # callback thread, and is stored internally. It's just waiting to\n    744     # be returned.\n--&gt; 745     return self._return_or_raise()\n    747 # For other backends, the main thread needs to run the retrieval step.\n    748 try:\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:763, in BatchCompletionCallBack._return_or_raise(self)\n    761 try:\n    762     if self.status == TASK_ERROR:\n--&gt; 763         raise self._result\n    764     return self._result\n    765 finally:\n\nTypeError: proximity_test() got an unexpected keyword argument 'span_as_zero'\n\n\n\n\n\nParallelized Jaccard test\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nimport os.path as op\nfrom genominterv.stat import jaccard_stat\nfrom genominterv.decorators import bootstrap\nfrom datetime import datetime\nimport pandas as pd\n\nb = 100_000\n@bootstrap(chromsizes, samples=b)\ndef jaccard_bootstrap(query, annot):\n    return jaccard_stat(query, annot)\n\ndef process_sample(sample):\n    \"\"\"Function to process a single sample.\"\"\"\n    query_comp = ech90\n    query_edge = ech90\n    annot_comp = comps[sample]\n    annot_edge = edges[sample]\n\n    jaccard_comp = jaccard_bootstrap(query_comp, annot_comp)\n    jaccard_edge = jaccard_bootstrap(query_edge, annot_edge)\n\n    result = [{\n        'Sample': sample, \n        'Query': 'ECH90', \n        'Comp Index': jaccard_comp[0], \n        'Edge Index': jaccard_edge[0], \n        'Comp P-value': jaccard_comp[1], \n        'Edge P-value': jaccard_edge[1]\n        }\n    ]\n\n    # Swap query and annotation for the Edge test\n    query_comp, annot_comp = annot_comp, query_comp\n    query_edge, annot_edge = annot_edge, query_edge\n\n    jaccard_comp = jaccard_bootstrap(query_comp, annot_comp)\n    jaccard_edge = jaccard_bootstrap(query_edge, annot_edge)\n\n    result.append({\n        'Sample': sample, \n        'Query': 'Edge', \n        'Comp Index': jaccard_comp[0], \n        'Edge Index': jaccard_edge[0], \n        'Comp P-value': jaccard_comp[1], \n        'Edge P-value': jaccard_edge[1]\n        }\n    )\n    return result\n\njaccard_file = f'../results/jaccard_test_{b}.csv'\n\nif not op.exists(jaccard_file):\n\n    # Run parallel computation\n    print(f\"Running bootstrap ({b}) for all samples in parallel\")\n    results = Parallel(n_jobs=-1)(\n        delayed(process_sample)(sample) for sample in tqdm(samples)\n    )\n\n    # Flatten and create DataFrame\n    jaccard_res = pd.DataFrame([item for sublist in results for item in sublist])\n\n    # Write to CSV\n    jaccard_res.to_csv(jaccard_file, index=False)\n\nelse:\n    # Read\n    jaccard_res = pd.read_csv(jaccard_file)\n\n\n\nPlot some summary statistics\n\n# Split sample column:\nproximity_res = pd.read_csv(proximity_file)\n\nproximity_res[['source', 'resolution', 'view', 'smoothed']] = proximity_res['Sample'].str.extract(r'^(.*?)_(100kb|500kb)_(full|arms|10Mb)(?:_(smoothed))?$')\nproximity_res['source'] = proximity_res['source'].map({'fibroblast':'Fib', 'spermatogonia': 'SP', 'pachytene_spermatocyte': 'PAC', 'round_spermatid': 'RS', 'sperm': 'Sperm'})\nproximity_res['smoothed'] = proximity_res['smoothed'].notna()\nproximity_res['resolution'] = proximity_res.apply(lambda x: 'ps500kb' if x['smoothed'] else x['resolution'], axis=1)\nproximity_res = proximity_res.melt(\n    id_vars=['Sample', 'source', 'resolution', 'view', 'Query'],\n    value_vars=['Comp P-value', 'Edge P-value'], \n     var_name='type', value_name='p-value',).query('Query == \"ECH90\"')\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nsource_order = ['Fib', 'SP', 'PAC', 'RS', 'Sperm']\n# Choose the combination og parameters to plot\nsource = ['fibroblast','round_spermatid']\nres = ['100kb']\nview = ['arms']\nannot = ['Edge P-value']\n\n# Plot the results from @group\nplot_group_prox = proximity_res.query('resolution in @res and view in @view and type in @annot')\n\nplot_group_prox = plot_group_prox.assign(\n    minuslog10p = lambda x: -np.log10(x['p-value']),\n    type = 'Proximity')\n\n# Plot the results\n\nsns.set_theme(style=\"whitegrid\", rc=notebook_rcparams)\n\ng = sns.catplot(\n    plot_group_prox, kind='bar',\n    x='source', y='minuslog10p', hue='type', \n    order=source_order,\n    errorbar=None, margin_titles=True, sharex=False,\n    )\n\ng.despine(left=True)\ng.set_axis_labels(\"\", \"-log10(p)\")\ng.legend.set_title('')\n\n\nfor axis in g.axes.flat:\n    axis.tick_params(labelbottom=True)\n    # rotate said labels\n    for item in axis.get_xticklabels():\n        item.set_rotation(45)\n\ng.tight_layout()\n\n\n\n\n\n\n\n\n\n\n# Now do the same for the Jaccard index\n\njaccard_res = pd.read_csv(jaccard_file)\n\njaccard_res[['source', 'resolution', 'view', 'smoothed']] = jaccard_res['Sample'].str.extract(r'^(.*?)_(100kb|500kb)_(full|arms|10Mb)(?:_(smoothed))?$')\njaccard_res['source'] = jaccard_res['source'].map({'fibroblast':'Fib', 'spermatogonia': 'SP', 'pachytene_spermatocyte': 'PAC', 'round_spermatid': 'RS', 'sperm': 'Sperm'})\njaccard_res['smoothed'] = jaccard_res['smoothed'].notna()\njaccard_res['resolution'] = jaccard_res.apply(lambda x: 'ps500kb' if x['smoothed'] else x['resolution'], axis=1)\njaccard_res = jaccard_res.melt(\n    id_vars=['Sample', 'source', 'resolution', 'view', 'Query'],\n    value_vars=['Comp P-value', 'Edge P-value'], \n    var_name='type', value_name='p-value',).query('Query == \"ECH90\"')\n\n\n\nimport numpy as np\n\nsource_order = ['Fib', 'SP', 'PAC', 'RS', 'Sperm']\n# Choose the combination og parameters to plot\nsource = ['fibroblast','round_spermatid']\nres = ['100kb']\nview = ['arms']\nannot = ['Edge P-value']\n\n# Plot the results from @group\nplot_group_jacc = jaccard_res.query('resolution in @res and view in @view and type in @annot')\nplot_group_jacc = plot_group_jacc.assign(\n    minuslog10p = lambda x: -np.log10(x['p-value']),\n    type = 'Jaccard')\n\n# Plot the results\n\nsns.set_theme(style=\"whitegrid\", rc=notebook_rcparams)\n\ng = sns.catplot(\n    plot_group_jacc, kind='bar',\n    x='source', y='minuslog10p', hue='type', \n    order=source_order,\n    errorbar=None, margin_titles=True, sharex=False,\n    )\n\ng.despine(left=True)\ng.set_axis_labels(\"\", \"-log10(p)\")\ng.legend.set_title('')\n\n\nfor axis in g.axes.flat:\n    axis.tick_params(labelbottom=True)\n    # rotate said labels\n    for item in axis.get_xticklabels():\n        item.set_rotation(45)\n\ng.tight_layout()\n\n\n\n\n\n\n\n\n\n\nPlot proximity result with Jaccard result\n\n# Concatenate the two plot_groups\n\ngroup = pd.concat([plot_group_prox, plot_group_jacc])\n# display(group[['source', 'resolution', 'type', 'p-value', 'minuslog10p']].query(\n#     'source in (\"Fib\", \"RS\")'\n# ).reset_index(drop=True))\n\n# g = sns.catplot(\n#     group, kind='bar',\n#     x='source', y='minuslog10p', hue='type', \n#     order=source_order,\n#     errorbar=None, margin_titles=True,\n#     height=2, aspect=1.5\n#     )\n# # Plot a horisontal line at p=0.05\n# g.ax.axhline(-np.log10(0.05), color='tab:red', linestyle='--')\n\nf,ax = plt.subplots(figsize=(3,2))\n\n# barplot\ng = sns.barplot(\n    data=group, x='source', y='minuslog10p', hue='type', \n    order=source_order, ax = ax\n    )\n\nax.axhline(-np.log10(0.05), color='tab:red', linestyle='--')\n\n\nsns.despine(ax=g, left=True)\n\ng.set_ylabel('-log10(p)')\ng.set_xlabel('')\ng.get_legend().set_title('')\nsns.move_legend(g, 'upper center', bbox_to_anchor=(0.5,0.975))\n\nf.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 7.1: Proximity and Jaccard index p-values for ECH90 regions on compartment edges for all cell types at 100kb resolution at arms view \\(p=0.05\\) is marked as a red line.\n\n\n\n\n\n\n\nPlot all cominations of the parameters\nAvoid this to avoid p-hacking.\n\n\n# # Define the order of the x-axis if we plot all combinations\n# view_order = ['full', 'arms', '10Mb']\n# row_order = ['Fib', 'SP', 'PAC', 'RS', 'Sperm']\n#\n# sns.set_theme(style=\"whitegrid\")\n#\n# g = sns.catplot(\n#     proximity_res, kind='bar', row='source',\n#     x='view', y='p-value', hue='type', col='resolution', \n#     order=view_order, row_order=row_order,\n#     errorbar=None, margin_titles=True, sharex=False,\n#     )\n#\n# g.despine(left=True)\n# g.set_axis_labels(\"\", \"P-value\")\n# g.legend.set_title('')\n#\n#\n# for axis in g.axes.flat:\n#     axis.tick_params(labelbottom=True)\n#     # rotate said labels\n#     for item in axis.get_xticklabels():\n#         item.set_rotation(45)\n#\n# g.tight_layout()\n\n\n\n# # # Group the results by source and resolution\n# # group = [\"fibroblast\", 'round_spermatid']\n# # # Plot the results from @group\n# # plot_group = jaccard_res.query(f'source in @group')\n# sns.set_theme(style=\"whitegrid\")\n\n# view_order = ['full', 'arms', '10Mb']\n# row_order = ['Fib', 'SP', 'PAC', 'RS', 'Sperm']\n\n# g = sns.catplot(\n#     jaccard_res, kind='bar', row='source',\n#     x='view', y='p-value', hue='type', col='resolution', \n#     margin_titles=True, sharex=False, \n#     order=view_order, row_order=row_order,\n#     errorbar=None)\n\n# g.despine(left=True)\n# g.set_axis_labels(\"\", \"P-value\")\n# g.legend.set_title('')\n# for axis in g.axes.flat:\n#     axis.tick_params(labelbottom=True)\n#     # rotate said labels\n#     for item in axis.get_xticklabels():\n#         item.set_rotation(45)\n#         item.set_va('top')\n\n# g.tight_layout()",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#revised-test-baboon",
    "href": "notebooks/06_rec_genomicintervals.html#revised-test-baboon",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Revised test (baboon)",
    "text": "Revised test (baboon)\n\nBaboon data\nHere, the data for hybrid incompatibility in baboons (having Papio hamadryas or Papio anubis ancestry) is introduced and compared with the edge regions of the compartments. The intervals are extracted from baboondiversity project, in the notebook baboon_ancestry_segments.ipynb.\nThe data originates from a baboon population in a hybridization zone between olive and hamadryas baboons, and the extracted intervals are genomic regions where (almost) all individiuals have the same ancestral allele, 100% from olive or 95% hamadryas. It has nothing to do with Hi-C data, but maybe the intervals align as well?\nThe intervals were lifted to rheMac10 via hg38: panu_3.0 -&gt; hg38 -&gt; rheMac10: two intervals were deleted with no match in the last step:\n#Deleted in new\nchrX    58600000    58700000    high_olive\n#Deleted in new\nchrX    59400000    60800000    high_olive\nAdditionally, 4 intervals were lifted to the Y chromosome, so they were deleted as well\n\n\nThe tests\nWe think the regions where hamadryas ancestry is preserved are the most relevant to this analysis, as the regions are shorter and there are not as many.\nHere, perform the tests as discussed (meeting)\nEdge.v.Edge: (100kb +/- start,end)\n\njaccard_test\n\nquery: [ech, high_hama]\nannot: [rs100_arms_edge, fb100_arms_edge]\nTotal tests: \\(4\\)\n\nproximity_test(overlap_as_zero=True,span_as_zero=True)\n\nquery: [ech, high_hama]\nannot: [rs100_arms_edge, fb100_arms_edge]\nTotal tests: \\(4\\)\n\n\nRegion.v.Region\n\njaccard_bootstrap()\n\nquery: [ech, high_hama]\nannot: [rs100_arms_comp, fb100_arms_comp]\n\n\n\n\nLoad baboons\n\n# Load baboons, define only high_hama\n\nimport pandas as pd\nfrom genominterv import interval_collapse\n\n\n### Lifted with standard UCSC LiftOver\n# baboon_df = pd.read_csv('../results/high_baboon_rhemac10.bed', sep='\\t', index_col=False, header=None, names=['chrom', 'start', 'end', 'group', 'score'])\nbaboon_nonlift = pd.read_csv('../results/hama_olive_high_intervals.tsv', sep='\\t', index_col=False)\n\n# # print(\"Original:\")\n# # print(baboon_df.groupby('group').size())\n\n# high_hama = (interval_collapse(baboon_df.query('group == \"high_hama\"')).\n#              assign(group = \"high_hama\").\n#              query('chrom == \"chrX\"')\n#              ).reset_index(drop=True)\n# high_olive = (interval_collapse(baboon_df.query('group == \"high_olive\"')).\n#               assign(group = \"high_olive\").\n#               query('chrom == \"chrX\"')\n#               )\n# print(\"\\nCollapsed:\")\n# #print(pd.concat([high_hama, high_olive]).groupby('group').size())\n\n\n# #baboon_dict = {\"P.hama\": high_hama, \"P.anubis\": high_olive}\n# print(f\"high_hama: {high_hama.shape[0]}\")\n\n### Lifted with  segment_liftover (`lift` env)\n\nhigh_hama = pd.read_csv('../data/lift/rheMac10/high_hama_rhemac10.bed', sep='\\t', index_col=False, header=None, names=['group', 'chrom', 'start', 'end'])\n\nhigh_olive = pd.read_csv('../data/lift/rheMac10/high_olive_rhemac10.bed', sep='\\t', index_col=False, header=None, names=['group', 'chrom', 'start', 'end'])\n\n\n\nDefine functions\n\nfrom genominterv import interval_collapse\nfrom multiprocessing import cpu_count\nfrom genominterv.stats import jaccard_stat, proximity_stat\nfrom genominterv.decorators import bootstrap\nimport numpy as np\nimport pandas as pd\n\n# Make edges function\n\n## Make a function that splits an interval into its edges (and collapses overlapping edges)\n\ndef make_edges(df, resolution):\n    start_edge = pd.DataFrame({\n        'chrom': df['chrom'],\n        'start': df.apply(lambda x: max(x['start'] - resolution, 0), axis=1),\n        'end': df['start']+1*resolution,\n        'resolution': resolution,\n    })\n    end_edge = pd.DataFrame({\n        'chrom': df['chrom'],\n        'start': df['end']-1*resolution,\n        'end': df.apply(lambda x: min(x['end'] + resolution, chromsizes['chrX']), axis=1),\n        'resolution': resolution,\n    })\n\n    return interval_collapse(pd.concat([start_edge, end_edge]).sort_values(['chrom', 'start', 'end'])).assign(resolution=resolution)\n\n\nnsamples=100_000\n\n@bootstrap(chromsizes, samples=nsamples)\ndef proximity_test(q, a):\n    \"\"\"\n    Tests if the mean relative distance of query segments to the\n    closest annotation is smaller than expected.\n    \"\"\"\n    return proximity_stat(q, a)\n\n@bootstrap(chromsizes, samples=nsamples)\ndef jaccard_test(q, a):\n    \"\"\"\"\n    Tests if the overlap between query and annotation segments \n    is smaller than expected.\n    \"\"\"\n    return jaccard_stat(q, a)\n\ndef overlaps(df1, df2):\n    \"\"\"\n    Establishes whether each query segment overlaps at least one \n    annotation segment. Returns a boolean array with same length \n    as df1.index.\n    \"\"\"\n    overlapping = []\n    for i, (s1, e1) in enumerate(zip(df1.start, df1.end)):\n        overlaps = False\n        for s2, e2 in zip(df2.start, df2.end):\n            if e1 &gt; s2 and e2 &gt; s1:\n                overlaps = True\n                break\n        overlapping.append(overlaps)\n    return np.array(overlapping)\n\ndef svedig_tabel(orig_df, index, columns, values, cmap='Reds'):\n    df = (orig_df\n        .assign(log10p=np.log10(results.p))\n        .loc[(results.p &lt; 0.05)]\n        .pivot(index=index, columns=columns, values=values)\n    )\n    df = df.rename(columns = {x:x.replace('_', '&lt;br&gt;') for x in df.columns.tolist()})\n    df = (df.style\n        .background_gradient(subset=df.columns, axis=None, cmap=cmap, vmin=0)\n        .map(lambda x: 'color: transparent; background-color: transparent' if np.isnan(x) else '')\n        .format('{:.3f}')\n        .set_table_styles(\n                {c: [{'selector': '', \n                        'props': [('min-width', '100px')],\n                        }] for c in df.columns}, overwrite=False\n        )\n    )\n    return df\n\n\n\n\nLoad comps and edges\n\n# Define the rest and get an overview of the selected samples\n\nsamples = ['fibroblast_100kb_arms', 'round_spermatid_100kb_arms']\n\nfb100_dict = {\n    'full':dataframes[samples[0]], \n    'edges':edge_df[f'{samples[0]}_edges'],\n    'limits': make_edges(dataframes[samples[0]], 1)}\n\nrs100_dict = {\n    'full':dataframes[samples[1]],\n    'edges':edge_df[f'{samples[1]}_edges'],\n    'limits': make_edges(dataframes[samples[1]], 1)}\n\nhama_dict = {\n    'full': high_hama,\n    'edges': make_edges(high_hama, 100_000),\n    'limits': make_edges(high_hama, 1)\n}\n\nolive_dict = {\n    'full': high_olive,\n    'edges': make_edges(high_olive, 100_000),\n    'limits': make_edges(high_olive, 1)\n}\n\nech_dict = {'full': ech90,\n            'edges': make_edges(ech90, 100_000),\n            'limits': make_edges(ech90, 1)}\n\n\n\nSummarise\n\n# Summarise how much the edges are reduced compared to the full regions\n\nnames = ['Fibroblast', 'Round spermatid', 'Hamadryas', 'Olive', 'ECH']\nsamples = [fb100_dict, rs100_dict, hama_dict, olive_dict, ech_dict]\n\n# \n\nsummary = pd.DataFrame({\n    'Sample': names,\n    'Full_bp': [sum(sample['full']['end'] - sample['full']['start']) for sample in samples],\n    'full_avg_bp': [round(sum(sample['full']['end'] - sample['full']['start']) / sample['full'].shape[0], 1) for sample in samples],\n    'Edge_bp': [sum(sample['edges']['end'] - sample['edges']['start']) for sample in samples],\n    'edge_avg_bp': [round(sum(sample['edges']['end'] - sample['edges']['start']) / sample['edges'].shape[0], 1) for sample in samples],\n\n}).assign(edge_over_full=lambda x: round(x['Edge_bp'] / x['Full_bp'],3))\n\n# tell pandas to use thousands separator\ndisplay(summary.style.format(\"{:,.0f}\", subset=['Full_bp', 'Edge_bp']).format(\"{:,.1f}\", subset=['full_avg_bp', 'edge_avg_bp']).format(\"{:.1%}\", subset='edge_over_full'))\n\nplot_regions(high_olive, high_hama, ech90, track_titles=['Hama', 'Olive', 'ECH90'])\n\nplot_regions(high_olive,baboon_nonlift.query('group == \"high_olive\"'), track_titles=['Lifted High olive', 'Non-lifted high olive'])\n\n\n\n\n\n\n\n \nSample\nFull_bp\nfull_avg_bp\nEdge_bp\nedge_avg_bp\nedge_over_full\n\n\n\n\n0\nFibroblast\n64,200,000\n1,088,135.6\n21,600,000\n260,241.0\n33.6%\n\n\n1\nRound spermatid\n56,500,000\n733,766.2\n27,088,924\n282,176.3\n47.9%\n\n\n2\nHamadryas\n8,775,834\n516,225.5\n6,434,612\n229,807.6\n73.3%\n\n\n3\nOlive\n44,876,120\n1,319,885.9\n12,715,662\n219,235.6\n28.3%\n\n\n4\nECH\n5,511,675\n290,088.2\n7,195,159\n224,848.7\n130.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest\n\nTest revised I\n\n# Now define tests \nfrom genominterv.decorators import bootstrap\nfrom genominterv.stats import proximity_test, jaccard_stat\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\n\nn_samples=100_000\n\n## Proximity test\n\ndef proximity_parallel(query, annot, nsamples=100_000, oaz=False, saz=False):\n    q_key, a_key = query, annot\n    query = prox_dict[q_key]\n    annot = prox_dict[a_key]\n    \n    test = proximity_test(query, annot, nsamples, \n                          overlap_as_zero=oaz, \n                          span_as_zero=saz\n                          )\n\n    results = [\n        {'Query': q_key,\n         'Annot': a_key, \n         'Statistic': test.statistic, \n         'P-value': test.pvalue,\n         'Overlap as zero': oaz,\n         'Span as zero': saz\n         }\n    ]\n\n    return results\n\n## Jaccard bootstrap\n@bootstrap(chromsizes, samples=10_000)\ndef jaccard_bootstrap(query, annot):\n    return jaccard_stat(query, annot)\n\ndef jaccard_parallel(query, annot):\n    q_key = query\n    a_key = annot\n    query = jacc_dict[q_key]\n    annot = jacc_dict[a_key]\n\n    test = jaccard_bootstrap(query, annot)\n\n    results = [\n        {'Query': q_key,\n            'Annot': a_key, \n            'Index': test[0], \n            'P-value': test[1]\n            }]\n    return results\n\n# Now do the testing\n# Define the samples\nprox_dict = {'ECH90': ech_dict['full'],\n             'Hamadryas': hama_dict['full'],\n             'Olive': olive_dict['full'],\n             'Fib100_edge': fb100_dict['edges'],\n             'RS100_edge': rs100_dict['edges'],\n             'RS100_full': rs100_dict['full']\n            }\n\nprox_samples = [('ECH90', 'Fib100_edge', n_samples),\n                ('ECH90', 'RS100_edge', n_samples),\n                ('Hamadryas', 'Fib100_edge', n_samples),\n                ('Hamadryas', 'RS100_edge', n_samples),\n                ('Olive', 'Fib100_edge', n_samples),\n                ('Olive', 'RS100_edge', n_samples),\n                ('Olive', 'RS100_full', n_samples),\n                ('Hamadryas', 'RS100_full', n_samples),\n                ]\n\n# First, without oaz, saz\nproximity_res1 = Parallel(n_jobs=-1)(\n    delayed(proximity_parallel)(que, ann, n, False, False) for (que,ann,n) in tqdm(prox_samples)\n)\nproximity_res1 = pd.DataFrame([item for sublist in proximity_res1 for item in sublist])\n\n# Now with oaz, saz\nproximity_res2 = Parallel(n_jobs=-1)(\n    delayed(proximity_parallel)(que, ann, n, True, True) for (que,ann,n) in tqdm(prox_samples)\n)\nproximity_res2 = pd.DataFrame([item for sublist in proximity_res2 for item in sublist])\n\n# Now with oaz, saz\nproximity_res3 = Parallel(n_jobs=-1)(\n    delayed(proximity_parallel)(que, ann, n, True, False) for (que,ann,n) in tqdm(prox_samples)\n)\nproximity_res3 = pd.DataFrame([item for sublist in proximity_res3 for item in sublist])\n\n\n# Concatenate the results\nproximity_res = pd.concat([proximity_res1, proximity_res2, proximity_res3])\n\n# Write to CSV\n#proximity_res.to_csv('../results/proximity_revised.csv', index=False)\n\n# Now do the Jaccard index\njacc_samples = [(ech_dict['full'], fb100_dict['full']), \n                (hama_dict['full'], rs100_dict['full'])\n                ]\n\njacc_dict = {'ECH90': ech_dict['full'],\n             'Hamadryas': hama_dict['full'],\n             'Olive': olive_dict['full'],\n             'Fib100_edge': fb100_dict['edges'],\n             'Fib100_full': fb100_dict['full'],\n             'RS100_full': rs100_dict['full'],\n             'RS100_edge': rs100_dict['edges']\n            }\njacc_samples = [\n    ('ECH90', 'Fib100_full'),\n    ('ECH90', 'Fib100_edge'),\n    ('ECH90', 'RS100_full'),\n    ('ECH90', 'RS100_edge'),\n    ('Hamadryas', 'Fib100_full'),\n    ('Hamadryas', 'Fib100_edge'),\n    ('Hamadryas', 'RS100_full'),\n    ('Hamadryas', 'RS100_edge'),\n    ('Olive', 'Fib100_edge'),\n    ('Olive', 'RS100_edge'),\n    ]\n\njaccard_res = Parallel(n_jobs=-1)(\n    delayed(jaccard_parallel)(que, ann) for (que,ann) in tqdm(jacc_samples)\n)   \n\n# Flatten and create DataFrame\njaccard_res = pd.DataFrame([item for sublist in jaccard_res for item in sublist])\n\n# Write to CSV\n#jaccard_res.to_csv('../results/jaccard_revised.csv', index=False)\n\n100%|██████████| 8/8 [00:00&lt;00:00, 395.88it/s]\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[15], line 75\n     64 prox_samples = [('ECH90', 'Fib100_edge', n_samples),\n     65                 ('ECH90', 'RS100_edge', n_samples),\n     66                 ('Hamadryas', 'Fib100_edge', n_samples),\n   (...)\n     71                 ('Hamadryas', 'RS100_full', n_samples),\n     72                 ]\n     74 # First, without oaz, saz\n---&gt; 75 proximity_res1 = Parallel(n_jobs=-1)(\n     76     delayed(proximity_parallel)(que, ann, n, False, False) for (que,ann,n) in tqdm(prox_samples)\n     77 )\n     78 proximity_res1 = pd.DataFrame([item for sublist in proximity_res1 for item in sublist])\n     80 # Now with oaz, saz\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:2007, in Parallel.__call__(self, iterable)\n   2001 # The first item from the output is blank, but it makes the interpreter\n   2002 # progress until it enters the Try/Except block of the generator and\n   2003 # reaches the first `yield` statement. This starts the asynchronous\n   2004 # dispatch of the tasks to the workers.\n   2005 next(output)\n-&gt; 2007 return output if self.return_generator else list(output)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:1650, in Parallel._get_outputs(self, iterator, pre_dispatch)\n   1647     yield\n   1649     with self._backend.retrieval_context():\n-&gt; 1650         yield from self._retrieve()\n   1652 except GeneratorExit:\n   1653     # The generator has been garbage collected before being fully\n   1654     # consumed. This aborts the remaining tasks if possible and warn\n   1655     # the user if necessary.\n   1656     self._exception = True\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/joblib/parallel.py:1762, in Parallel._retrieve(self)\n   1757 # If the next job is not ready for retrieval yet, we just wait for\n   1758 # async callbacks to progress.\n   1759 if ((len(self._jobs) == 0) or\n   1760     (self._jobs[0].get_status(\n   1761         timeout=self.timeout) == TASK_PENDING)):\n-&gt; 1762     time.sleep(0.01)\n   1763     continue\n   1765 # We need to be careful: the job list can be filling up as\n   1766 # we empty it and Python list are not thread-safe by\n   1767 # default hence the use of the lock\n\nKeyboardInterrupt: \n\n\n\n\n\ndisplay('Proximity:',proximity_res.sort_values(['Query', 'Annot','Overlap as zero']), \n        'Jaccard:',jaccard_res)\n\n'Proximity:'\n\n\n\n\n\n\n\n\n\nQuery\nAnnot\nStatistic\nP-value\nOverlap as zero\nSpan as zero\n\n\n\n\n0\nECH90\nFib100_edge\n0.126462\n0.18750\nFalse\nFalse\n\n\n0\nECH90\nFib100_edge\n0.320105\n0.00000\nTrue\nTrue\n\n\n0\nECH90\nFib100_edge\n0.320105\n0.00000\nTrue\nFalse\n\n\n1\nECH90\nRS100_edge\n-0.051091\n0.85932\nFalse\nFalse\n\n\n1\nECH90\nRS100_edge\n0.412667\n0.00000\nTrue\nTrue\n\n\n1\nECH90\nRS100_edge\n0.383300\n0.00000\nTrue\nFalse\n\n\n2\nHamadryas\nFib100_edge\n0.010583\n0.49535\nFalse\nFalse\n\n\n2\nHamadryas\nFib100_edge\n0.121857\n0.00057\nTrue\nTrue\n\n\n2\nHamadryas\nFib100_edge\n0.121857\n0.32055\nTrue\nFalse\n\n\n3\nHamadryas\nRS100_edge\n0.043037\n0.46991\nFalse\nFalse\n\n\n3\nHamadryas\nRS100_edge\n0.079267\n0.10159\nTrue\nTrue\n\n\n3\nHamadryas\nRS100_edge\n0.079267\n0.00830\nTrue\nFalse\n\n\n7\nHamadryas\nRS100_full\n-0.038111\n0.67801\nFalse\nFalse\n\n\n7\nHamadryas\nRS100_full\n0.065700\n0.55859\nTrue\nTrue\n\n\n7\nHamadryas\nRS100_full\n0.065700\n0.32201\nTrue\nFalse\n\n\n4\nOlive\nFib100_edge\n0.267519\n0.00000\nFalse\nFalse\n\n\n4\nOlive\nFib100_edge\n0.281078\n0.00000\nTrue\nTrue\n\n\n4\nOlive\nFib100_edge\n0.277333\n0.00000\nTrue\nFalse\n\n\n5\nOlive\nRS100_edge\n0.137642\n0.00000\nFalse\nFalse\n\n\n5\nOlive\nRS100_edge\n0.156492\n0.00000\nTrue\nTrue\n\n\n5\nOlive\nRS100_edge\n0.156492\n0.00000\nTrue\nFalse\n\n\n6\nOlive\nRS100_full\n0.179701\n0.00000\nFalse\nFalse\n\n\n6\nOlive\nRS100_full\n0.197664\n0.00000\nTrue\nTrue\n\n\n6\nOlive\nRS100_full\n0.185778\n0.00000\nTrue\nFalse\n\n\n\n\n\n\n\n'Jaccard:'\n\n\n\n\n\n\n\n\n\nQuery\nAnnot\nIndex\nP-value\n\n\n\n\n0\nECH90\nFib100_full\n0.042072\n0.1962\n\n\n1\nECH90\nFib100_edge\n0.063394\n0.0141\n\n\n2\nECH90\nRS100_full\n0.046543\n0.1005\n\n\n3\nECH90\nRS100_edge\n0.062911\n0.0121\n\n\n4\nHamadryas\nFib100_full\n0.032936\n0.2989\n\n\n5\nHamadryas\nFib100_edge\n0.015783\n0.7405\n\n\n6\nHamadryas\nRS100_full\n0.031271\n0.3467\n\n\n7\nHamadryas\nRS100_edge\n0.022037\n0.5719\n\n\n8\nOlive\nFib100_edge\n0.039584\n0.7753\n\n\n9\nOlive\nRS100_edge\n0.039312\n0.8489\n\n\n\n\n\n\n\n\n\nTest revised II\nKasper realized it is very hard to capture both proximity and intersect in the same statistic. Thus, we go back to test the overlapping regions with Jaccard test, and use a new proximity test, measuring the mean distance between query regions and annotation regions, almost with the same power as the previous one.\n\n\n### Test the functions ### took 25 seconds for nsamples=100_000\n\nquery = ech90\nannot = edge_df['round_spermatid_100kb_arms_edges']\n\nstat, p = jaccard_test(query, annot)\nprint(f'''\nJaccard overlap test: \n    stat: {stat} \n       p: {p}\n''')\n\nquery_non_ovl = query.loc[~overlaps(query, annot)]   \nstat, p = proximity_test(query_non_ovl, annot)\nprint(f'''\nProximity test: \n    stat: {stat} \n       p: {p} \n''')\n\n\nJaccard overlap test: \n    stat: 0.06291087597375193 \n       p: 0.01016\n\n\nProximity test: \n    stat: 0.23724870541725634 \n       p: 0.78488 \n\n\n\n\n### Make it a loop in stead\na_names = ['Fb100arms_edge', 'RS100arms_edge', \n           'Fb100_10Mb_edge', 'RS100_10Mb_edge',\n           'Fb100arms_full', 'RS100arms_full']\nq_names = ['ECH', 'Hama', 'Olive',\n           'ECH_edge', 'Hama_edge', 'Olive_edge']\n\nannots = [edge_df['fibroblast_100kb_arms_edges'], edge_df['round_spermatid_100kb_arms_edges'], \n          edge_df['fibroblast_100kb_10Mb_edges'], edge_df['round_spermatid_100kb_10Mb_edges'],\n          dataframes['fibroblast_100kb_arms'], dataframes['round_spermatid_100kb_arms']]\nqueries = [ech_dict['full'], hama_dict['full'], olive_dict['full'],\n            ech_dict['edges'], hama_dict['edges'], olive_dict['edges']]\n\nresults = pd.DataFrame({\n    'Query': [],\n    'Annotation': [],\n    'Jaccard Index': [],\n    'Jaccard P-value': [],\n    'Proximity Statistic': [],\n    'Proximity P-value': []\n})\n\nfor i,query in enumerate(queries):\n    print(f'i = {i}')\n    for j,annot in enumerate(annots):\n        print(f'j = {j}')\n        j_stat, j_p = jaccard_test(query, annot)\n        query_non_ovl = query.loc[~overlaps(query, annot)]   \n        p_stat, p_p = proximity_test(query_non_ovl, annot)\n        tmp = pd.DataFrame(\n            {\n            'Query': q_names[i],\n            'Annotation': a_names[j],\n            'Jaccard Index': j_stat,\n            'Jaccard P-value': j_p,\n            'Proximity Statistic': p_stat,\n            'Proximity P-value': p_p\n            }, \n            index=[0])\n        results = pd.concat([results, tmp], ignore_index=True)\n\nresults\n\ni = 0\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\ni = 1\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\ni = 2\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\ni = 3\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\ni = 4\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\ni = 5\nj = 0\nj = 1\nj = 2\nj = 3\nj = 4\nj = 5\n\n\n\n\n\n\n\n\n\nQuery\nAnnotation\nJaccard Index\nJaccard P-value\nProximity Statistic\nProximity P-value\n\n\n\n\n0\nECH\nFb100arms_edge\n0.063394\n0.01176\n0.281690\n0.31419\n\n\n1\nECH\nRS100arms_edge\n0.062911\n0.01016\n0.237249\n0.89885\n\n\n2\nECH\nFb100_10Mb_edge\n0.048480\n0.08807\n0.221680\n0.73092\n\n\n3\nECH\nRS100_10Mb_edge\n0.057965\n0.02465\n0.280611\n0.33422\n\n\n4\nECH\nFb100arms_full\n0.042072\n0.19652\n0.188639\n0.87190\n\n\n5\nECH\nRS100arms_full\n0.046543\n0.10433\n0.277032\n0.58258\n\n\n6\nHama\nFb100arms_edge\n0.021886\n0.90061\n0.253639\n0.51626\n\n\n7\nHama\nRS100arms_edge\n0.027870\n0.85140\n0.256731\n0.50021\n\n\n8\nHama\nFb100_10Mb_edge\n0.031809\n0.74751\n0.253548\n0.51450\n\n\n9\nHama\nRS100_10Mb_edge\n0.034824\n0.72508\n0.298500\n0.55472\n\n\n10\nHama\nFb100arms_full\n0.059582\n0.33024\n0.255948\n0.68782\n\n\n11\nHama\nRS100arms_full\n0.069205\n0.15858\n0.242701\n0.82281\n\n\n12\nOlive\nFb100arms_edge\n0.109276\n0.39855\n0.279857\n0.27256\n\n\n13\nOlive\nRS100arms_edge\n0.139396\n0.23590\n0.239110\n0.65186\n\n\n14\nOlive\nFb100_10Mb_edge\n0.082725\n0.93407\n0.252348\n0.53033\n\n\n15\nOlive\nRS100_10Mb_edge\n0.146962\n0.17529\n0.242756\n0.61615\n\n\n16\nOlive\nFb100arms_full\n0.281681\n0.03044\n0.272324\n0.54491\n\n\n17\nOlive\nRS100arms_full\n0.209506\n0.31974\n0.235625\n0.66108\n\n\n18\nECH_edge\nFb100arms_edge\n0.076356\n0.00430\n0.295478\n0.17750\n\n\n19\nECH_edge\nRS100arms_edge\n0.062408\n0.03353\n0.266103\n0.39102\n\n\n20\nECH_edge\nFb100_10Mb_edge\n0.057708\n0.06635\n0.269624\n0.34090\n\n\n21\nECH_edge\nRS100_10Mb_edge\n0.074277\n0.00502\n0.273560\n0.35292\n\n\n22\nECH_edge\nFb100arms_full\n0.051794\n0.18487\n0.295836\n0.02331\n\n\n23\nECH_edge\nRS100arms_full\n0.054435\n0.11827\n0.274170\n0.76486\n\n\n24\nHama_edge\nFb100arms_edge\n0.014028\n0.95038\n0.240012\n0.64586\n\n\n25\nHama_edge\nRS100arms_edge\n0.033281\n0.53688\n0.244095\n0.60001\n\n\n26\nHama_edge\nFb100_10Mb_edge\n0.029314\n0.63135\n0.262847\n0.40006\n\n\n27\nHama_edge\nRS100_10Mb_edge\n0.044633\n0.21777\n0.234146\n0.67282\n\n\n28\nHama_edge\nFb100arms_full\n0.053583\n0.05399\n0.191426\n0.73381\n\n\n29\nHama_edge\nRS100arms_full\n0.061216\n0.00984\n0.200406\n0.23433\n\n\n30\nOlive_edge\nFb100arms_edge\n0.038987\n0.86829\n0.250063\n0.54602\n\n\n31\nOlive_edge\nRS100arms_edge\n0.049514\n0.75737\n0.257123\n0.43711\n\n\n32\nOlive_edge\nFb100_10Mb_edge\n0.057027\n0.47363\n0.257397\n0.42562\n\n\n33\nOlive_edge\nRS100_10Mb_edge\n0.051652\n0.71605\n0.243567\n0.64340\n\n\n34\nOlive_edge\nFb100arms_full\n0.079507\n0.32081\n0.258289\n0.46700\n\n\n35\nOlive_edge\nRS100arms_full\n0.071486\n0.51293\n0.237859\n0.67562\n\n\n\n\n\n\n\n\nsubset_annot = ['RS100arms_edge', 'RS100_10Mb_edge',\n                'Fb100arms_edge', 'Fb100_10Mb_edge']\nsubset_query = ['ECH_edge', 'Hama_edge', 'Olive_edge']\ndisplay((results\n .query('Annotation in @subset_annot and Query in @subset_query')\n .sort_values(['Annotation','Query'])\n .filter(['Annotation','Query', 'Jaccard P-value', 'Proximity P-value'])\n)\n)\n\n\n\n\n\n\n\n\nAnnotation\nQuery\nJaccard P-value\nProximity P-value\n\n\n\n\n20\nFb100_10Mb_edge\nECH_edge\n0.06635\n0.34090\n\n\n26\nFb100_10Mb_edge\nHama_edge\n0.63135\n0.40006\n\n\n32\nFb100_10Mb_edge\nOlive_edge\n0.47363\n0.42562\n\n\n18\nFb100arms_edge\nECH_edge\n0.00430\n0.17750\n\n\n24\nFb100arms_edge\nHama_edge\n0.95038\n0.64586\n\n\n30\nFb100arms_edge\nOlive_edge\n0.86829\n0.54602\n\n\n21\nRS100_10Mb_edge\nECH_edge\n0.00502\n0.35292\n\n\n27\nRS100_10Mb_edge\nHama_edge\n0.21777\n0.67282\n\n\n33\nRS100_10Mb_edge\nOlive_edge\n0.71605\n0.64340\n\n\n19\nRS100arms_edge\nECH_edge\n0.03353\n0.39102\n\n\n25\nRS100arms_edge\nHama_edge\n0.53688\n0.60001\n\n\n31\nRS100arms_edge\nOlive_edge\n0.75737\n0.43711\n\n\n\n\n\n\n\n\n# plot the significant proximity-result\nquery=ech_dict['edges']\nannot= fb100_dict['full']\n\nplot_regions(query, annot, interval_intersect(query, annot), track_titles=['ECH90', 'Fb100_full', 'Intersect'])\n\n# plot some Jaccard-results\n\nquery=ech_dict['edges']\nannot= edge_df['round_spermatid_100kb_10Mb_edges']\n\nplot_regions(query, annot, interval_intersect(query, annot), track_titles=['ECH90', 'RS100_10Mb_edges', 'Intersect'])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo new test with limits (2bp)\n\n\n# Calcilate the proximity and Jaccard tests\n# Annot: Fb, SPA, PAC, RS, SP (edges)\n# Query: ECH\n\n# Define the samples\n\nannots = {\n    'Fb': dataframes['fibroblast_100kb_arms'], \n    'Spa': dataframes['spermatogonia_100kb_arms'],\n    'Pac': dataframes['pachytene_spermatocyte_100kb_arms'],\n    'RS': dataframes['round_spermatid_100kb_arms'],\n    'Spz': dataframes['sperm_100kb_arms']\n}\nqueries = {\n    'ECH': ech90,\n    'ECH_lim': make_edges(ech90, 1),\n    'Hama_lim': make_edges(high_hama, 1),\n    'Olive_lim': make_edges(high_olive, 1)\n}\n\n# Run the tests\n\ntest_results = {\n    'Query': [],\n    'Source': [],\n    'Type': [],\n    'Jaccard': [],\n    'Proximity': []\n}\n\nfor i,(name,annot) in enumerate(annots.items()):\n    print(f'{i+1} of {len(annots)}: {name}')\n\n    tmp_annots = {'comps': annot, \n                  'edges': make_edges(annot, 100_000), \n                  'limits': make_edges(annot, 1)}\n    \n    for tmp_query_key, query in queries.items():\n        print(f'\\tQuery: {tmp_query_key}')\n        for tmp_key, tmp_annot in tmp_annots.items():\n            print(f'\\t\\t{tmp_key}',end=' ')\n            _, j_p = jaccard_test(query, tmp_annot)\n            print('--&gt; Jaccard done', end=' ')\n            query_non_ovl = query.loc[~overlaps(query, tmp_annot)]   \n            _, p_p = proximity_test(query_non_ovl, tmp_annot)\n            print('--&gt; Proximity done.')\n\n            # Append to results\n            test_results['Query'].append(tmp_query_key)\n            test_results['Source'].append(name)\n            test_results['Type'].append(tmp_key)\n            test_results['Jaccard'].append(j_p)\n            test_results['Proximity'].append(p_p)\n\nresults = pd.DataFrame(test_results)\nresults\n\n1 of 5: Fb\n    Query: ECH\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: ECH_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Hama_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Olive_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n2 of 5: Spa\n    Query: ECH\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: ECH_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Hama_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Olive_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n3 of 5: Pac\n    Query: ECH\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: ECH_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Hama_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Olive_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n4 of 5: RS\n    Query: ECH\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: ECH_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Hama_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Olive_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n5 of 5: Spz\n    Query: ECH\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: ECH_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Hama_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n    Query: Olive_lim\n        comps --&gt; Jaccard done --&gt; Proximity done.\n        edges --&gt; Jaccard done --&gt; Proximity done.\n        limits --&gt; Jaccard done --&gt; Proximity done.\n\n\n\n\n\n\n\n\n\nQuery\nSource\nType\nJaccard\nProximity\n\n\n\n\n0\nECH\nFb\ncomps\n0.19934\n0.82548\n\n\n1\nECH\nFb\nedges\n0.01199\n0.31260\n\n\n2\nECH\nFb\nlimits\n0.00530\n0.55282\n\n\n3\nECH_lim\nFb\ncomps\n0.40849\n0.65961\n\n\n4\nECH_lim\nFb\nedges\n0.03409\n0.29474\n\n\n5\nECH_lim\nFb\nlimits\n1.00000\n0.55628\n\n\n6\nHama_lim\nFb\ncomps\n0.12358\n0.62059\n\n\n7\nHama_lim\nFb\nedges\n0.87612\n0.89615\n\n\n8\nHama_lim\nFb\nlimits\n1.00000\n0.86046\n\n\n9\nOlive_lim\nFb\ncomps\n0.27137\n0.36505\n\n\n10\nOlive_lim\nFb\nedges\n0.85070\n0.51847\n\n\n11\nOlive_lim\nFb\nlimits\n1.00000\n0.60821\n\n\n12\nECH\nSpa\ncomps\n0.05156\n0.00314\n\n\n13\nECH\nSpa\nedges\n0.49491\n0.24411\n\n\n14\nECH\nSpa\nlimits\n0.68780\n0.23246\n\n\n15\nECH_lim\nSpa\ncomps\n0.33333\n0.03413\n\n\n16\nECH_lim\nSpa\nedges\n0.23260\n0.09237\n\n\n17\nECH_lim\nSpa\nlimits\n1.00000\n0.04169\n\n\n18\nHama_lim\nSpa\ncomps\n0.09449\n0.51142\n\n\n19\nHama_lim\nSpa\nedges\n0.62895\n0.61381\n\n\n20\nHama_lim\nSpa\nlimits\n0.00001\n0.50210\n\n\n21\nOlive_lim\nSpa\ncomps\n0.57259\n0.58325\n\n\n22\nOlive_lim\nSpa\nedges\n0.91817\n0.19321\n\n\n23\nOlive_lim\nSpa\nlimits\n1.00000\n0.46966\n\n\n24\nECH\nPac\ncomps\n0.59824\n0.42413\n\n\n25\nECH\nPac\nedges\n0.10229\n0.74138\n\n\n26\nECH\nPac\nlimits\n0.15461\n0.69764\n\n\n27\nECH_lim\nPac\ncomps\n0.46237\n0.92811\n\n\n28\nECH_lim\nPac\nedges\n0.10141\n0.74043\n\n\n29\nECH_lim\nPac\nlimits\n1.00000\n0.71976\n\n\n30\nHama_lim\nPac\ncomps\n0.39982\n0.66599\n\n\n31\nHama_lim\nPac\nedges\n0.48866\n0.22423\n\n\n32\nHama_lim\nPac\nlimits\n0.00005\n0.44405\n\n\n33\nOlive_lim\nPac\ncomps\n0.03725\n0.78024\n\n\n34\nOlive_lim\nPac\nedges\n0.58759\n0.34903\n\n\n35\nOlive_lim\nPac\nlimits\n0.00004\n0.39258\n\n\n36\nECH\nRS\ncomps\n0.10578\n0.07079\n\n\n37\nECH\nRS\nedges\n0.01046\n0.61816\n\n\n38\nECH\nRS\nlimits\n0.00655\n0.73480\n\n\n39\nECH_lim\nRS\ncomps\n0.18603\n0.34104\n\n\n40\nECH_lim\nRS\nedges\n0.11797\n0.53686\n\n\n41\nECH_lim\nRS\nlimits\n1.00000\n0.35290\n\n\n42\nHama_lim\nRS\ncomps\n0.01714\n0.85609\n\n\n43\nHama_lim\nRS\nedges\n0.56556\n0.78961\n\n\n44\nHama_lim\nRS\nlimits\n1.00000\n0.78258\n\n\n45\nOlive_lim\nRS\ncomps\n0.39299\n0.78907\n\n\n46\nOlive_lim\nRS\nedges\n0.66654\n0.75863\n\n\n47\nOlive_lim\nRS\nlimits\n1.00000\n0.56521\n\n\n48\nECH\nSpz\ncomps\n0.03892\n0.86643\n\n\n49\nECH\nSpz\nedges\n0.07330\n0.63545\n\n\n50\nECH\nSpz\nlimits\n0.08195\n0.88817\n\n\n51\nECH_lim\nSpz\ncomps\n0.10352\n0.54812\n\n\n52\nECH_lim\nSpz\nedges\n0.80407\n0.54553\n\n\n53\nECH_lim\nSpz\nlimits\n1.00000\n0.73543\n\n\n54\nHama_lim\nSpz\ncomps\n0.20128\n0.13174\n\n\n55\nHama_lim\nSpz\nedges\n0.53662\n0.22328\n\n\n56\nHama_lim\nSpz\nlimits\n1.00000\n0.09604\n\n\n57\nOlive_lim\nSpz\ncomps\n0.18841\n0.59118\n\n\n58\nOlive_lim\nSpz\nedges\n0.84400\n0.55331\n\n\n59\nOlive_lim\nSpz\nlimits\n1.00000\n0.64852\n\n\n\n\n\n\n\n\nq_filter = ['ECH', 'Hama_lim', 'Olive_lim']\n\nresults.query('Query in @q_filter and Type == \"limits\"').sort_values(['Source', 'Type'])\n\n\n\n\n\n\n\n\nQuery\nSource\nType\nJaccard\nProximity\n\n\n\n\n2\nECH\nFb\nlimits\n0.00530\n0.55282\n\n\n8\nHama_lim\nFb\nlimits\n1.00000\n0.86046\n\n\n11\nOlive_lim\nFb\nlimits\n1.00000\n0.60821\n\n\n26\nECH\nPac\nlimits\n0.15461\n0.69764\n\n\n32\nHama_lim\nPac\nlimits\n0.00005\n0.44405\n\n\n35\nOlive_lim\nPac\nlimits\n0.00004\n0.39258\n\n\n38\nECH\nRS\nlimits\n0.00655\n0.73480\n\n\n44\nHama_lim\nRS\nlimits\n1.00000\n0.78258\n\n\n47\nOlive_lim\nRS\nlimits\n1.00000\n0.56521\n\n\n14\nECH\nSpa\nlimits\n0.68780\n0.23246\n\n\n20\nHama_lim\nSpa\nlimits\n0.00001\n0.50210\n\n\n23\nOlive_lim\nSpa\nlimits\n1.00000\n0.46966\n\n\n50\nECH\nSpz\nlimits\n0.08195\n0.88817\n\n\n56\nHama_lim\nSpz\nlimits\n1.00000\n0.09604\n\n\n59\nOlive_lim\nSpz\nlimits\n1.00000\n0.64852\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Melt the results to a P-value column\ntest_results_melt = (\n    test_results\n    .rename(columns={'Jaccard P-value': 'Jaccard', 'Proximity P-value': 'Proximity'})\n    .melt(\n        id_vars=['Query', 'Annotation'],\n        value_vars=['Jaccard', 'Proximity'], \n        var_name='type', value_name='p-value')\n    .assign(logp=lambda x: -np.log10(x['p-value']))\n)\n\nsource_order = ['Fb', 'Spa', 'Pac', 'RS', 'Spz']\n\nf,ax = plt.subplots(figsize=(3,2))\n\ng = sns.barplot(\n    data=test_results_melt, x='Annotation', y='logp', hue='type', \n    order=source_order, ax = ax\n    )\nax.axhline(-np.log10(0.05), color='tab:red', linestyle='--')\n\n\nsns.despine(ax=g, left=True)\n\ng.set_ylabel('-log10(p)')\ng.set_xlabel('')\ng.get_legend().set_title('')\nsns.move_legend(g, 'upper center', bbox_to_anchor=(0.4,0.975))\n\n\n\n\n\n\n\n\nFigure 7.2: Proximity and Jaccard index p-values for ECH90 regions on compartment edges for all cell types at 100kb resolution at arms view \\(p=0.05\\) is marked as a red line.\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Melt the results to a P-value column\ntest_results_melt = (\n    results.query('Query == \"ECH_limits\"')\n    .melt(\n        id_vars=['Query', 'Source'],\n        value_vars=['Jaccard', 'Proximity'], \n        var_name='test', value_name='p-value')\n    .assign(logp=lambda x: -np.log10(x['p-value']))\n)\n\nsource_order = ['Fb', 'Spa', 'Pac', 'RS', 'Spz']\n\nf,ax = plt.subplots(figsize=(3,2))\n\ng = sns.barplot(\n    data=test_results_melt, x='Source', y='logp', hue='test', \n    order=source_order, ax = ax\n    )\nax.axhline(-np.log10(0.05), color='tab:red', linestyle='--')\n\n\nsns.despine(ax=g, left=True)\n\ng.set_ylabel('-log10(p)')\ng.set_xlabel('')\ng.get_legend().set_title('')\nsns.move_legend(g, 'upper center', bbox_to_anchor=(0.4,0.975))\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[38], line 29\n     27 g.set_ylabel('-log10(p)')\n     28 g.set_xlabel('')\n---&gt; 29 g.get_legend().set_title('')\n     30 sns.move_legend(g, 'upper center', bbox_to_anchor=(0.4,0.975))\n\nAttributeError: 'NoneType' object has no attribute 'set_title'\n\n\n\n\n\n\n\n\n\n\n\n\nOld test\n\n# # Now we should test\n\n# from genominterv import proximity_test, interval_diff, jaccard_stat, bootstrap\n\n# #query = ech90\n# query = edges['round_spermatid_100kb_arms']\n# annot_hama = hama_edges\n# #annot_olive = baboon_dict['P.anubis']\n# b = 1_000\n\n# # Proximity test\n# non_ovl_query_hama = interval_diff(query, annot_hama)\n# #non_ovl_query_olive = interval_diff(query, annot_olive)\n\n# proximity_hama = proximity_test(non_ovl_query_hama, annot_hama, two_sided=True, samples=10_000)\n# #proximity_olive = proximity_test(non_ovl_query_olive, annot_olive, two_sided=True, samples=10_000)\n\n# # Jaccard index\n\n# @bootstrap(chromsizes, samples=b, smaller=False)\n# def jaccard_bootstrap(query, annot):\n#     return jaccard_stat(query, annot)\n\n# jaccard_hama = jaccard_bootstrap(query, annot_hama)\n# #jaccard_olive = jaccard_bootstrap(query, annot_olive)\n\n# print(f\"\"\"\n# Proximity test results:\n#     Hama: {proximity_hama}\n#  #   Olive: {proximity_olive}\n\n# Jaccard index results:\n#     Hama: {jaccard_hama}\n#   #  Olive: {jaccard_olive}\n# \"\"\")\n\n# # # Swap annot and query \n\n# # non_ovl_query_hama = interval_diff(annot_hama, query)\n# # non_ovl_query_olive = interval_diff(annot_olive, query)\n\n# # proximity_hama_flip = proximity_test(non_ovl_query_hama, query, two_sided=True, samples=b)\n# # proximity_olive_flip = proximity_test(non_ovl_query_olive, query, two_sided=True, samples=b)\n\n# # jaccard_hama_flip = jaccard_bootstrap(annot_hama, query)\n# # jaccard_olive_flip = jaccard_bootstrap(annot_olive, query)\n\n\n\n\n# Make a long dataframe\n\n# pd.DataFrame({\n#     'Group': ['P.hama', 'P.anubis'],\n#     #'Proximity Statistic': [proximity_hama.statistic, proximity_olive.statistic],\n#     'Proximity P-value': [proximity_hama.pvalue, proximity_olive.pvalue],\n#     #'Jaccard Index': [jaccard_hama[0], jaccard_olive[0]],\n#     'Jaccard P-value': [jaccard_hama[1], jaccard_olive[1]]\n# }).melt(id_vars='Group', var_name='Test', value_name='Value')\n\npd.DataFrame({\n    'Group': ['P.hama', 'P.anubis'],\n    #'Proximity Statistic': [proximity_hama.statistic, proximity_olive.statistic],\n    'Proximity P-value': [proximity_hama.pvalue, proximity_olive.pvalue],\n    #'Jaccard Index': [jaccard_hama[0], jaccard_olive[0]],\n    'Jaccard P-value': [jaccard_hama[1], jaccard_olive[1]],\n    # #'Proximity Statistic (flip)': [proximity_hama_flip.statistic, proximity_olive_flip.statistic],\n    # 'Proximity P-value (flip)': [proximity_hama_flip.pvalue, proximity_olive_flip.pvalue],\n    # #'Jaccard Index (flip)': [jaccard_hama_flip[0], jaccard_olive_flip[0]],\n    # 'Jaccard P-value (flip)': [jaccard_hama_flip[1], jaccard_olive_flip[1]],\n}).melt(id_vars='Group', var_name='Test', value_name='Value')\n\n\n\n\n\n\n\n\n\nGroup\nTest\nValue\n\n\n\n\n0\nP.hama\nProximity P-value\n0.0069\n\n\n1\nP.anubis\nProximity P-value\n0.0274\n\n\n2\nP.hama\nJaccard P-value\n0.2720\n\n\n3\nP.anubis\nJaccard P-value\n0.8250\n\n\n\n\n\n\n\n\n\nPlot the relative distances (proximities)\n\nech90.assign(start=ech90['start']-5000,\n             end  = ech90['end']+5000)\n\n\n\n\n\n\n\n\nchrom\nstart\nend\nlength\n\n\n\n\n0\nchrX\n19531773\n19641984\n100211\n\n\n1\nchrX\n20930188\n21051124\n110936\n\n\n2\nchrX\n36218142\n36427842\n199700\n\n\n3\nchrX\n37230935\n37637028\n396093\n\n\n4\nchrX\n49511522\n50019126\n497604\n\n\n5\nchrX\n50816385\n51449493\n623108\n\n\n6\nchrX\n53897995\n54111817\n203822\n\n\n7\nchrX\n62091538\n62298349\n196811\n\n\n8\nchrX\n70884995\n71154673\n259678\n\n\n9\nchrX\n71783766\n72149275\n355509\n\n\n10\nchrX\n74336598\n74640686\n294088\n\n\n11\nchrX\n96245950\n96344522\n88572\n\n\n12\nchrX\n108173096\n108564466\n381370\n\n\n13\nchrX\n111297881\n111601540\n293659\n\n\n14\nchrX\n124073238\n124182167\n98929\n\n\n15\nchrX\n126833587\n127249031\n405444\n\n\n16\nchrX\n128398780\n128706766\n297986\n\n\n17\nchrX\n129729920\n130039306\n299386\n\n\n18\nchrX\n150800639\n151219408\n408769\n\n\n\n\n\n\n\n\n# Size of each of the dataframes\n\nprint(f\"\"\"\nrs100_full: {rs100_dict['full'].shape[0]}\nrs100_edges: {rs100_dict['edges'].shape[0]}\nfb100_full: {fb100_dict['full'].shape[0]}\nfb100_edges: {fb100_dict['edges'].shape[0]}\nhama_dict: {hama_dict['full'].shape[0]}\nech_dict: {ech_dict['full'].shape[0]}\n\n\"\"\")\n\n\nrs100_full: 77\nrs100_edges: 96\nfb100_full: 59\nfb100_edges: 83\nhama_dict: 31\nech_dict: 19\n\n\n\n\n\nimport seaborn as sns\nfrom genominterv.remapping import remap_interval_data\n\nn = 1000\na = np.sort(np.random.randint(1, 10_000_000, size=n))\nannot = pd.DataFrame(dict(chrom='chrX', start=a, end=a+10))\nq = np.sort(np.random.randint(1, 10_000_000, size=n))\nquery = pd.DataFrame(dict(chrom='chrX', start=q, end=q+10))\ndf1 = remap_interval_data(query, annot, relative=True)\ndf1['mid'] = (df1.start + df1.end) / 2\ndf1['absmid'] = df1.mid.abs()\n\n# dummy data\na = np.sort(np.random.randint(1, 10_000_000, size=n))\nannot = pd.DataFrame(dict(chrom='chrX', start=a, end=a+10))\nq = a + np.random.randint(-1000, 1000, size=n)\nquery = pd.DataFrame(dict(chrom='chrX', start=q, end=q+10))\ndf2 = remap_interval_data(query, annot, relative=True)\ndf2['mid'] = (df2.start + df2.end) / 2\ndf2['absmid'] = df2.mid.abs()\n\n# Real data\nq1 = hama_dict['full']\na1 = rs100_dict['full']\ndf3 = remap_interval_data(q1, a1, relative=True)\ndf3['mid'] = (df3.start + df3.end) / 2\ndf3['absmid'] = df3.mid.abs()\n\nq2 = hama_dict['full']\na2 = fb100_dict['full']\ndf4 = remap_interval_data(q2, a2, relative=True)\ndf4['mid'] = (df4.start + df4.end) / 2\ndf4['absmid'] = df4.mid.abs()\n\nsns.histplot(df3, x='mid', bins=np.linspace(-0.5, 0.5, 20))\nsns.histplot(df4, x='mid', bins=np.linspace(-0.5, 0.5, 20))\n\n\n\n\n\n\n\n\n\nsns.histplot(df3, x='absmid', bins=np.linspace(0, 0.5, 20))\nsns.histplot(df4, x='absmid', bins=np.linspace(0, 0.5, 20))\n\n\n\n\n\n\n\n\n\ndf3['dist'] = 'uniform'\ndf4['dist'] = 'closer'\ndf = pd.concat([df3, df4])\nsns.barplot(df, y='absmid', x='dist', hue='dist')",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "notebooks/06_rec_genomicintervals.html#geneinfo",
    "href": "notebooks/06_rec_genomicintervals.html#geneinfo",
    "title": "E1 vs. ECH (recommended params)",
    "section": "Geneinfo",
    "text": "Geneinfo\nHow does the edges align with genes?\nThis first plot is just to figure out how to plot with gene_plot.\n\nimport geneinfo as gi\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\n\n\n# Use the proximity test results to plot the ECH90 regions and the compartment edges\n\nstart = full_intersect['start'][2]\nend = full_intersect['end'][5]\n\nrectangles = [Rectangle((start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.6) for start, end in zip(full_intersect['start'][2:6], full_intersect['end'][2:6])]\n\npc = PatchCollection(rectangles, match_original=True)\n\nax = gi.gene_plot('chrX', start-100_000, end+100_000, assembly='rheMac10')\nax.add_collection(pc)\n\n\n\n\n\n\n\n\n\nGet the geneinfo for all intersections between edges and ECH90\nAnd write to a csv file. If the file exists, read it with pandas.\n\n# Use get_genes_region\nimport os.path as op\nimport geneinfo as gi\nimport pandas as pd\nfrom os import makedirs as mkdir\n\ngenes_dir = '../results/rec_edge_genes/'\nif not op.exists(genes_dir):\n    mkdir(genes_dir)\n    \ngenes_file = op.join(genes_dir,'rs_edges_100kb_genes.csv')\n\nif not op.exists(genes_file):\n    genes = pd.concat(\n        full_intersect.apply(\n            lambda x: gi.get_genes_region_dataframe('chrX', x['start'], x['end'], assembly='rheMac10'), \n            axis =1\n            ).to_list(),\n        ignore_index=True\n    )\n    genes.to_csv(genes_file, index=False) \nelse: \n    genes = pd.read_csv(genes_file)\n\n\ngenes_list = genes['name'].unique().tolist()\ngenes_list\n\n['SH3KBP1',\n 'MIR7206',\n 'LANCL3',\n 'XK',\n 'CYBB',\n 'LOC696657',\n 'DYNLT3',\n 'PAGE4',\n 'USP27X',\n 'CLCN5',\n 'LOC114675180',\n 'MIR532',\n 'MIR188',\n 'MIR500A',\n 'MIR362',\n 'MIR501',\n 'MIR500B',\n 'MIR660',\n 'MIR502',\n 'AKAP4',\n 'CCNB3',\n 'LOC114675218',\n 'LOC695959',\n 'CENPVL3',\n 'FAM120C',\n 'WNK3',\n 'LOC114675302',\n 'ZC3H12B',\n 'LAS1L',\n 'MSN',\n 'ATRX',\n 'MAGT1',\n 'LOC114675151',\n 'COX7B',\n 'ATP7A',\n 'ALG13',\n 'LOC706958',\n 'TRPC5',\n 'ENOX2',\n 'RAP2C',\n 'LOC114675176',\n 'DKC1',\n 'LOC114675231',\n 'MPP1',\n 'SMIM9',\n 'F8',\n 'H2AFB3',\n 'FUNDC2',\n 'CMC4',\n 'MTCP1',\n 'BRCC3',\n 'LOC703257']\n\n\n\nimport geneinfo as gi\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\n\n\n# Use the proximity test results to plot the ECH90 regions and the compartment edges\n\nfor i in full_intersect.index:\n    start_idx = i\n    end_idx = i\n\n    start = full_intersect['start'][start_idx]\n    end = full_intersect['end'][end_idx]\n\n    rectangles = [Rectangle(\n        (start, 0.1), width=end-start, height=0.9, color='tab:green', linewidth=0, alpha=0.6) for start, end in zip(full_intersect['start'][start_idx:end_idx+1], full_intersect['end'][start_idx:end_idx+1])]\n\n    pc = PatchCollection(rectangles, match_original=True)\n\n    ax = gi.gene_plot('chrX', start-100_000, end+100_000, assembly='rheMac10', \n                    highlight=genes_list,\n                    despine=True,\n                    figsize=(5, 5),\n                    aspect=5,\n                    )\n    ax.add_collection(pc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat can I do with the list of genes on the edges?\n\nGO enrichment?\n\nmmul_x_genes = gi.get_genes_region_dataframe('chrX', 0, 155_000_000, assembly='rheMac10')\n\n\nmmul_x_genelist = mmul_x_genes['name'].unique().tolist()\n\n\ngene_list = genes['name'].unique().tolist()\ntaxid = 9544\ngi.email('sojernj@gmail.com')\n#gi.go_annotation_table(taxid=taxid)\n\n#gi.show_go_evidence_codes()\n\ngo_terms = gi.get_go_terms_for_genes(gene_list, taxid=taxid)\n\n\nlen(go_terms)\n#gene_list[:5]\n\n127\n\n\n\nresults = gi.go_enrichment(\n    # Use human taxid as a start\n    gene_list, \n    alpha=0.05,\n    terms=go_terms)\n\ngeneinfo_cache/go-basic.obo: fmt(1.2) rel(2024-10-27) 44,017 Terms; optional_attrs(def relationship)\n\n\nCould not map gene symbol \"MIR7206\" to ncbi id\nCould not map gene symbol \"LOC696657\" to ncbi id\nCould not map gene symbol \"LOC114675180\" to ncbi id\n\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:1050, in _cached_symbol2ncbi(symbols, taxid)\n   1049 try:    \n-&gt; 1050     return symbol2ncbi.loc[symbols].tolist() \n   1051 except KeyError:\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)\n   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)\n-&gt; 1191 return self._getitem_axis(maybe_callable, axis=axis)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1420, in _LocIndexer._getitem_axis(self, key, axis)\n   1418         raise ValueError(\"Cannot index with multidimensional key\")\n-&gt; 1420     return self._getitem_iterable(key, axis=axis)\n   1422 # nested tuple slicing\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1360, in _LocIndexer._getitem_iterable(self, key, axis)\n   1359 # A collection of keys\n-&gt; 1360 keyarr, indexer = self._get_listlike_indexer(key, axis)\n   1361 return self.obj._reindex_with_indexers(\n   1362     {axis: [keyarr, indexer]}, copy=True, allow_dups=True\n   1363 )\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1558, in _LocIndexer._get_listlike_indexer(self, key, axis)\n   1556 axis_name = self.obj._get_axis_name(axis)\n-&gt; 1558 keyarr, indexer = ax._get_indexer_strict(key, axis_name)\n   1560 return keyarr, indexer\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200, in Index._get_indexer_strict(self, key, axis_name)\n   6198     keyarr, indexer, new_indexer = self._reindex_non_unique(keyarr)\n-&gt; 6200 self._raise_if_missing(keyarr, indexer, axis_name)\n   6202 keyarr = self.take(indexer)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252, in Index._raise_if_missing(self, key, indexer, axis_name)\n   6251 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique())\n-&gt; 6252 raise KeyError(f\"{not_found} not in index\")\n\nKeyError: \"['MIR7206', 'LOC696657', 'LOC114675180', 'MIR532', 'MIR188', 'MIR500A', 'MIR362', 'MIR501', 'MIR500B', 'MIR660', 'MIR502', 'LOC114675218', 'LOC695959', 'LOC114675302', 'LOC114675151', 'LOC706958', 'LOC114675176', 'LOC114675231', 'H2AFB3', 'LOC703257'] not in index\"\n\nDuring handling of the above exception, another exception occurred:\n\nKeyError                                  Traceback (most recent call last)\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-&gt; 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'MIR532'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:1055, in _cached_symbol2ncbi(symbols, taxid)\n   1054 try:\n-&gt; 1055     geneids.append(symbol2ncbi.loc[symbol])\n   1056 except KeyError:\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)\n   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)\n-&gt; 1191 return self._getitem_axis(maybe_callable, axis=axis)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1431, in _LocIndexer._getitem_axis(self, key, axis)\n   1430 self._validate_key(key, axis)\n-&gt; 1431 return self._get_label(key, axis=axis)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexing.py:1381, in _LocIndexer._get_label(self, label, axis)\n   1379 def _get_label(self, label, axis: AxisInt):\n   1380     # GH#5567 this will fail if the label is not present in the axis.\n-&gt; 1381     return self.obj.xs(label, axis=axis)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/generic.py:4301, in NDFrame.xs(self, key, axis, level, drop_level)\n   4300 else:\n-&gt; 4301     loc = index.get_loc(key)\n   4303     if isinstance(loc, np.ndarray):\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)\n   3811         raise InvalidIndexError(key)\n-&gt; 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n\nKeyError: 'MIR532'\n\nDuring handling of the above exception, another exception occurred:\n\nHTTPError                                 Traceback (most recent call last)\nCell In[55], line 1\n----&gt; 1 results = gi.go_enrichment(\n      2     # Use human taxid as a start\n      3     gene_list, \n      4     alpha=0.05,\n      5     terms=go_terms)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:1780, in go_enrichment(gene_list, taxid, background_chrom, background_genes, terms, list_study_genes, alpha)\n   1777 GeneID2nt = background_genes.GENEID2NT\n   1779 if not all(type(x) is int for x in gene_list):\n-&gt; 1780     gene_list = _cached_symbol2ncbi(gene_list, taxid=taxid)\n   1782 goeaobj = GOEnrichmentStudyNS(\n   1783         GeneID2nt, # List of mouse protein-coding genes\n   1784         ns2assoc, # geneid/GO associations\n   (...)\n   1788         methods=['fdr_bh'],\n   1789         pvalcalc='fisher_scipy_stats') \n   1791 goea_results_all = goeaobj.run_study(gene_list)\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:1058, in _cached_symbol2ncbi(symbols, taxid)\n   1056 except KeyError:\n   1057     try:\n-&gt; 1058         ncbi_id = hgcn_symbol(symbol)\n   1059         if ncbi_id not in symbol2ncbi.index:\n   1060             print(ncbi_id, 'not in symbol2ncbi index')\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:256, in hgcn_symbol(name)\n    254     return [ensembl2symbol(ensembl_id(n)) for n in name]\n    255 else:\n--&gt; 256     return ensembl2symbol(ensembl_id(name))\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/geneinfo/__init__.py:227, in ensembl2symbol(ensembl_id)\n    225 r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n    226 if not r.ok:\n--&gt; 227     r.raise_for_status()\n    228 decoded = r.json()\n    229 symbols = [x['display_id'] for x in decoded if x['dbname'] == 'HGNC']\n\nFile ~/miniconda3/envs/hic/lib/python3.12/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   1019     http_error_msg = (\n   1020         f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n   1021     )\n   1023 if http_error_msg:\n-&gt; 1024     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: https://rest.ensembl.org/xrefs/id/%5B'ENSG00000207758'%5D",
    "crumbs": [
      "Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>E1 vs. ECH (recommended params)</span>"
    ]
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "master_workflow",
    "section": "",
    "text": "from gwf import *\nimport os\nimport os.path as op\nimport pandas as pd\nfrom pprintpp import pprint as pp\n\n#######################################\n#\n# `gwf` workflow for the full pipeline from downloading raw reads \n# to compartmentalization analysis. We are using `bwa mem` for mapping. \n# \n# How to run:\n# conda activate hic\n# gwf -f master_workflow.py status\n# \n# Workflow:\n#   1a  bwa_index        : Index the reference genome with `bwa index`\n#   1b  sam_index        : Index the fasta again with `samtools faidx`\n#   1c  download_reads   : Download raw reads from SRA\n#                         `sra-downloader` with SRR IDs (paired-end reads)\n#   2   bwa_map          : Map reads (PE) to the reference with `bwa mem`\n#   3   pair_sort        : Pair the merged alignments from mate-pair sequencing with `pairtools parse`,\n#                         then sort with `pairtools sort`\n#   4   dedup            : Deduplicate the sorted pairs with `pairtools dedup`\n#   5   make_pairs_cool  : Create a .cool file from the deduplicated pairs with `cooler cload pairs`\n#\n#######################################\n\n# Create a workflow object\ngwf = Workflow(defaults={'nodes': 1, 'queue':\"normal\", 'account':\"hic-spermatogenesis\"})\n\n#############################################\n############### Templates ###################\n#############################################\n\ndef download_reads(sra_downloader, srr_id, read_dir):\n    \"\"\"Download raw reads from SRA\"\"\"\n    inputs  = [sra_downloader]\n    outputs = [f\"{read_dir}/{srr_id}_1.fastq.gz\",\n               f\"{read_dir}/{srr_id}_2.fastq.gz\",\n               f\"{read_dir}/dl_{srr_id}.done\"]\n    options = {'cores':32, 'memory': \"4g\", 'walltime':\"06:00:00\"}\n    spec = f\"\"\"\nsingularity run {sra_downloader} {srr_id} --save-dir {read_dir} --cores 16 && \\\ntouch {read_dir}/dl_{srr_id}.done\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef bwa_index(ref_genome):\n    \"\"\"Template for indexing the reference genome with bwa\"\"\"\n    inputs  = [ref_genome]\n    outputs = [f\"{ref_genome}.amb\", \n               f\"{ref_genome}.ann\", \n               f\"{ref_genome}.bwt\", \n               f\"{ref_genome}.pac\", \n               f\"{ref_genome}.sa\"]\n    options = {'cores':1, 'memory': \"5g\", 'walltime':\"02:00:00\"}\n    spec = f'''\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nbwa index -p {ref_genome} -a bwtsw {ref_genome}\n'''\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef sam_index(ref_genome):\n    \"\"\"Creating a fasta index. `bwa mem` also needs a fasta index generated by samtools\"\"\"\n    inputs = [ref_genome]\n    outputs = [f\"{ref_genome}.fai\"]\n    options = {'cores':1, 'memory':\"5g\", 'walltime':\"00:20:00\"}\n    spec=f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nsamtools faidx {ref_genome}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef bwa_map(ref_genome, mate_1, mate_2, download_ok, out_bam):\n    \"\"\"\n    Template for mapping reads to a reference genome using `bwa` and `samtools`. \n    NB! Here, we map the mates together, as bwa states it is no problem for Hi-C reads. \n    \"\"\"\n    threads = 32\n    inputs = [f\"{ref_genome}.amb\", \n              f\"{ref_genome}.ann\", \n              f\"{ref_genome}.bwt\", \n              f\"{ref_genome}.pac\", \n              f\"{ref_genome}.sa\", \n              f\"{ref_genome}.fai\",\n              mate_1, mate_2,\n              download_ok]\n    outputs = [out_bam]\n    options = {'cores':threads, 'memory': \"32g\", 'walltime':\"24:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\nbwa mem -t {threads} -SP {ref_genome} {mate_1} {mate_2} &gt; {out_bam}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n# Updated version uses --walks-policy 5unique in stead of mask\ndef pair_sort_alignments(chromsizes, bam_merged, sorted_pairs):\n    \"\"\"Convert the paired-end alignments to .pairs with `pairtools parse`, then sort\"\"\"\n    inputs = [bam_merged]\n    outputs = [f\"{bam_merged}_parsed.stats\", \n               sorted_pairs]\n    options = {'cores':32, 'memory':\"16g\", 'walltime':\"08:00:00\"}\n    spec=f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools parse \\\n    -c {chromsizes} \\\n    --drop-sam --drop-seq \\\n    --output-stats {bam_merged}_parsed.stats \\\n    --add-columns mapq \\\n    --assembly rheMac10 \\\n    --walks-policy 5unique \\\n    {bam_merged} | \\\npairtools sort -o {sorted_pairs} \n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\ndef dedup(sorted_pairs, chromsizes):\n    \"\"\"Deduplicate the sorted pairs with `pairtools dedup`\"\"\"\n    pairs_prefix = sorted_pairs.split(\".sorted\")[0]\n    inputs = [sorted_pairs]\n    outputs = [f\"{pairs_prefix}.nodups.pairs.gz\",\n               f\"{pairs_prefix}.unmapped.pairs.gz\",\n               f\"{pairs_prefix}.dups.pairs.gz\",\n               f\"{pairs_prefix}.dedup.stats\",\n               f\"{pairs_prefix}.dedup.done\"]\n    options = {'cores':12, 'memory': \"16g\", 'walltime': \"06:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools dedup \\\n    --max-mismatch 3 \\\n    --mark-dups \\\n    --chunksize 100000 \\\n    --chrom-subset {chromsizes} \\\n    --output {pairs_prefix}.nodups.pairs.gz \\\n    --output-unmapped {pairs_prefix}.unmapped.pairs.gz \\\n    --output-stats {pairs_prefix}.dedup.stats \\\n    --output-dups {pairs_prefix}.dups.pairs.gz \\\n    {sorted_pairs} && \\\ntouch {pairs_prefix}.dedup.done\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n# Updated version uses pairtools select to filter out low quality reads\ndef make_pairs_cool(chromsizes, pairs, cool_out):\n    \"\"\"Create coolers from pairs with `cooler cload pairs`\"\"\"\n    base = os.path.basename(pairs).split(\".pairs.gz\")[0]\n    inputs = [pairs]\n    outputs = [cool_out]\n    options = {'cores':1, 'memory':\"4g\", 'walltime':\"03:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\npairtools select \"(mapq1&gt;=30) and (mapq2&gt;=30)\" {pairs} | \\\ncooler cload pairs \\\n    -c1 2 -p1 3 -c2 4 -p2 5 \\\n    --assembly rheMac10 \\\n    --chunksize 50000 \\\n    {chromsizes}:10000 \\\n    - \\\n    {cool_out}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n    \n# DRAFT: Not implemented as a target yet\ndef merge_zoomify_coolers(cooler_list, merged, mcool):\n    \"\"\"Merge a given list of coolers with `cooler merge`\"\"\"\n    inputs = [cooler_list]\n    outputs = [merged, mcool]\n    options = {'cores':8, 'memory':\"32g\", 'walltime':\"03:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\ncooler merge -c 50000000 {merged} {cooler_list} && \\\ncooler zoomify --nproc 8 \\\n    --resolutions 10000,50000,100000,500000 \\\n    -o {mcool} \\\n    {merged}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n# DRAFT: Not implemented as a target yet\ndef balance_cooler_default(cool_in, cool_out):\n    \"\"\"Balance a cooler with `cooler balance`\"\"\"\n    mcool = cool_in.split(\"::\")[0]\n    inputs = [mcool]\n    outputs = [cool_out]\n    options = {'cores':8, 'memory':\"32g\", 'walltime':\"03:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\ncooler balance -p 32 {cool_in} && \\\ntouch {cool_out}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n# DRAFT: Not implemented as a target yet\ndef balance_cooler_cis(cool_in, cool_out):\n    \"\"\"Balance a cooler with `cooler balance`\"\"\"\n    mcool = cool_in.split(\"::\")[0]\n    inputs = [mcool]\n    outputs = [cool_out]\n    options = {'cores':8, 'memory':\"32g\", 'walltime':\"03:00:00\"}\n    spec = f\"\"\"\nsource $(conda info --base)/etc/profile.d/conda.sh\nconda activate hic\ncooler balance -p 32 --cis-only --name cis_weights {cool_in} && \\\ntouch {cool_out}\n\"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n\n################################################\n# Set up the folder structure for the workflow #\n################################################   \n \n # Define our working dir\ndirname = op.dirname(__file__)\n\n# Define reference genome directory (relative to project/script dir)\nref_dir = \"data/links/ucsc_ref/\"\n\nref_genome = op.join(dirname, ref_dir, \"rheMac10.fa\")\nchromsizes = op.join(dirname, ref_dir, \"misc/rheMac10.chrom.sizes\")\nfiltered_chromsizes = op.join(dirname, ref_dir, \"misc/rheMac10.filtered.chrom.sizes\")\n\n\n# Locate the reference genome\nif not op.exists(ref_genome):\n    raise FileNotFoundError(f\"Reference genome not found: {ref_genome}\")\nelse:\n    #print(f\"Reference genome found at: \\n{ref_genome}\")\n    pass\n\n# Define the reads directory\nreads_dir = op.join(dirname, \"../../../data/macaque_raw/downloaded/\")\n\n# Define subdirs for tissue type, strip_whitespace and make lowercase\nsra_runtable = pd.read_csv(\"data/SraRunTable.txt\")\nreads_subdirs = set(sra_runtable[\"source_name\"])\n\n# Make a dict mapping the tissue type ['source_name'] to the SRR IDs ['Run']\ntissue_dict = {tissue: sra_runtable[sra_runtable[\"source_name\"]==tissue][\"Run\"].tolist() for tissue in reads_subdirs}\n\n# Define the output dirs for files\nbam_dir = op.join(dirname,\"steps/bwa/PE/bamfiles\")\npair_dir = op.join(dirname, \"steps/bwa/PE/pairs\")\ncool_dir = op.join(dirname, \"steps/bwa/PE/cool\")\n\n\n#### Updated version creates the new .pairs and .cool files under 'recPE' for recommended PE. --walks-policy 5unique, filter mapq &gt;= 30\nrec_pair_dir = op.join(dirname, \"steps/bwa/recPE/pairs\")\nrec_cool_dir = op.join(dirname, \"steps/bwa/recPE/cool\")\npair_dir = rec_pair_dir\ncool_dir = rec_cool_dir\n\n#############################################\n############### Targets #####################\n#############################################\n\nT1a = gwf.target_from_template(f\"bwa_index_{os.path.basename(ref_genome).split('.')[0]}\", \n                               bwa_index(ref_genome=ref_genome))\nT1b = gwf.target_from_template(f\"sam_index_{os.path.basename(ref_genome).split('.')[0]}\", \n                               sam_index(ref_genome=ref_genome))\n\n\nT5out = {} # initialize a dict to store the cool files (T5)\n\n# T1c target for each ID in the SRA runtable\nfor id in sra_runtable[\"Run\"]:\n    \n    # Do some stuff before downloading the reads\n    # Get the tissue type for the ID, and assign a subdirectory for the reads\n    sub_dir = None\n    for cell_type, ids in tissue_dict.items():\n        if id in ids:\n            sub_dir = cell_type.lower().replace(\" \", \"_\")\n            break\n    if sub_dir is None:\n        raise ValueError(f\"ID {id} not found in any tissue type\")\n\n    fastq_dir = op.join(reads_dir, sub_dir)\n\n    # Create subdirs if they don't exist\n    if not op.exists(fastq_dir):\n        os.makedirs(fastq_dir)\n\n    # T1c: Download SRA ID\n    T1c = gwf.target_from_template(f\"dl_{id}\",\n                                  download_reads(\n                                        sra_downloader = \"../../../data/macaque_raw/sra-downloader_latest.sif\",\n                                        srr_id = id,\n                                        read_dir = fastq_dir\n                                    ))\n    \n    # T2: Map the reads to the reference genome\n    bam_wdir = op.join(bam_dir, sub_dir)\n    out_bam = op.join(bam_wdir, f\"{id}.PE.bam\")\n\n    if not op.exists(bam_wdir):\n        os.makedirs(bam_wdir)\n\n    T2 = gwf.target_from_template(f\"bwa_map_{id}\", \n                                  bwa_map(ref_genome=ref_genome, \n                                          mate_1=T1c.outputs[0], mate_2=T1c.outputs[1], \n                                          download_ok=T1c.outputs[2],\n                                          out_bam=out_bam))\n    \n    # T3: pair and sort the alignments\n    pair_subdir = op.join(pair_dir, sub_dir)\n    sorted_pairs = op.join(pair_subdir, f\"{id}.sorted.pairs.gz\")\n\n    if not op.exists(pair_subdir):\n        os.makedirs(pair_subdir)\n\n    T3 = gwf.target_from_template(f\"parse_{id}\",\n                                    pair_sort_alignments(chromsizes=chromsizes, \n                                                         bam_merged=T2.outputs[0], \n                                                         sorted_pairs=sorted_pairs))\n    \n    # T4: Deduplicate the sorted pairs\n    # Dedup dir is the same as pair dir\n    # NB we are using the reduced chromsizes file (only 'real' chromosomes)\n    T4 = gwf.target_from_template(f\"dedup_{id}\",\n                                    dedup(sorted_pairs=T3.outputs[1],\n                                            chromsizes=filtered_chromsizes))\n    #pp(T4.outputs)\n\n    # T5: Create a .cool file from the deduplicated pairs\n    cool_subdir = op.join(cool_dir, sub_dir)\n\n    if not op.exists(cool_subdir):\n        os.makedirs(cool_subdir)\n\n    T4outpairs = [x for x in T4.outputs if x.endswith(\".pairs.gz\")]\n    if sub_dir not in T5out:\n        T5out[sub_dir] = []\n\n    for T4out in T4outpairs:\n        # Filter to be removed if we want to\n        # Only make a cool file of the 'nodups' pairs\n        if 'nodups' not in T4out:\n            continue\n\n        cool_name = f\"{id}.{T4out.split('.')[1]}\"\n        cool_file = os.path.join(cool_subdir, f\"{cool_name}.10000.cool\")\n\n        T5 = gwf.target_from_template(f\"coolify_{cool_name}\",\n                                        make_pairs_cool(filtered_chromsizes, pairs=T4out, cool_out=cool_file))\n        T5out[sub_dir].append(T5.outputs[0])\n        \n#pp(T5out)\n\nfor subdir,cool_list in T5out.items():\n    print(f'merging {subdir} coolers:')\n    T6 = gwf.target_from_template(f\"merge_{subdir}\",\n                                    merge_zoomify_coolers(cooler_list=cool_list, \n                                                          merged=op.join(cool_dir, subdir, f\"{subdir}.merged.cool\"), \n                                                          mcool=op.join(cool_dir, subdir, f\"{subdir}.merged.mcool\")))",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>master_workflow</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html",
    "href": "reports/thoughts.html",
    "title": "Thoughts and Prayers",
    "section": "",
    "text": "Notes on methods\nHere goes my thoughts and frustrations about the tools, the results, or the project in general.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html#notes-on-methods",
    "href": "reports/thoughts.html#notes-on-methods",
    "title": "Thoughts and Prayers",
    "section": "",
    "text": "(Wang et al. 2019) uses a sliding window approach (Dixon et al. 2015) to calculate the obs/exp matrices for the PCA. I will try that next, and work within the cooler/cooltools framework which has a Python API and is thus more suitable to run in Jupyter Notebooks.\nHiCExplorer use a genome-wide contact-distance-based normalization method (dist_norm) to generate obs/exp matrices for PCA (similar to (aiden2009comprehensivemappinglongrange?)) that may introduce biases. I don’t know why, but it looks more like (Wang et al. 2019) when subtracting the running average [triangular windows, Kasper did this] from the computed PCs.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html#notes-on-quarto",
    "href": "reports/thoughts.html#notes-on-quarto",
    "title": "Thoughts and Prayers",
    "section": "Notes on Quarto",
    "text": "Notes on Quarto\nI feel like i have the Markdown/Quarto thing under control, which is pretty nice. It is going to be really cool when actually starting to write the manus (I think).",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html#notes-on-hicexplorer",
    "href": "reports/thoughts.html#notes-on-hicexplorer",
    "title": "Thoughts and Prayers",
    "section": "Notes on HiCExplorer",
    "text": "Notes on HiCExplorer\nIt feels very old school and unnecessary that I can’t just output the HiCExplorer commands [plots] to the Jupyter display. I have to save the plots to .pngs, which is flooding my figures directory. I should probably clean it up.\nI have created plots to mimic the (Wang et al. 2019) for the chr12 as well as chrX. They don’t compare very well with Wang2019, and the both PC1 and PC2 plot looks like they’re highly biased (only intersects 0 one time). PC3 looks more reasonable, but I don’t know if it is reasonable at all to use the 3rd PC in stead of the 1st. I guess it means that the compartmentalization is not the most variable feature, and there are some biases that we have to get rid of. That, or the X chromosome is divided only into two compartments in fibroblasts (unlikely).\n\n\n\n\n\n\nThe X chromosome in 50kb bins and the first 3 PCs below. Made with HicExplorer.\n\n\n\n\n\n\n\n\n\n\n\nThe X chromosome in 100kb bins and the first 3 PCs below. Made with HicExplorer.\n\n\n\n\n\n\nPlotting .cool files with h5py and pyBigWig\nIt does not work as I want. To read both the matrix and PC components, it requires an abnormal amount of memory (I don’t think it is strictly necessary to load 75 Gb of data into memory to make a 5x8” plot). However, HicExplorer advise against merging bins after correction and normalization, but I just don’t get that. I see no reason it could mess up the correction. Jupyter Display and, ultimately, my screen resolution makes that binning, so It would be completely fine to just bin the matrices after the fact.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html#notes-on-open2c-framework",
    "href": "reports/thoughts.html#notes-on-open2c-framework",
    "title": "Thoughts and Prayers",
    "section": "Notes on Open2C framework",
    "text": "Notes on Open2C framework\n\npairtools\nI’m considering to just map the reads again with bwa, mates together to create a pairs file in the first place. Alternatively, I will use samtools sort | samtools fixmate to convert them back into a paired-end alignment for inputting into cooler. Their own recommendation is to map with bwa mem with paired-end mates.\n\nEnded up mapping them again\n\n\n\ncooler\nI’ve decided that this is a much better tool than HiCExplorer, the overall experience is way better. The Python API makes it optimal for Jupyter Notebooks, in stead of doing shell escapes in every cell. It can plot 10kb bins without any issue.\n\nUpdate: 08-10-2024\nIt took more than a week to get a valid .pairs file and to get that processed into a .cool matrix. But now it seems to work pretty smoothly, and I believe it is more customizable. The pairs are split up into .nodups, .dups, and .unmapped pairs, meaning all the reads are still saved. A dedup.stats is also generated and visualized with MultiQC.\nI made these plots of both uncorrected and corrected (ICE) matrices (made with cooler)\n\n\n\n\n\n\nRaw matrix. Left: All chromosomes plotted in 100kb bins. Middle: chrX in 100kb bins. Right: chrX:60Mb-70Mb in 50 kb bins\n\n\n\n\n\n\n\n\n\n\n\nCorrected matrix. Left: All chromosomes plotted in 100kb bins. Middle: chrX in 100kb bins. Right: chrX:60Mb-70Mb in 50 kb bins\n\n\n\n\n\nNeither of them really resembles the ones from (Wang et al. 2019), but we have some confidence in our method still. Next step is to do the default compartmentalization analysis from cooler as well.\n\n\nUpdate 10-10-2024\nI plotted the weights variable below the interaction maps. Maybe it will be useful.\n\n\n\n\n\n\nRep1 interaction matrix with weights visualized. Top: raw counts. Bottom: corrected frequencies. Left: whole chrX. Right: chrX60:70Mb\n\n\n\n\n\nAlso, we can plot the coverage divided into cis and all contacts, as well as the cis/total coverage ratio:\n\n\n\n\n\n\nRep1 chrX interaction matrix with coverage for cis and total as well as cis/total coverage ratio.\n\n\n\n\n\nFinally, before moving on, we can do some visual improvements to the plot (it does not alter the data), with adaptive coarsegraining and interpolating the matrix. It looks pretty cool:\n\n\n\n\n\n\nNormal, smoothed, and interpolated views of the interaction matrix. Functions provided by cooltools.\n\n\n\n\n\n\n\nCompartments\nFinally, I managed to map the compartments with cooler. First, the depencies are imported: numpy, pandas, cooler, cooltools, bioframe, and some more plot-specific packages.\n\nLoad the cooler at a selected binsize.\nLoad the reference genome\n(bioframe.load_fasta())\nCalculate the GC% in each of the bins\n(bioframe.frac_gc())\n\nNB I found some missing values, but only 1 on the X. I don’t know why.\n\nCalculate the cis eigenvectors to each bin (cooltools.eigs_cis()), where the GC coverage is used as a ‘phasing’ track.\nIt is saved as a E1-track, with [['chrom','start','end','E1']]\nPlot with matplotlib and submodules. Optionally, we can mark the E1 transitions on the matrix. Here, I removed the horisontal lines.\n\n\n\n\n\n\n\nchrX interaction matrix with E1 eigenvector values.\n\n\n\n\n\nA note from the authors of cooltools is that we always have to inspect the E1 values to see how well it captures the compartments in the matrix. Here, it actually doesn’t do very well, So i’m not sure what went wrong. The E1 values seem to have a lot of sign changes, that are not visible in the plot. Maybe it looks better with 500kb resolution.\nHere, comparing to the Wang paper:\n\n\n\nWang2019 PC1 on chrX\n\n\n\n\n\n\n\n\n\n\n100kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.\n\n\n\n\n\nI’m very positive about the results. The compartments do not match completely, but we have to take into account another mapping algorithm and a new (updated) reference genome rheMac10, where more than 99% of the segmentation is removed, compared to rheMac2. It is evident in the (Wang et al. 2019) PC1 plot, that a chunk in the middle is missing, possibly due to unmmapped reads. In any case, here is higher-resolution of PC compartments, as more Hi-C contacts can be mapped.\n\n\nCompartments 500kb resolution looks smoother\nI made the same plot as above, but using a 500kb bin size in stead. It looks more smooth, but it is not obvious if we a removing valid information or noise. It looks more like it captures only the visible compartments in the matrix, whcih is good\n\n\n\n\n\n\n\n\n\nFigure 9.1: chrX interaction matrix with E1 eigenvector values in 500kb resolution. The sign change of the E1 is overlayed as thin black lines, making it more easily interpretable. We should qualitatively determine how well the E1 values capture the plaid pattern in the matrix.\n\n\n\n\n\n\nOr the full size E1 plot:\n\n\n\n\n\n\n\n\n\nFigure 9.2: 500kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.\n\n\n\n\n\n\nTo ease the eye, here are the 100kb E1 and 500kb E1 plots next to each other:\n500kb resolution:\n\n\n\n\n\n\n\n\n\nFigure 9.3: 500kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.\n\n\n\n\n\n\n100kb resolution\n\n\n\n\n\n\n100kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.\n\n\n\n\n\n\n\n\nCompartments on all cell types (By merging all samples from each type)\nNow it is time for the analysis of the other cell types as well. Here, we trust (Wang et al. 2019) when they state that their compartments were highly reproducible between replicates.\nThus, we merge all samples from each cell type, leaving us with 5 coolers at 10 kb bins. We then zoomify the coolers to include the resolutions 50, 100, and 500kb binned data as well.\nWe continue with the analysis with the 500kb binned data, as it runs faster, uses less memory, while still being sufficient for chromosome-wide analysis.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "reports/thoughts.html#calculating-the-eigenvectors-again",
    "href": "reports/thoughts.html#calculating-the-eigenvectors-again",
    "title": "Thoughts and Prayers",
    "section": "Calculating the eigenvectors again",
    "text": "Calculating the eigenvectors again\nInitially, the results were not as expected, as the E1 did not reflect the plaid pattern from the matrix from all cell types. In stead, it showed two compartments.\nAs stated in (aiden2009comprehensivemappinglongrange?) and cooltools documentation, the E1 occasionally does not reflect the plaid pattern from the interaction matrix, but rather a two-compartment chromosome. That happens when the difference in interaction frequencies differ more between the chromosome arms than it does within the arms. To mitigate such cases (or get the correct compartments), we can either use the next eigenvector, or (a better option, in our opinion) calculate the eigenvectors from a chromosome partitioned in the two arms (separated by the centromere).\nI determined the region of the centromere from the NCBI browser, in a region from 58-61Mb that have no gene annotations. That region corresponds well with NaN values in the calculated eigenvector (values removed because of low-count bins), as seen below:\n\n\n\n\n\n\nHistogram of NaN values in the E1 eigenvector for each cell type.\n\n\n\n\n\nThen, the E1 for each cell type was plotted and looks like we have succesfully reproduced the A/B compartments from (Wang et al. 2019). Also, I noticed after all this, that they also partition the chromosomes at the centromere. The more you know…\n\n\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution. Left: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.\n\n\n\n\n\nFurthermoere, we wanted to see if we could apply the same smoothing as they did: They calculate the obs/exp matrix on a smoothed 100kb matrix: they slide a 400kb window with a step size of 100kb, summing the values.\nIt turned out to be practically very hard to do in the Open2c ecosystem, so I decided to apply the smoothing directly on the calculated E1 values.\n\n\n\n\n\n\nE1 eigenvector values for all merged samples at 100kb resolution. Left: Chromosomes (not restricted) Middle: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.Values are smoothed with a sliding window of 5 bins, step size 1 bin.\n\n\n\n\n\nNow we will do some planning, tidying, and writing before continuing the analysis.\n\n\n\n\nDixon, Jesse R., Inkyung Jung, Siddarth Selvaraj, Yin Shen, Jessica E. Antosiewicz-Bourget, Ah Young Lee, Zhen Ye, et al. 2015. “Chromatin Architecture Reorganization During Stem Cell Differentiation.” Nature 518 (7539): 331–36. https://doi.org/10.1038/nature14222.\n\n\nWang, Yao, Hanben Wang, Yu Zhang, Zhenhai Du, Wei Si, Suixing Fan, Dongdong Qin, et al. 2019. “Reprogramming of Meiotic Chromatin Architecture During Spermatogenesis.” Molecular Cell 73 (3): 547–561.e6. https://doi.org/10.1016/j.molcel.2018.11.019.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Thoughts and Prayers</span>"
    ]
  },
  {
    "objectID": "results/Readme.html",
    "href": "results/Readme.html",
    "title": "Result files",
    "section": "",
    "text": "Quality control\nhicBuildMatrix was used to generate the matrices for the Hi-C data, doing some quality control in the process. The quality control results are available as a html file in each folder.\nTo preview the html files, prepend the following to the URL of the hicQC.html in each folder: https://html-preview.github.io/?url=\nOr click the links below:",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Result files</span>"
    ]
  },
  {
    "objectID": "results/Readme.html#quality-control",
    "href": "results/Readme.html#quality-control",
    "title": "Result files",
    "section": "",
    "text": "Preview sample SRR6502335 QC results\n\n\n\nName\nCount\nPercent\n\n\n\n\nSequenced reads\n244,003,806\n100\n\n\nMappable, highQ+uniq\n164,715,495\n67.5\n\n\nHi-C contacts\n110,459,727\n45.27\n\n\nInter chromosomal\n28,350,411\n25.67\n\n\nIntra short\n14,384,188\n13.02\n\n\nIntra long\n67,725,128\n61.31\n\n\n\n\n\nPreview sample SRR6502336 QC results\n\n\n\nName\nCount\nPercent\n\n\n\n\nSequenced reads\n217,066,567\n100\n\n\nMappable, highQ+uniq\n147,553,720\n68\n\n\nHi-C contacts\n94,317,987\n43.45\n\n\nInter chromosomal\n24,058,490\n25.51\n\n\nIntra short\n12,514,652\n13.27\n\n\nIntra long\n57,744,845\n61.22\n\n\n\n\n\nPreview sample SRR6502337 QC results\n\n\n\nName\nCount\nPercent\n\n\n\n\nSequenced reads\n175,897,321\n100\n\n\nMappable, highQ+uniq\n117,483,977\n66.79\n\n\nHi-C contacts\n79,573,279\n45.24\n\n\nInter chromosomal\n22,500,348\n28.28\n\n\nIntra short\n9,800,706\n12.32\n\n\nIntra long\n47,272,225\n59.41\n\n\n\n\n\nPreview sample SRR6502338 QC results\n\n\n\nName\nCount\nPercent\n\n\n\n\nSequenced reads\n174,596,497\n100\n\n\nMappable, highQ+uniq\n119,036,178\n68.18\n\n\nHi-C contacts\n84,296,486\n48.28\n\n\nInter chromosomal\n23,802,080\n28.24\n\n\nIntra short\n10,189,916\n12.09\n\n\nIntra long\n50,304,490\n59.68\n\n\n\n\n\nPreview sample SRR6502339 QC results\n\n\n\nName\nCount\nPercent\n\n\n\n\nSequenced reads\n96,286,472\n100\n\n\nMappable, highQ+uniq\n65,355,035\n67.88\n\n\nHi-C contacts\n41,072,908\n42.66\n\n\nInter chromosomal\n11,586,845\n28.21\n\n\nIntra short\n5,180,947\n12.61\n\n\nIntra long\n24,305,116\n59.18\n\n\n\n\n\nGuidelines from HiCExplorer:\nThe hicBuildMatrix command generates a bam file and a matrix file for the Hi-C data. The bam file contains only the valid Hi-C read pairs, which can be used to assess the quality of the Hi-C library on the genome browser. A good Hi-C library should have an abundance of reads near the restriction fragment sites.\nIn the QC folder, an html file is saved with plots that provide useful information for the quality control of the Hi-C sample. This includes metrics such as the number of valid pairs, duplicated pairs, and self-ligations. Typically, only 25%-40% of the reads are considered valid and used to build the Hi-C matrix, as reads on repetitive regions are discarded.\nOne important quality control measurement is the interchromosomal fraction of reads, which indirectly measures random Hi-C contacts. A good Hi-C library should have less than 10% interchromosomal contacts. The hicQC module can be used to compare the quality control measures across different samples.",
    "crumbs": [
      "Reports",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Result files</span>"
    ]
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "",
    "text": "Problem 1: Chromatin Compartments",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#section",
    "href": "slides/index.html#section",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "",
    "text": "Ok, very briefly: The DNA is organized into higher-order structures by the histones/nucleosomes. This illustration is a nice view of the higher-order structures of DNA inside the nucleus; Nucleosome, Chromatin fiber, Chromatin loops, Chromatin domains, and Chromatin compartments",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#d-organization-of-chromatin-into-compartments",
    "href": "slides/index.html#d-organization-of-chromatin-into-compartments",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "3D organization of Chromatin into Compartments",
    "text": "3D organization of Chromatin into Compartments\n\n\n\nData\n\nSpecial library construction\nSequencing (Hi-C)\n\n\n\n\n\n\n\nTo infer this 3-dimensional structure, we need a specialized sequence library, which is made by cross-linking close-proximity DNA (at a specific site), digestion, proximity-ligation, amplification. Now the amplified fragments are pairs of sequences that are close in physical space, but not in necessarily in bp position. All this lab-work is done by others, and now it’s our turn.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#hi-c-pipeline",
    "href": "slides/index.html#hi-c-pipeline",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Hi-C pipeline",
    "text": "Hi-C pipeline\n\n\n\n\nThe plaid pattern is reflected by the E1\n\n\n\n\n\n\n\n\n\n\nFigure 12.1: chrX interaction matrix with E1 eigenvector values in 500kb resolution. The sign change of the E1 is overlayed as thin black lines, making it more easily interpretable. We should qualitatively determine how well the E1 values capture the plaid pattern in the matrix.\n\n\n\n\n\n\n\n\n\n\nWhen the pairs are sequenced, we map (align) them back onto the reference genome (to get a coordinate for each of the pairs). After filtering out poorly mapped and unmapped reads and matrix-balancing, we construct a heat map at some chosen resolution. We should see plaid patterns like these, which indicate that regions of the genome interact more closely than others, marked by a sharp increase in interaction frequency.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#hi-c-pipeline-1",
    "href": "slides/index.html#hi-c-pipeline-1",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Hi-C pipeline",
    "text": "Hi-C pipeline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12.2: chrX interaction matrix with E1 eigenvector values in 500kb resolution. The sign change of the E1 is overlayed as thin black lines, making it more easily interpretable. We should qualitatively determine how well the E1 values capture the plaid pattern in the matrix.\n\n\n\n\n\n\n\n\n\n\nNow, it has been shown that the first eigenvector (the vector of PC1) can well predict these compartments, and we label them ‘A’ for active and ‘B’ for inactive compartments. We use (binned) GC content to phase or calibrate the sign. It is convention to eyeball how well we capture the plaid pattern as this point.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#reconstructing-figures-from-wang2019reprogrammingmeioticchromatin",
    "href": "slides/index.html#reconstructing-figures-from-wang2019reprogrammingmeioticchromatin",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Reconstructing figures from (Wang et al. 2019)",
    "text": "Reconstructing figures from (Wang et al. 2019)\n\n\n(Wang et al. 2019) identified compartments in rhesus macaque in five different stages of spermatogenesis:\n\nfibroblast, spermatogonia, pachytene spermatocyte, round spermatids, and sperm\n\nThe edges of some compartments look suspiciously close to some of the regions of weirdly selected genes of papio anubis (olive baboons)\n\n\n\n\n\n\n\nWang2019 PC1 on chrX\n\n\n\n\n\n\n\n\n\n\n\n\n100kb binned E1 eigenvector values for chrX. Freshly calculated from the cooler file.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#reconstructing-figures-from-wang2019reprogrammingmeioticchromatin-1",
    "href": "slides/index.html#reconstructing-figures-from-wang2019reprogrammingmeioticchromatin-1",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Reconstructing figures from (Wang et al. 2019)",
    "text": "Reconstructing figures from (Wang et al. 2019)\n\n(Wang et al. 2019) identified compartments in rhesus macaque in five different stages of spermatogenesis:\n\nfibroblast, spermatogonia, pachytene spermatocyte, round spermatids, and sperm\n\nThe edges of some compartments look suspiciously close to some of the regions of weirdly selected genes of papio anubis (olive baboons)\n\n\n\n\n\n\n\nThe initial results were good for fibroblasts, but they were not so good for the rest of the cell types (next slide)",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#partition-the-genome",
    "href": "slides/index.html#partition-the-genome",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Partition the genome",
    "text": "Partition the genome\n\n\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution. Left: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#partition-the-genome-and-smooth",
    "href": "slides/index.html#partition-the-genome-and-smooth",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Partition the genome and smooth",
    "text": "Partition the genome and smooth\n\n\n\n\n\n\nE1 eigenvector values for all merged samples at 100kb resolution. Left: Chromosomes (not restricted) Middle: Chromosome-arm restricted E1. Right: 10Mb window restricted E1.Values are smoothed with a sliding window of 5 bins, step size 1 bin.\n\n\n\n\n\n\nIt seems it has a big effect how we partition the genome when calculating the E1. What it actually means (biologically), I don’t know. Do we remove noise or actual information?",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#check-with-the-matrix",
    "href": "slides/index.html#check-with-the-matrix",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Check with the matrix",
    "text": "Check with the matrix\n\n\n\nAs stated, we have to eyeball how well the E1 captures the plaid pattern\nHow does it look?\n\n\n\n\n\n\n\n\nE1 eigenvector values for all merged samples at 500kb resolution for round spermatid, as well as the interaction matrix. E1 was restricted to top: Full-chromosome, middle: Chromosome-arms, bottom: 10Mb window.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#what-regions",
    "href": "slides/index.html#what-regions",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "What regions",
    "text": "What regions\n\n\nSome genes behave weirdly during spermatogenesis\nWhy are they selected (seemingly) against fitness?",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#macaque-vs-baboon-vs-human",
    "href": "slides/index.html#macaque-vs-baboon-vs-human",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "Macaque vs Baboon vs human",
    "text": "Macaque vs Baboon vs human\n\n\nDo they correlate?\nDo we have to work on sperm samples (laborious - hard to get data)",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "slides/index.html#references",
    "href": "slides/index.html#references",
    "title": "Project Progress Day: Msc. Project 2024",
    "section": "References",
    "text": "References\n\n\n\n\nWang, Yao, Hanben Wang, Yu Zhang, Zhenhai Du, Wei Si, Suixing Fan, Dongdong Qin, et al. 2019. “Reprogramming of Meiotic Chromatin Architecture During Spermatogenesis.” Molecular Cell 73 (3): 547–561.e6. https://doi.org/10.1016/j.molcel.2018.11.019.",
    "crumbs": [
      "Slides",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Project Progress Day: Msc. Project 2024</span>"
    ]
  },
  {
    "objectID": "thesis/index.html",
    "href": "thesis/index.html",
    "title": "Chromatin Compartments and Selection on X",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#sexual-reproduction-and-sex-chromosomes",
    "href": "thesis/index.html#sexual-reproduction-and-sex-chromosomes",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Sexual Reproduction and Sex Chromosomes",
    "text": "Sexual Reproduction and Sex Chromosomes\nThe production of gametes in a sexually reproducing organism is a highly complex process that involves numeruous elements. Spermatogenesis, the process of forming male gametes, involves four stages of differentiation from a germ cell through spermatogonia, pachytene spermatocyte, and round spermatids to spermatozoa, or sperm (Wang et al. 2019), and it is the very basis of male reproduction. The specialized cell division of meiosis neatly handles the pairing, recombination, and segregation of homologous chromosomes, thereby ensuring proper genetic distribution. Deeply understanding the steps of molecular steps of reproduction and how our genetic material is inherited is essential in biology, bringing insight to areas such as speciation, population diversity, and (male) infertility.\nSex chromosomes behave differently than autosomes for several reasons. One reason is hemizygosity, where there is only one copy of a chromosome. The Y chromosome exist only in males, and (generally) never more than one copy is in the same individual. The copmlexity increases when we tend to the X chromosome, which exist both alone (in males) and as two copies (in females). This skewed ratio means that X chromosomes exist \\(2/3\\) of the time in females and only 1/3 of the time in males, and it is more exposed in males as there is no other copy to take over loss of function. It is also the underlying reasoning for Haldane’s rule (Haldane 1922), postulating that the heterogametic sex (XY, ZW) is the first to dissapear or have severely lowered fitness (e.g. sterility) when crossing different species. Even today, a hundred years later, there is only hypotheses as to why this is observed, including Y-incompatibility (Y has to be compatible to X or autosomes), dosage compensation (hybridisation deregulates crucial dosage compensation in heterogametes), dominance (recessive genes causes sterility), faster-male (male reproductive genes diverge faster than female), faster-X (X-linked loci diverge faster than autosomal ones), and meiotic drive (discrepancy between drivers and surpressors on sex chromosomes leads to sterility) (Cowell 2023). Additionally, while it appears to be the same phenomenon across multiple taxa (even kingdoms), it has received different explanations, and consensus for different species are not the same. Often times even, several of the listed explanations are described to be acting in collaboration (Lindholm et al. 2016). The complexity of selection on the X chromosome therefore still an area of active investigation, and several studies infers selective strong selection on the X chromosomes across primates, as discussed in the following.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#gene-drive-and-selfishness",
    "href": "thesis/index.html#gene-drive-and-selfishness",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Gene Drive and Selfishness",
    "text": "Gene Drive and Selfishness\nGene drive occur when a particular collection of genes is propagated through a population by increasing the probability of transmitting the genes to the offspring from random (Mendelian) inheritance, resulting in a biased gene transmission against its alternative (referred to as transmission advantage). Two categories of gene drivers exist (Bravo Núñez, Nuckolls, and Zanders 2018); class one drivers affect chromosome segregation in meiosis, and killer meiotic drivers will sabotage meiotic product that have not inherited the driving allele (Bravo Núñez, Nuckolls, and Zanders 2018). This happens regardless of the fitness effects of the developed organism, and is there often a factor offsetting classical selection. Even though the implications of such systems are potentially detrimental, they are notoriously difficult to detect. A circumstance contributing to the difficulty is that most genetic experiments are done in homozygotes. Bravo Núñez, Nuckolls, and Zanders (2018) states that the general choice of experimental system may have biased our understanding of sexual reproduction. A key point is; meiotic drivers can only be observed in heterozygotes, where a genetic driver has a competitor.\nIf an autosomal driver reaches fixation, it no longer has a target to act against, and consequently the driving phenotype will not be observed (Bravo Núñez, Nuckolls, and Zanders 2018). Over time, as there is neither selfish nor selective pressure to maintain the drive mechanism of a fixed driver, the mechanism will decay as it accumulates inactivating mutations. As a result, genetic drivers are said to be transient (Bravo Núñez, Nuckolls, and Zanders 2018) on an evolutionary timescale, unless it is linked to another positively selected allele (Jaenike 2001). Interestingly, gene drive is much more well-documented on sex chromosomes than for autosomes. Possibly because the sex chromosome meiotic drive inherently causes a skewed sex ratio, more notably raising a flag for further analysis. The consequences of sex chromosome drive and skewed sex ratio can be widespread. A fully driving gene on X can to lead to the extinction of the population that fixes the allele (Jaenike 2001), as only one (fertile) offspring sex will be produced. Therefore, sex chromosome drivers usually exist in equilibrium with a supressor. When a population becomes female-biased, autosomal suppressors will be favored with a process termed Fisher’s sex ratio selection (Lindholm et al. 2016.)",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#selection-on-x",
    "href": "thesis/index.html#selection-on-x",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Selection on X",
    "text": "Selection on X\nAs described, the sex chromosomes are under intense selective pressures. As a result, they have greatly reduced recombination rates comparing to the autosomal background (Dutheil et al. 2015) (especially between X and Y) and are less diverse than expected under neutral evolution (Skov et al. 2023). A driving element on X may target a region on Y, mitigating the risk of self-destruction and increasing its frequency at the same time. However as it induces a skewed sex-ratio by limiting the number of functioning Y-bearing spermatozoa, the selection on Y to counter this effect is strong, engaging an evolutionary arms race between driving allele and its supressor, potentially explaining stable Y chromosome polymorphisms (Jaenike 2001). However, the Y chromosome only exist in the male population and a supressor on Y has only limited effect on the X chromosome on a population-scale compared to its autosomal cousins, which consequently often harbours supressors of X-drive, as they are passed down to more offspring than the Y chromosome. The fight between a driver and a supressor in their coevolution is linked to the chromosomal architecture, as they have been shown to be protected by low-recombining regions or chromosomal inversions, and to be mediating the evolution of karyotype (Lindholm et al. 2016). Thus, the structural features of a chromosome not only shield genetic drivers but influence the patterns of synteny, which, in turn, is shaped by both selection and genomic constraints.\nSynteny, the conservation of the order of genes along a chromosome, can be used to infer many things about a genome, an example being ancestral relationships between species. In the assembly of a new reference genome for baboon, Panubis1.0 (Batra et al. 2020), the high level of synteny between their assembly and established chromosome-scale assembly of rhesus macaque was used to support the correctness of their assembly. Additionally, the observed breaks observed in synteny on the Y chromosome correspond to the generally high rate of rearrangements occuring on Y chromosomes of mammals (Batra et al. 2020; Skov, The Danish Pan Genome Consortium, and Schierup 2017). Dutheil et al. (2015) uses the high level of synteny on the X chromosomes of the human-chimp ancestor to infer a close relationship (at least on X) as well as strong selective sweeps acting against chromosomal rearrangements since divergence 6-7 million years ago (Munch et al. 2016).\n\nExtended Common Haplotypes (ECH) in humans\nMore low-diversity regions on X in humans have been inferred to be arise from selective sweeps between 55,000 (archaic introgression after out-of-Africa event) to 45,000 (Ust’-Ishim man) years ago (Skov et al. 2023). They define the time-span by comparing haplotypes of unadmixed African genomes with admixed non-African genomes. Here, they locate megabase-spanning regions on the X chromosome where a large proportion of the non-African population have reduced archaic introgression, hypothesizing that selective sweeps have created these extended common haplotypes (ECH).\n\n\nSelecting parent ancestry in baboons\nMapping the interspecies gene flow between baboon genomes in their evolutionary history have revealed male-driven admixture patterns 6 baboon species(Sørensen et al. 2023). They infer a male-driven admixture from mismatching phylogenies of the mitochondrial DNA and the nuclear DNA, indicating a role of nuclear swamping. They compare the ratio of chromosome 8/X admixture between the populations, supporting the same pattern. Recently, in an unpublished analysis by Munch (2024), large megabase-regions were identified in olive baboon (Papio anubis), where either all individuals had olive ancestry, or 95% of the individuals had hamadryas ancestry, significantly diverging from the background.\nStudying live and closely related primate species is our best way of glimpsing into how the hominin (human, Neanderthal, Denisovan) phylogenies have been formed, and by studying the intricate effects of population structure, migration and selection, we might infer events in our archaic history.\n\nsynteny on chrX\nSelective sweeps (or is it?) in humans (ECH90; Skov et al. (2023))\nNegative selection in baboons w.r.t. minor parent ancestry\nErik: Negative selection against Admixture\nDraw a parallel to Human/Neanderthal",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#chromatin-architecture",
    "href": "thesis/index.html#chromatin-architecture",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Chromatin Architecture",
    "text": "Chromatin Architecture\nThis is were the ends are tied and this project comes together. The regions of strong selection that have been located across primate species (human and baboon) are all on the X chromosome and on the same genomic scale (spanning up a million base pairs). As discussed, the chromosomal arrangement and rearrangement play a crucial role for synteny and chromosomal architecture in general, and it has a massive impact on evolution.\nGenerally, the structure and compartmentalization of chromatin is highly conserved, and the structural patterns are evident in animals throughout. Wang et al. (2019) found that through the stages of spermatogeneis, chromatin compartmentalization undergo massive reprogramming, going from megabase-spanning compartments through smaller, refined compartments and back to the megabase compartments. The reprogramming is conserved between rhesus macaque and mouse, indicating a very important feature of the organization. Chromatin has long since been implicated in gene regulation and the functional state of the cell (Lieberman-Aiden et al. 2009), as the three-dimensional structure of the chromosome can bring distant regions in close proximity, and disrupting the organization can lead to development abnormalities (Dixon et al. 2015). Even at smaller scales, at the level of topologically associating domains (TADs) or chromatin loops (Ramírez et al. 2018; Zuo et al. 2021), the structure helps segregate regulatory elements and ensure proper function. Modelling chromatin compartmentalization through spermatogenesis makes Wang et al. (2019) and their Hi-C data obvious starting pointa for investing the relationship between these (yet another) megabase-spanning conserved regions and those of strong selection identified above.\n\nChromatin organization is highly conserved between species\nExplain why take offset in Wang et al. (2019)\nExlpain the rationale of reproducing results with the latest reference\nExplain why it makes sense to compare these datasets\nThe low-diveristy in P.hamadryas and ECH are very wide - chromatin has same window size??",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#c-chromatin-conformation-capture",
    "href": "thesis/index.html#c-chromatin-conformation-capture",
    "title": "Chromatin Compartments and Selection on X",
    "section": "3C: Chromatin Conformation Capture",
    "text": "3C: Chromatin Conformation Capture\nThe first method to capture long-range interactions between pairs of loci was 3C, where spatially constrained ligation is performed followed by locus-specific PCR (Lieberman-Aiden et al. 2009). Then, inverse PCR was added to the pipeline (4C) and multiplexed ligation-mediated amplification (5C). Common for those methods is that they can not make a genome-wide analysis which is unbiased, as we have to chose pairs of target loci. Our DNA can be divided into different orders of structure. 3C focus on identifying the highest orders of organization inside the nucleus, that is, when the 30 nm thick coil of chromatin fibers folds into loops, Topologically Associating Domains (TADs), and chromatin compartments.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#hi-c-high-throughput-3c",
    "href": "thesis/index.html#hi-c-high-throughput-3c",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Hi-C: High-Throughput 3C",
    "text": "Hi-C: High-Throughput 3C\nThe introduction of the Hi-C (high-throughput 3C) method (Lieberman-Aiden et al. 2009) opened new possibilities for exploring the three-dimensional organization of the genome, as deep-sequencing technologies combined with high-performance computing allow for genome-wide analysis that is unbiased. Lieberman-Aiden et al. (2009) show that when combining spatially constrained ligation with deep parallel sequencing and subsequent analysis, we can infer distinct chromosomal territories as intrachromosomal contacts were significantly less abundant than interchromosomal contacts. The method also confirmed the spatial separation of two chromatin conformations in its active (open) state or inactive (closed) state, as they were significantly correlated with distances measured by fluorescence in-situ hybridisation (FISH). The two comformations were termed A- and B-compartments, respectively, and A defined to positively correlate with gene density. Finally, they showed that loci are physically more proximal when they belong to the same compartment implying that Hi-C reads serves well as a proxy for distance. Later, several smaller-order domains were inferred with the same method, such as topologically associating domains (TADs) and chromatin loops. Here, we narrow our focus on the largest of the structures, compartments, that is known to determine availability to transcription factors, thus making an A compartment active—and the B compartment inactive.\n\nHi-C Library preparation\nA specialized protocol for preparing the DNA library is necessary (Lieberman-Aiden et al. 2009, fig. 1a). Briefly, formaldehyde is used to crosslink spatially adjecent chromatin. Restriction enzyme HindIII is used to digest the crosslinked chromatin, leaving sticky ends, 5-AGCT-3, that are filled and biotinylated with a polymerase (using either biotinylated A, G, C, or T). The strands are ligated in highly dilute conditions, which is favoring the ligation of the two crosslinked strands, forming chimeric, biotinylated strands. Upon ligation, the restriction site is lost as a biotinylated 5-CTAG-3 site (also referred to as the ligation junction) is formed. Lastly, the ligation junctions are isolated with streptavidin beads and sequenced as a paired-end library.\nTo be able to create stage-resolved Hi-C library of spermatogenetis, several steps have to be performed on the samples before crosslinking. First, the samples have to be treated immediately after harvesting to ensure viable cells. Secondly, the samples have to be purified to accurately represent each stage og spermatogenesis. Specifically, the data for this project (Wang et al. 2019, acc. GSE109344) preluded the library preparation protocol by sedimentation-based cell sorting to separate live spermatogenic cells into different stages of differentiation, namely spermatogonia, pachytene spermatocyte, round spermatid, and spermatozoa. Then, the cells were fixed in their respective state before crosslinking. They use their own derived method for library preparation, termed small-scale in-situ Hi-C, allegedly producing a high-quality Hi-C libary from as little as 500 cells (capturing the variance of millions of cells).\nInitially, Hi-C library preparation was designed to generate molecules with only a single ligation site in each, but with advancements in sequencing technology (‘short-reads’ can now span several hundreds of base pairs) and the shift to more frequently cutting restriction enzymes for higher resolution results in multiple ligation events per sequenced molecule (Open2C et al. 2024), which is adressed in the section below.\n\n\nHi-C Data Analysis\nThe analysis of the read-pairs of a Hi-C library is divided into several smaller tasks, see [ref fig-hic-analysis-flow].\n\n\n\n\n\n\nFigure 13.1: A simplified pipeline for Hi-C data analysis: from raw reads to a Hi-C interaction matrix. See Table 13.1 for details on ligation events.\n\n\n\nWe must align the reads to the reference in such a way that the intentional chimeric read-pairs (as per above-mentioned protocol) are rescued, and unintentional read-pairs are discarded. That is, we must make sure they represent ligation junction of adjecent chromatin segments, and not technical artefacts or unintentional (random) fusions of unrelated DNA.\n\nAligning the Hi-C reads\nThe main difference between Hi-C libraries and standard paired-end libraries is the high fraction of chimeric reads in Hi-C. As a contact pair is crosslinked and ligated before sequencing, chimeric reads occur as a feature, and standard mapping techniques seeks to filter out this type of reads [ref]. Thus, we need specialized tools for rescuing chimeric reads. That said, we have to be cautious distinguishing the intended chimerism for Hi-C and that of technical artefacts. Any software for local alignment can be used for aligning reads from a Hi-C library. However, one should make sure to disable paired-end rescue mode if possible, otherwise each read in a pair (each mate) should be aligned separately (Lajoie, Dekker, and Kaplan 2015). This removes the assumption that the distance between mates fits a known distribution because the genomic sequences originate from a continuous DNA-fragment. For example, the bwa-mem [ref] implementation of this (the -P option) activates the Smith-Waterman algorithm to rescue missing hits, but disables the search of hits that fit a ‘proper’ pair. After alignment, each read is typically assigned to the nearest restriction fragment to enable categorization of pairs into different categories.\nInterestingly, this last step is not included by default in pairtools, as [ref] observe very similar statistical properties on pairs that are either close or distant from the nearest restriction site. Thus, restriction fragment filters are not needed, and in stead, a simple filter is applied against short-distance pairs that is automatically calibrated.\n\n\nIdentifying and Storing Valid Hi-C Pairs\nOne should be cautious when filtering invalid from valid pairs, as they are not easily distinguished. A ligation event will be categorized into one of five categories (see Table 13.1): dangling-end, self-circle, weird, intrachromosomal (cis), and interchromosomal (trans) (Bicciato and Ferrari 2022, Ch. 1). Either dangling-end or self-circle events are reported if a read-pair maps to the same restriction fragment depending on the orientation, and deemed uninformative (Lajoie, Dekker, and Kaplan 2015). Usually, weird events are demeed uninformative as well, as it is challenging to distinguish a sequencing error from the result of a diploid fragment. PCR duplicates should be discarded as well, having either identical genomic sequence, or sharing exact 5’ alignment positions of the pair (Lajoie, Dekker, and Kaplan 2015; Bicciato and Ferrari 2022, Ch. 1). The probability that such pairs are valid (i.e. there are multiple of the same pairs) is very low. We also have to distinguish between molecules with only a single ligation event (one-way contact) or multiple ligation events (multi-way contacts). For that, a descision should be made on whether to 1) discard molecules with multiple ligations, 2) report one of the ligations (e.g. the 5’-most in both directions), or 3) report all events on a molecule.\n\n\n\nTable 13.1: Five categories of ligation events and a short explanation. Hi-C Data Analysis: Methods and Protocols Ch. 1.\n\n\n\n\n\n\n\n\n\nEvent name\nExplanation\n\n\n\n\nDangling-end\nNon-digested collinear fragments. Fraction can be high.\n\n\nSelf-circle\nCollinear fragment(s) have circularized. Very low fraction could indicate unsuccesful ligation.\n\n\nWeird\nMates have the same orientation on the reference. Is not possible with single copy fragment. Either sequencing errors or diploid fragments1.\n\n\nCis\nPairs from the same chromosome (intrachromosomal)\n\n\nTrans\nPairs from distinct chromosomes (interchromosomal)\n\n\n\n\n\n\n\n\nQuality Control and Interaction Matrices\nTo determine the quality of the Hi-C library, most tools generate quality control log files at some point during the filtering steps, which can then be aggregated and analyzed (with e.g. MultiQC [ref]). The ratios between the different ligation events can be informative about the quality of the Hi-C library. Here, both the distribution of discarded reads across categories, as well as the ratios between cis/trans interactions for a certain organism provide information about the library. For example, the biases of different aligners might be captured by comparing the reason why reads are discarded between two different aligners, as well as if there is a preference of cis or trans in an aligner itself. This allows for evaluating the mapping parameters as well as the filters applied downstream. Additionally, \\(P(s)\\), the contact probability as a function of genomic separation can be inspected as it should decay with increasing distance. The trans/cis-ratio can sometimes be a good indicator of the noise level in the library, and additionally, the level of random ligation events can be quantified by counting the number of trans events occurring to mitochondrial genome. They should not occur naturally, as the mitochondrial genome is separated from the DNA in the nucleus. This method has some pitfalls that should be controlled for; some parts of the mitochondrial genome can be integrated into the host genome, and mitochondrial count may differ between cell-stages.\nTypically, a filter against low mapping quality is applied on the data before constructing the interaction matrix (Hi-C matrix), and a conventional threshold is \\(mapq &lt; 30\\) (Bicciato and Ferrari 2022). However, a considerable amount of reads do not pass that threshold, and thus we risk discarding potential valid information and should make sure to have enough data. Consequently, HicExplorer defaults a lower threshold (\\(mapq &lt; 15\\)), and pairtools enforces no filter by default, but recommends setting this manually (starting at \\(mapq &lt; 30\\)).\nA Hi-C interaction matrix simply maps the frequency of interactions between genomic positions in a sample. The maximum resolution of a Hi-C matrix is defined by the restriction enzyme, where the size of the restriction site (probabilistically) determines average space between each cut. With a 4 bp restriction site, the fragments will average \\(4^4 = 256 bp\\) and similarly \\(4^6 = 4096 bp\\) for a 6 bp restriction site. This leads to ~12,000,000 and ~800,000 fragments, respectively. Very deep sequencing is required to achieve enough coverage to analyze the interaction matrix at the restriction fragment resolution, but, usually, such high resolution is not required. Therefore, it is practice to bin the genome into fixed bin sizes, which also enables a more efficient handling of the data if the full resolution is not needed (e.g. when plotting large regions such as a whole chromosome). The conventional format to store a Hi-C matrix, consisting of large multidimensional arrays, is HDF5. Each HDF5 file can store all resolutions and metadata about the sample, resolutions typically ranging from 10kb to 1Mb. Typically, the stored resolutions should be multiples of the chosen base-resolution, as the lower resolutions are constructed by recursive binning of the base resolution. cooler [ref] neatly offers efficient storage with sparse, upper-triangle symmetric matrices and naming-conventions of the groups in their .h5-based file format, .cool, and they provide a Python class Cooler as well for efficiently fetching and manipulating the matrices in Python.\n\n\nInferring from the matrix (Calling Compartments)\nThe raw frequency matrices are generally not very informative, as the contact frequencies vary greatly between bins and contain biases in addition to the \\(P(s)\\) decay, which results in a diagonal-heavy matrix with high amount of noise the further we travel from the diagonal. Therefore, to analyze the three-dimensional structure of the chromatin, a method for correcting (or balancing) the raw Hi-C matrix has to be applied. It is unadvisable to correct low-count bins as it will greatly increase the noise, or to correct very noisy bins, or very high-count bins. Therefore, some bin-level filters are applied before balancing (Lajoie, Dekker, and Kaplan 2015);\n\nLow-count bins are detected by comparing bin sums to the distribution of bin sums with a percentile cutoff,\nNoisy bins are detected by comparing bin variance to the variance distribution of all bins (and percentile cutoff), and\nOutlier point-interactions are removed (a top-percentile of bin-bin interactions)\n\nA widely used balancing method is Iterative Correction and Eigendecomposition (ICE) (Imakaev et al. 2012), which utilizes a data-driven approach for correcting multiplicative biases. Briefly, is based on an assumption of equal visibility of all loci, and uses the pairwise and genome-wide structure to generate a set of biases along with a map of relative interaction frequencies by iteratively dividing each row, then each column, by its mean until convergence. This results in a uniform coverage profile (corrected coverage), yielding a smoother interaction matrix with slower transitions, thus greatly reduces visibility-induced biases. It does not distinguish between the sources of biases, and thus calculates a collective bias for each position. Imakaev et al. (2012) show that known biases are factorizable by comparing their results to predictions of restriction fragment biases, GC content, and mappability from a computationally intensive probabilistic approach. By showing that the product of those known biases explain \\(&gt;99.99%\\) of the variability in their bias estimation, they argue both known and unknown biases will be captured with their iterative correction method (also denoted matrix balancing).\nEven with a binned, filtered, and balanced matrix, we are still left with the challenge of translating the matrix into biologically relevant inferations. Importantly, we have to remember that the matrix arise from a collection of cells and that the interaction frequency cannot be translated to a fraction of cells. Additionally, the effect from averaging interaction patterns can cause both individual patterns to be burried and the average pattern to show a pattern that does not exist in any of the single cells. Therefore, when pooling matrices one must make sure that the samples are as similar as possible (e.g. the same differentiation stage and so on). We can also not distinguish interactions that either co-occur in the same cell or ones that are mutually exclusive. Lastly, the way interaction patterns are defined poses a challenge; we define the chromatin compartments to be the output of a method, the ‘E’ in ‘ICE’, eigendecomposition, not as a specific pattern that we can explicitly search for. Although experimentally verified to tightly correlate with chromatin states, the inferred compartments vary with different methods of calculating the eigenvector, as dicussed in Eigendecomposition and Compartments (Eigenvectors). To further complicate the challenge, interaction patterns on different scales co-exist and are difficult to disentangle without simplifying assumptions such as small-scale interactions are not visible (or they are negligible) at a certain resolution, or restricting the viewframe to eliminate large-scale variance between chromosome arms. It is by definition a speculative exercise to interpret the biological relevance of an observed pattern, but the consensus is to call compartments on interacting regions that arise from the eigendecomposition of a Hi-C matrix without further modifications (Lajoie, Dekker, and Kaplan 2015). As the eigenvector is only unique up to a sign, a phasing track is used to orient the eigenvector, aiming for a positive correlation with GC content (in mammals), making A-compartments represent the active euchromatin, and B-compartments the closed heterochromatin.\n\n\nCompartment Edges and Genomic Intervals\nAs arbitrary as a compartment may be defined, we chose to define another genomic interval for analysis. It is well (Bicciato and Ferrari 2022, Ch. 3) known that CTCF and other structural proteins preferentially binds to Topologically Associating Domains (TADs; they were initially defined as sub-Mb chromatin structures (Lajoie, Dekker, and Kaplan 2015), but now the definition seems to vary based on the method of extraction [ref cooltools]). Derived from this, we define a transition zone between A/B compartments to look for enrichment of specific regions of interest.\nWe can test if two sets of genomic intervals correlate (say, compartment edges and ECH regions) by either proximity of the non-intersecting parts of the sets, or by intersection over union (Jaccard index). When the underlying distribution of a statistic (or index) is unknown, a widespread method in bioinformatics for estimating a p-value is by bootstrapping. Here, one of the sets are bootstrapped (the intervals are placed at random positions) a number of times, \\(b\\), and the fraction of statistics more extreme than the one we observe is reported as the p-value.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#reproducibility-infrastructure",
    "href": "thesis/index.html#reproducibility-infrastructure",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Reproducibility Infrastructure",
    "text": "Reproducibility Infrastructure\nFirst, describe the importance of reproducibility and the scientific method. Include a bit of scientific skeptiscism of there is time.\nThus, apart from the biological questions we seek to investigate and answer in this thesis, a major goal of the thesis is to create fully (and easily) reproducible results through a self-contained and version-controlled pipeline using git [ref], GitHub [ref], quarto [ref], Conda [ref], gwf [ref], and Jupyter [ref]. See Table 13.2 for a brief introduction.\n\n\n\nTable 13.2: Overview of the tools used for reproducibility of this thesis.\n\n\n\n\n\nTool\nDescription\n\n\n\n\nJupyter\nInteractive coding environment for analysis and development (notebooks are natively rendered with Quarto)\n\n\nQuarto\nA Quarto Manuscript project nested inside a Quarto Book for rendering html (website) and PDF (manuscript) from Markdown via Pandoc. Supports direct embedding of output from Jupyter Notebook cells (plots, tables).\n\n\nConda\nFor managing software requirements and dependency versions reproducibly.\n\n\ngit\nVersion control and gh-pages branch for automated render of Quarto project\n\n\nGitHub\nAction was triggered on push to render the project and host on munch-group.org\n\n\ngwf\nWorkflow manager to automate the analysis on a HPC cluster, wrapped in Python code. workflow.py currently does everything from .fastq to .cool, but notebooks can be set to run sequentially as part of the workflow as well.\n\n\n\n\n\n\n\nGWF: workflow management for High-Performance Computing (HPC)\nTo enable consistently reproducing the analyses, a workflow manager is used. Several exist, but the most well-known must be snakemake [ref]. However, we use the pragmatic (their own words), lightweight workflow manager gwf, which is optimized for the GenomeDK insfrastructure, and has the benefit of in-house support.\nBriefly, gwf works on a python script, conventionally workflow.py, that wraps all the jobs (targets in gwf lingo) you will submit to the HPC cluster. Each target is submitted from a template, written as a Python function, which includes inputs and outputs that gwf should look for when building the depency graph, options list of resources that is forwarded to the queueing system (Slurm in our case), and specs, specifying the submission code in Bash as a formatted Python string (meaning we can pass Python variables to the submission code), providing an extremely flexible framework for running large and intensive analyses in a high-performance computing environment.\n\n\nProject Initialization\n\ngwf\nThe initialization of the project directory is the basis of reproducibility and transparency, together with workflow.py inhabiting the main directory. Specifically, it includes a subdirectory for (intermediate) files that are produced by the pipeline, steps/. Everything in this directory is reproducible simply by re-running the gwf-workflow. It is thus not tracked by git, as the large files (raw reads, aligned read-pairs, etc.) it contains are already indirectly tracked (workflow.py is tracked). It can be safely deleted if your system administrator tells you to free up disk space, although you would have to run the workflow again to continue the analysis. Several directories are created for files that are not produced by the pipeline, that is, files that the workflow uses, configuration files, figures edited by hand, etc. Ideally, as few files as possible should be outside of steps/, to be as close as possible to an automated analysis.\n\n\nJupyter Notebooks\nA notebooks/ subdirectory contains Jupyter notebooks that are named chronologically, meaning they operate on data located in either steps/ or generated from a previous notebook. This way, the workflow can also be set up to run the notebooks (in order) to produce the figures, tables, and their captions used in this manuscript.\n\n\nQuarto\nQuarto is an open-source scientific and technical publishing system that uses (pandoc) markdown to create and share production quality output, integrating Jupyter Notebooks with Markdown and LaTeX and enabling embedding content across .ipynb and .qmd. In .qmd, code chunks in several programming languages can be executed and rendered, including Python, R, mermaid (JavaScript-based diagramming). A Quarto project is configured with a YAML configuration file (_quarto.yml) that defines how output is rendered. In this project, we use a nested structure, nesting a Slides project and a Manuscript project inside a Book project. To manage the directory as a Quarto Book project, a quarto configuration file was placed at the base, defining how the Book should be rendered. Additionally, configuration files were placed in slides/ and thesis/, to render them as Quarto Slides and Quarto Manuscript, respectively. This nested structure lets us render different subprojects with different configurations than the main project, for example to generate the manuscript, a single Quarto Markdown file, in both .html and .pdf, and only including embedded outputs from specified cells from notebooks in the parent directory. Although the Quarto framework is extensive, it is still under development and has several drawbacks worth mentioning. First, one can only embed the output of code cells from notebooks, meaning the only way to embed text with a python variable (e.g. you want the manuscript to reflect the actual value of a variable, sample sizes n = [1000, 10000, 100000], and their respective outputs) is by converting a formatted python string into Markdown and send it to the output. Second, embedded figures will be copied as-is in the notebook, and thus cannot be post-processed with size or layout. This makes it impractical to e.g. use the same figures in slides and in the manuscript. Third, when rendering large projects that is tracked by git, some output files (that have to be tracked to publish the website) can exeed GitHub size limits. Especially if rendering in the jats format, producing a MECA Bundle that should be the most flexible way to exchange manuscripts [ref]. However, as not applicable to this thesis, the option was simply disabled. Fourth, some functionality relies on external dependencies that cannot be installed on a (linux) remote host (GenomeDK), such as relying on a browser for converting mermaid diagrams into png for the pdf-manuscript.\n\n\n\ngit and GitHub\nTo track the project with git and GitHub, the abovementioned structure was initialized as a GitHub repository, including a workflow for GitHub Actions to publish and deploy the website on the gh-pages branch when pushing commits to main. Briefly, it sets up a virtual machine with Quarto and its dependencies, renders the project as specified in the _quarto.yml configuration file(s), and publishes the project on the group website munch-group.org.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#our-research-question",
    "href": "thesis/index.html#our-research-question",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Our research question",
    "text": "Our research question\nIn this project, we formulate two main objectives:\n\nA\nRedo the Hi-C analyses from (Wang et al. 2019) using the latest macaque reference genome, rheMac10, with some modifications. We decided to use HiCExplorer, a Python-based software for command line use, and supplement the analyses with the Open2C Ecosystem (“Open Chromosome Collective (Open2C)” n.d.) that have a Pyton API as well as command-line functions, which can be paired very well with Jupyter Notebooks. The majority of the data analysis was run with a gwf workflow, and the commands that were visually inspected were run in Jupyter Notebooks.\n\n\nB\nCompare with regions of extended common haplotypes (strong selective sweeps) that are found in human, and with regions of negative selection of minor parent ancestry in baboons. Investigate the biological meaning of the results. We use in-house software to compare genomic intervals.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#fetching-raw-data",
    "href": "thesis/index.html#fetching-raw-data",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Fetching raw data",
    "text": "Fetching raw data\nTo reproduce the results from (Wang et al. 2019), I chose to use their raw data directly from the SRA portal [ref]. I filtered the data to contain all their paired-end Hi-C reads, and included only macaque samples. The data set also contains RNAseq data, and the same tissues for both macaque and mouse. The meta data for the data set was extracted into a runtable SRA-runtable.tsv. To get an overview of the data accessions used in this analysis, we will first summarize the runtable that contains the accession numbers and some metadata for each sample (Table 14.1). It adds up to ~1Tb of compressed fastq files, holding ~9.5 billion reads, roughly evenly spread on the 5 tissue types.\n\n\n\n\n\nTable 14.1: Summary of the data accessions used in this analysis\n\n\n\n\n\n\n\n\n\n\nsource_name\nGB\nBases\nReads\n\n\n\n\n0\nfibroblast\n211.403275\n553,968,406,500\n1,846,561,355\n\n\n1\npachytene spermatocyte\n274.835160\n715,656,614,700\n2,385,522,049\n\n\n2\nround spermatid\n243.128044\n655,938,457,200\n2,186,461,524\n\n\n3\nsperm\n164.131640\n428,913,635,400\n1,429,712,118\n\n\n4\nspermatogonia\n192.794420\n518,665,980,300\n1,728,886,601\n\n\n\n\n\n\n\n\n\n\n\n\nFetching and indexing the reference\nWang et al. (2019) use the 2006-version of the macaque reference, rheMac2. Supporting my previous sentiment about not using outdated resources I find it reasonable to use the latest reference, rheMac10. Warren et al. (2020) have improved contiguity from rhemac8 by 120 fold, going from N50 contig size of 107 Kbp to 46 Mbp. Part of the reasoning for reproducing their results was doing so on the latest assembly of the Macaca mulata genome, which arguably will result in a more accurate mapping of the reads, and a better inference of the chromatin compartments as well. Therefore, the latest reference genome for rhesus macaque/Macaca mulata, rheMac10/Mmul_10 (UCSC or NCBI naming conventions, respectively) was downloaded to GDK from UCSC web servers with wget. To use bwa for mapping, rheMac10 needs to be indexed with both bwa index with the --bwtsw option and samtools faidx, which results in six indexing files for bwa mem to use. Two mappers (bwa-mem and bowtie2) were used in different configurations (described below), and bowtie2 requires its own indexing of the reference, using bowtie2-build --large-index, which creates six index files for bowtie2 to use. --large-index creates the special indexing format required for large genomes such as macaque. As we use the position of the centromere to partition chrX into its two arms, and no comment about it was made by Warren et al. (2020), the centromeric region was inferred (visually) from the UCSC browser view of rheMac10, where a large continuous region (chrX:57,500,000-60,200,000) had no annotation and showed many repeating regions. The region is roughly the same region as inferred by Wang et al. (2019) by the same method.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#hicexplorer-trials",
    "href": "thesis/index.html#hicexplorer-trials",
    "title": "Chromatin Compartments and Selection on X",
    "section": "HiCExplorer trials",
    "text": "HiCExplorer trials\nTo get aligned reads in a format compatible with HiCExplorer, the read mates have to be mapped individually to the reference genome. This supports the old convention to avoid the common heuristics of local aligners used for regular paired-end sequencing libraries (Lajoie, Dekker, and Kaplan (2015)). HiCExplorer provide examples for both bwa and bowtie2, so I used both with recommended settings. bowtie2 was more resource-intensive, and only succesfully aligned a small fraction of the reads [ref sup-fig-bowtie2-stats], but likely some parameters could be tuned for better alignment. In both cases, the aligner outputs a .bam-file for each mate (sample_R1.bam and sample_R2.bam), and HiCExplorer performs the parsing, deduplication, and filtering of the reads and builds the raw interaction matrix in a single command,\nhicBuildMatrix -s sample_R1.bam sample_R2.bam -o matrix.h5 [...],\nFor parsing, the command needs a restrictionCutFile, locating the restriction sites from the restriction enzyme used on the reference genome, which is generated with hicFindRestSites that operates on the reference genome and restriction sequence. The default filter, --minMappingQuality 15, was applied as described in Quality Control and Interaction Matrices. Notably, HiCExplorer has no options on handling multiple ligations, and thus the method is unknown. I assume that they have the intitial design of Hi-C libraries in mind.\n\n\n\n\n\n\nFigure 14.2: Overview of the target templates used for hicexplorer. As most operations are handled by hicBuildMatrix, it is rather simple.\n\n\n\n\n\n\n\n\nTable 14.2: The samples chosen for initial data exploration with HiCExplorer. From NCBI SRA Portal.\n\n\n\n\n\n\n\n\n\n\nRun\nBases\nBytes\nsource_name\n\n\n\n\n0\nSRR6502335\n73201141800\n31966430779\nfibroblast\n\n\n1\nSRR6502336\n65119970100\n24433383054\nfibroblast\n\n\n2\nSRR6502337\n52769196300\n23015357755\nfibroblast\n\n\n3\nSRR6502338\n52378949100\n22999581685\nfibroblast\n\n\n4\nSRR6502339\n28885941600\n10960123150\nfibroblast\n\n\n\n\n\n\n\n\n\n\n\nFor the initial exploration of methods with HiCExplorer, we chose five fibroblast samples (see Table 14.2). The goal was to replicate some of the figures from Wang et al. (2019) using HiCExplorer, especially to reconstruct interaction matrices and E1 graphs from macaque data. We constructed matrices with hicBuildMatrix as described from the separately mapped read-pairs. Along with the matrix .h5 file, a .log file was created as well, documenting the quality control for the sample. Multiple logs were aggregated and visualized with hicQC.\nBefore correction (or balancing) of the interaction matrix, a pre-correction filter is applied, filtering out low-count bins and very high-count bins. A threshold for Mean Absolute Deviation (MAD) is estimated by hicCorrect diagnostic_plot, followed by iterative correction with hicCorrect correct --correctionMethod ICE. The PCA was performed with hicPCA on the corrected matrices, yielding the first 3 PCs.\nhicPlotMatrix plots matrices directly to .png (no display). When keeping the analysis in a Jupyter Notebook (using the builtin shell-escape commands to execute bash code), the plot files must be embedded back into the notebook. There is limited support for modifying the plot (from command-line options), such as to add spacing for a bigWig track with E1 values, add plot titles, and define the size and resolution of the plot. I briefly tried to implement a plotting function on the .h5 matrices and bigWig tracks, but it could not fetch regions from a matrix on the fly and had to load the full matrix into memory (that is, all full-length chromosomes).",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#open2c-pipeline",
    "href": "thesis/index.html#open2c-pipeline",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Open2C pipeline",
    "text": "Open2C pipeline\n\n\n\n\n\n\nFigure 14.3: Showing the gwf target templates used with the Open2C pipeline. As it is highly modular, it is also a bit elaborate.\n\n\n\nA gwf workflow was created to handle the first part of the data processing, and each accesion number (read pair, mate pair) from the Hi-C sequencing was processed in parallel, so their execution was independent from each other.\n\nDownloading the reads\nThe reads were downloaded from NCBI SRA with SRA-toolkit (DevTeam 2024) directly to GDK using a docker image of sra-downloader [ref wwydmanski/sra-downloader] as gunzipped .fastq files. Although possible to provide a list of accessions to the toolkit, I submitted each accession as a separate target, as SRA Toolkit acts sequentially, and only starts the next download after all compression tasks were done. It was therefore a low-hanging fruit to parallelize the download for efficiency.\n\n\nMapping Hi-C reads\nSuspiciously, (“Open Chromosome Collective (Open2C)” n.d.) never mentions any problems with aligning the Hi-C reads, they just provide an example using bwa mem in paired-end mode and with the -P option set, which activates the Smith-Waterman [ref] algorithm to rescue missing hits, by focusing on assigning only one of the mates to a good mapping and escape mate-rescue. The documentation of bwa ref state that both bwa-mem and bwa-sw will rescue chimeric reads. Consequently, Open2C does not have a builtin way of pairing the reads after mapping, and I was left with two options: 1) to re(-)pair the individually mapped read-mates (.bam) with samtools-fixmate into one of the specific input formats required for cooler to create an interaction matrix cooler, or 2) re-map the reads using Open2C’s recommendations and use their established pipeline for producing a cooler. I chose the latter, where I mapped the fastq files to rheMac10 in paired end mode for a pair (\\(m1\\), \\(m2\\)) with bwa mem -SP rheMac10 m1 m2.\n\n\nParse and sort the reads\nWe need to convert the alignments into ligation events, and distinguish between several types of ligation events. The simplest event is when each side only maps to one unique segment in the genome ‘UU’. Other events, where one or both sides map to multiple segments or the reads are long enough (&gt;150bp) to contain two alignments (multiple ligations) have to be considered as well. Multiple ligations (reads that have multiple ligation sites, thus having several valid alignments to the reference) are called walks by Open2C, and are treated according to the --walks-policy when parsing the alignments into valid pairs (or valid Hi-C contacts). Here, mask is the most conservative and masks all complex walks, whereas 5unique and 3unique reports the 5’-most or 3’-most unique alignment on each side, respectively, and all reports all the alignments. The pairs are piped directly into pairtools sort after parsing, as the deduplication step requires a sorted set of pairs. The .pairs-format produced by pairtools is an extension the 4DN Consortium-specified format, storing Hi-C pairs as in Table 14.3.\n\n\n\nTable 14.3: Column specification of the .pairs format as extended by pairtools [ref].\n\n\n\n\n\n\n\n\n\n\nIndex\nName\nDescription\n\n\n\n\n1\nread_id\nthe ID of the read as defined in fastq files\n\n\n2\nchrom1\nthe chromosome of the alignment on side 1\n\n\n3\npos1\nthe 1-based genomic position of the outer-most (5’) mapped bp on side 1\n\n\n4\nchrom2\nthe chromosome of the alignment on side 2\n\n\n5\npos2\nthe 1-based genomic position of the outer-most (5’) mapped bp on side 2\n\n\n6\nstrand1\nthe strand of the alignment on side 1\n\n\n7\nstrand2\nthe strand of the alignment on side 2\n\n\n8\npair_type\nthe type of a Hi-C pair\n\n\n9\nmapq1\nmapq of the first mate\n\n\n10\nmapq2\nmapq of the second mate\n\n\n\n\n\n\nI initially used --walks-policy mask without fully understanding the implications, but knowing it was the most conservative of the options. Only later I realized the recommendations from pairtools, specifically informing that longer reads (\\(&gt;150bp\\)) might have a significant proportion of reads that contain complex walks. With this in mind and as the average read-length of our data is 300 bp, I decided to re-parse the alignments into a new set of pairs, and equally apply the recommended filter (next section). As both results are saved, we can compare the two approaches.\n\n\nFilter and deduplicate pairs\nPairtools comes with a de-duplication function, dedup, to detect PCR duplication artefacts. At this point we will remove all reads that are mapped to an unplaced scaffold. Even though the publication of rhemac10 assembly states they have closed 99% of the gaps since rhemac8 [ref], rheMac10 still contain more than 2,500 unplaced scaffolds, which are all uninformative when calculating the chromatin compartments as is the goal of this analysis. Therefore, we simply only include the list of conventional chromosomes (1..22, X, Y) when doing the deduplication. Initially, the default values were used to remove duplicates, where pairs with both sides mapped within 3 base pairs from each other are considered duplicates. cooler recommend to store the most comprehensive and unfiltered list of pairs, and then applying a filter it on the fly by piping from pairtools select. Initially, I missed this step and I did not filter for mapping quality. After reparsing the alignments and applying the same analysis, we compare the two pipelines. A quality control report is generated by pairtools dedup as well, and the reports are merged and visualized with MultiQC [ref] for each cell type.\n\n\nCreate interaction matrices (coolers)\nThe final part of the gwf workflow takes .pairs as input and outputs a .cool file (cooler). Initially, we read directly from the newly generated deduplicated pairs without additional filtering, but the official recommendation is to filter out everything below \\(mapq = 30\\) by piping the pairs through pairtools select \"(mapq1&gt;=30) and (mapq2&gt;=30)\" to cooler cload pairs. I then re-parsed the alignments and created new coolers, including only the Hi-C contacts where \\(mapq \\leq 30\\), following the current recommendations from cooler.\n\n\nPooling samples (Merging coolers)\nThe samples are grouped into replicates with a unique BioSample ID, but we chose to pool all the interaction matrices for each cell type. We reason that when Wang et al. (2019) determine compartments to be highly reproducible between replicates, by merging the replicates we can get a more robust signal.\ncooler merge was used to merge all samples in each cell-type directory to just one interaction matrix for each cell type. The function merges matrices of the same dimensions by simply adding the interaction frequencies of each genomic position together, resulting in less empty or low-count bins.\n\n\nCreate multi-resolution coolers (zoomify)\nA feature of working inside the ecosystem of Open2C [ref] is that it natively provides support for storing sparse interaction matrices in multiple resolutions in the same file by adding HDF5-groups to the (multires-)cooler. We can then efficiently store resolutions (i.e., different bin sizes) that is multiples of the smallest bin size. We chose to use 10kb, 50kb, 100kb, and 500kb bins, and the resolutions are made by recursively binning the base resolution. They call this process zoomifying, and cooler zoomify does the job (it recursively calls cooler coarsen to merge bins).\n\n\nMatrix balancing (Iterative correction)\nFinally, we balance (or correct) the matrices using the cooler CLI. We use cooler balance with the default options which iteratively balances the matrix (Iterative Correction).\nWe balance the matrices on each resolution, and thus it cannot be done prior to zoomifying. They (Abdennur and Mirny (2020)) state that the balancing weights are resolution-specific and will no longer retain its biological meaning when binned with other weights. Therefore, we apply cooler balance to each resolution separately. cooler balance will create a new column in the bins group of each cooler, weight, which can then be included or not in the downstream analysis. This means we will have access to both the balanced and the unbalanced matrix.\nThe default mode uses genome-wide data to calculate the weights for each bin. It would maybe be more suitable to calculate the weights for cis contacts only, and that is possible through the --cis-only flag, and that can be added to another column, so that we can compare the difference between the two methods easily. However, when adding the option, the process seemed to stall and had to be terminated manually, and it was not investigated further.\n\n\nEigendecomposition\nThe eigendecomposition of a Hi-C interaction matrix is performed in multiple steps. As value of the eigenvector is only significant up to a sign, it is convention [ref] to use GC content as a phasing track to orient the vector. E1 is arbitrarily defined to be positively correlated with GC content, meaning a positive E1 value signifies an active chromatin state, which we denote a A-type compartment (or simply A-compartment). We performed eigendecomposition of two resolutions, 100 Kbp and 500 Kbp. Wang et al. (2019) briefly describes their method to calculate the eigenvectors as a sliding window approach on the observed/expected matrix in 100 kb resolution summing over 400 kb bins with 100 kb step size, a method I was not able to replicate in the Open2C ecosystem. I decided to mimic this by smoothing the 100 kb E1 values by summing to 500 kb bins in steps of 100 kb, yielding a comparable resolution which I denote ‘pseudo-500 kb’ resolution (ps500kb).\nFirst, we calculate the GC content of each bin of the reference genome, rheMac10, which is binned to the resolution of the Hi-C matrix we are handling. It is done with bioframe.frac_gc (Open2C). To calculate the E1 compartments, we use only within-chromosome contacts (cis), as we are not interested in the genome-wide contacts. cooltools.eigs_cis will decorrelate the contact-frequency by distance before performing the eigendecomposition. eigs_cis needs a viewframe (view) to calculate E1 values, the simplest view being the full chromosome. However, when there is more variance between chromosome arms than within arms, the sign of the first eigenvector will be determined largely by the chromosome arm it sits on, and not by the chromatin compartments. To mitigate this, we apply a chromosome-arm-partitioned view of the chromosome (as a bedlike format, described in bioframe docs [ref]).\nAdditionally, to mimic the Local PCA from (Wang et al. 2019), I also defined a view of 10 Mb bins. Thoughout the project, I will compare results from each of the three views and resolutions.\n\n\nPlotting matrices\nWe use matplotlib and seaborn to plot in the Open2C framework. Utilizing the cooler class, we can fetch regions of the matrix without modifying the file. As my analysis is centered around the X chromosome, it is efficiently handled by simply fetching ‘chrX’ from the matrix with cooler.Cooler.matrix().fetch('chrX'). Many methods of the cooler class returns data selectors, which do not retrieve data before it is queried [ref]. This means we can create many selectors at once without overflowing memory, enabling us to plot multiple interaction matrices side-by-side, e.g. the corrected and un-corrected matrices. This is easily done with the balance parameter of the matrix selector (.matrix()), which determines if it should apply the balancing weights to the coordinates and defaults to True.\nThe matrix is retrieved an plotted with matplotlib.pyplot.matshow, which automatically produces a heatmap image of the matrix. Here, in stead of transforming the interaction matrix, the color scale is log-transformed with matplotlib.colors.LogNorm. Additionally, cooltools comes with more tools to aid visualization: adative coarsegrain and interpolation, which can be chained. adaptive_coarsegrain iteratively coarsens an array to the nearest power of two and refines it back to the original resolution, replacing low-count pixels with NaN-aware averages to ensure no zeros in the output, unless there are very large regions that exceed the max_levels threshold, such as the peri-centromeric region.\nI implemented a plotting utility, plot_for_quarto in notebook 07_various_plotting.ipynb that is compatible with the YAML cell-options read by Quarto’s embed shortcode. It will take an arbitrary number of samples and plot a chromosome (or region) with or without its respective E1 value for either of the three viewframes that has been created. The input is a (subsetted) pandas DataFrame, defined from a file search matching a pattern specified to the glob Python module.\n\n\nCompartments and Their Edges (Transitional Regions)\nFrom the eigenvectors, the A-compartments were extracted in bedgraph-format (['chrom', 'start', 'end']) and compared with ECH90 regions lifted to rheMac10 from human [ref what reference?]. We perform visual inspection of the genomic intervals and test whether ECH90 regions are enriched near the edges of the compartments by defining a 200 kilobase transition-zone centered at each sign change of E1 (referred to as compartment edge). We compare genomic intervals (or sets) both visually by plotting the regions, and by a proximity test and bootstrapping the Jaccard index.\n\nProximity test\nDetermines whether the non-overlapping parts of the sets are more proximal than expected by chance. We define the annotation set and the query set, and the distance from each interval on the query to the most proximal interval on the annotation is used to generate an index of proximity by the mean distance to nearest interval in the annotation. Then, bootstrapping (\\(b = 100000\\)) is performed by randomly replacing the query intervals to generate the null distribution, and finally, the fraction of the null as or more extreme as our observed proximity is reported as the p-value.\n\n\nJaccard test\nMeasures the significance of the observed Jaccard index (intersection over union) between two sets. The index is a measure of similarity (\\(intersection/union\\)) between two sets (between 0 and 1), which is very sensitive to the size difference between the sets, as even when comparing a set of intervals to a small subset of itself will yield a very small Jaccard index. When we use bootstrapping to generate a null distribution (shuffling the intervals of the query), we find the probability that the two sets (with their respective number and size of intervals), are as similar or more than what we observe. The ratio is reported as the p-value. However, this approach is still sensitive to flipping of query/annotation (if the reginos are not the same size), as only the query is bootstrapped.\n\n\nMultiple testing\nCareful considerations were made to avoid multiple testing biases (p-hacking): Performing tests on all combinations of variables (cell type, resolution, viewframe, flip annot, query) will yield 180 p-values for each test, and we would have to adjust the significance threshold (with \\(\\alpha = 0.05\\), we expect 9 tests passing the threshold by chance). However, if we test only a few combinations we will greatly reduce that.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#hicexplorer-trials-1",
    "href": "thesis/index.html#hicexplorer-trials-1",
    "title": "Chromatin Compartments and Selection on X",
    "section": "HicExplorer Trials",
    "text": "HicExplorer Trials\n\nQuality Control\nThe separately mapped read-mates were parsed into a .h5 interaction matrix by hicBuildMatrix, which include a .log file documenting the builtin quality control (hereafter, QC). Log files from the 5 samples were merged with hicQC (Figure 15.1). We observe showed equal fractions of the read-orientation of read-pairs (Figure 15.1, left, row 5), which is expected for a good Hi-C library. Additionally, it determines between 40% to 50% of the total reads to be valid Hi-C contacts (Figure 15.1, left, row 1), which is usually only 25%-40% (as described in HiCExplorer docs). Figure 15.1 (left, row 4) shows, however, unusually high fractions of inter-chromosomal contacts (up to 30%) compared to intra-chromosomal contacts (also denoted trans and cis contacts, respectively). It is expected that cis contacts are orders of magnitude more frequent than trans contacts (Bicciato and Ferrari 2022, 2301:236; Lieberman-Aiden et al. 2009), and HiCExplorer states it is usually below 10% for a high-quality library. The high fraction may be mitigated by enforcing a stricter mapq threshold for a valid Hi-C pair, as we also observe higher-than expected valid contacts. However, we continue with the current matrices. To compare how well these mappings perform , the QC results is an easy way. Therefore, the reads were mapped with bowtie2 in both end-to-end- and local-mode followed by hiCBuildMatrix, and the QC from each method was plotted next to each other (Figure 15.1). Interestingly, bowtie2 was much more computer-intensive in both modes, perhaps because of the --very-sensitive option. In any case, the QC reveals a major difference in the total number of reads that are determined to be valid Hi-C contacts by hicBuildMatrix. As expected, mapping with end-to-end-bowtie2 makes locating Hi-C contacts more difficult than the other methods (Figure 15.1, row 1), finding a very low amount of mappable, unique pairs passing the quality threshold. In contrast, mapping with local-bowtie2 performs similarly to bwa in finding mappable, unique, high-quality pairs, but calls only approximately half the number of valid Hi-C contacts (&gt;20%), resulting in a fraction of valid Hi-C pairs that hits the expectation from HicExplorer docs (row3). With bwa, the reads were discarded either due to low mapping quality or non-unique mates, whereas with local-bowtie2, the reads were almost exclusively filtered out due to low mapping quality. This must be a result of how the mappers assign mapping quality, and I believe local-bowtie2 looks suspiciously selective in finding unique but low quality alignments. end-to-end-bowtie almost exclusively filters out read-pairs where one mate is unmapped, which is expected when the majority of reads are unmapped.\n\n\n\n\n\n\n\n\n\nFigure 15.1: Comparison of HiCExplorer QC plots for all samples using different alignment tools. The rows represent different QC plots (pairs sequenced, pairs discarded, unmappable/non-unique, distance, and read orientation), and the columns represent the 3 alignments used (BWA, Bowtie2 end-to-end, Bowtie2 local). Generated by hicQC.\n\n\n\n\n\n\n\n\nCorrection\nThe correction diagnostic tool yielded a similar mad threshold within the range \\([-3,-2]\\). Even so, I followed the HicExplorer recommendation to set the lower threshold to at least -2 and the upper threshold to 5 in the pre-normalization filter. I argue that with a high number of valid contacts, it is safer to err on the side of caution and maybe filter out bad data.\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(a) SRR6502335\n\n\n\n\n\n\n\n\n\n\n\n(b) SRR6502336\n\n\n\n\n\n\n\n\n\n\n\n(c) SRR6502337\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n(d) SRR6502338\n\n\n\n\n\n\n\n\n\n\n\n(e) SRR6502339\n\n\n\n\n\n \n\n\n\n\nFigure 15.2: Histograms of the number of counts per bin (bottom x-axis) and the modified z-score (top x-axis) from which the mad threshold is defined.\n\n\n\nTo compare these mappings with others, the QC results is an easy way. Therefore, the reads were mapped with bowtie2 in both end-to-end- and local-mode followed by hiCBuildMatrix, and the QC from each method was plotted next to each other (Figure 15.1). Interestingly, bowtie2 was much more computer-intensive in both modes, perhaps because of the --very-sensitive option. In any case, the QC reveals a major difference in the total number of reads that are determined to be valid Hi-C contacts by hicBuildMatrix. As expected, mapping with end-to-end-bowtie2 makes locating Hi-C contacts more difficult than the other methods (Figure 15.1, top row), finding a very low amount of mappable, unique pairs passing the quality threshold. In contrast, mapping with local-bowtie2 performs similarly to bwa in finding mappable, unique, high-quality pairs, but calls only approximately half the number of valid Hi-C contacts (&gt;20%), resulting in a fraction of valid Hi-C pairs that hits the expectation from HicExplorer docs [ref row3]. With bwa, the reads were discarded either due to low mapping quality or non-unique mates, whereas with local-bowtie2, the reads were almost exclusively filtered out due to low mapping quality. This must be a result of how the mappers assign mapping quality, and I believe local-bowtie2 looks suspiciously selective in finding unique but low quality alignments. end-to-end-bowtie almost exclusively filters out read-pairs where one mate is unmapped, which is expected when the majority of reads are unmapped.\nAs discussed, the five samples were pooled with hicSumMatrices, and the non-standard contigs (unplaced scaffolds) were filtered out, and the different resolutions were created (hicMergeMatrixBins). HiCExplorer also comes with a normalization function prior to correcting the matrix, which should be applied if different samples should have comparable bin counts. It has no effect when having only one matrix. Nevertheless, the pooled matrix was normalized and then corrected compared in Figure 15.3. It is now obvious why we have to correct the matrix. The uncorrected (Figure 15.3 (a)) has no signal apart from the diagonal. Even though some bins have been filtered out, the expected plaid pattern of a contact matrix is visible along the diagonal after the correction (Figure 15.3 (b)), leaving evidence for chromatin structure, especially in the first 50 million bases of the chromosome. There is a wide region of empty values at the place of the centromere.\n\n\n\n\n\n\n\n\n\n\n\n(a) Normalized matrix chrX\n\n\n\n\n\n\n\n\n\n\n\n(b) Normalized and corrected chrX\n\n\n\n\n\n\n\nFigure 15.3: A comparison of interaction matrices before/after iterative correction (HiCExplorer).\n\n\n\n\n\nEigenvectors\nThe PCA performed by hicPCA on the pooled samples at both 50kb and 100kb resolution yielded the first 3 principal components. For PC1 on both resolutions (Figure 15.4 (a), Figure 15.4 (d)) we observe only a single sign change which occurs at around 60 Mbp, the region of the centromere. It means the PCA has captured more variance between the chromosome arms than within them, making it uninformative about chromatin compartments. Upon visual inspection, it is clear that neither of the PC graphs capture the pattern of the interaction matrix by its change of sign. It seems the PCs capture variance from a bias that varies slowly and predictably along the chromosome. The first PC that is supposed to capture the compartments very suspiciously changes sign at the region of the centromere, a classic problem that could be solved by restricting the values from which the PC is calculated along the chromosome. Unimpressed, I rationalize that the option --extra-track to provide a gene track or histone coverage should not affect this result much. It should be provided as a phasing track to orient the eigenvector to positively correlate with gene density or histone marks, and could possibly muddle the compartments if not included. I followed HiCExplorer pipeline to plot and explore the matrices. At this point, I stoppped using HiCExplorer, as I assessed that a more flexible tool was needed.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\nFigure 15.4: Corrected interaction matrix for chromosome X along with PC1, 2, or 3, respectively. a-c: 50kb resolution, d-f: 100kb resolution. HiCExplorer.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#open2c-ecosystem",
    "href": "thesis/index.html#open2c-ecosystem",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Open2c ecosystem",
    "text": "Open2c ecosystem\n\nQuality Control\nAs described, the pairtools module in MultiQC (Ewels et al. 2016) was used to visualize results from pairtools stats for the two parsing runs, see Figure 15.5.\n\n--walks-policy mask\nComparing the multiQC report for each of the cell sources show similar distributions of unmapped (both sides unmapped), one-sided (one side mapped), two-sided (both sides mapped), and duplicated (w.r.t. total mapped) reads. The percentage of cis pairs w.r.t. mapped pairs is around 70% for all samples (Figure 15.5 (a)). The valid pairs also show similar distributions of pair types divided into 10 categories. The \\(P(s)\\) curve looks similar for all samples as well, peaking around 250 bp separation (Figure 15.5 (c)). The QC does not show any information about mapping quality of the reads. Note that the \\(P(s)\\) curve arise from pre-filtered pairs, meaning it provides information about the Hi-C library. As expected\n\n\n--walks-policy 5unique\nParsing alignments with the recommended walks-policy aproximately halves the percentage of unmapped reads, and one- and two-sided reads as well duplicated reads are slightly increased. Overall number of unique pairs are increased with more than 20% increase. The percentage of cis pairs are only decreased by a percentage point at most (Figure 15.5 (b)). Changing the walks policy does not alter the \\(P(s)\\) curve, meaning the parameter does not bias the parsing w.r.t. genomic separation.\n\n\n\n\n\n\n\n\n\n\n\n(a) --walks-policy mask\n\n\n\n\n\n\n\n\n\n\n\n(b) --walks-policy 5unique\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) --walks-policy mask\n\n\n\n\n\n\n\n\n\n\n\n(d) --walks-policy 5unique\n\n\n\n\n\n\n\nFigure 15.5: Results of pairtools stats run on all samples from the two walks-policies. Left (a+c): mask; right (b+d): 5unique. Generated by MultiQC (Ewels et al. 2016). Note: X-axes are not shared in the ‘Genereal Statistics’ plot.\n\n\n\n\n\n\nCorrection\nMatrix balancing did not show major improvement in the plaid pattern, as it already showed the expected pattern. It does, however, filter out bins that are deemed too low-count to be informative, for example peri-centromeric regions. The matrix was expected to be smoother after balancing (for chromosome-wide maps), as regions along a chromosome should only vary slowly in contact frequency with other regions as they are on a continouos molecule. Therefore, sharp contrasts represent a sudden drop in bin count (Figure 15.6, raw) and should not be interpreted as devoid of interaction, but an indication that the data is not sufficient to interpret. It is then better to simply remove the bins in stead of correcting, which will also amplify noise. Even with a high-quality Hi-C library we expect that all bins do not have the same coverage throughout(Lajoie, Dekker, and Kaplan 2015), as restriction enzymes do not bind equally to all regions of the genome, and therefore, some bins will be underrepresented as an artefact of binding/cutting efficieny of the restriction enzyme used. We can try to mitigate the white lines of empty bins that now appear in the matrices. The coarsegrained and interpolated matrix is useful to make a good-looking interaction matrix, but is not that useful for analysis purposes. It might get easier to visually inspect the matrix, but it is not clear how well the interpolated matrix reflects the structure of the chromatin, and it is not transparent which regions are interpolated and which that are not. I find it purposeful for interpolation on high-resolution (zoomed-in) views (Figure 15.7) with small empty regions, but misleading for chromosome-wide maps, where typically the centromere and extremities of the chromosome have filtered-out bins. Interpolation is further discussed below.\nThe regions that are coarsgrained are small zero- or low-count bins which are averaged, effectively reducing the resolution of those regions until the count is sufficient. They get more frequent the longer genomic distance (the further we travel from the diagonal), and effectively enables us to get some intuition about the interactions. The coarsegrain, however, does not interpolate the NaNs created when filtering out whole bins in the balancing step (horisontal and vertical lines in Figure 15.6 and Figure 15.7; middle). This is done in a subsequent step by linearly interpolating the NaNs. Examining the interpolated matrix on full chrX (Figure 15.6; right) gives the impression that the pericentromeric (at ~60 Mbp) region harbours a very strong compartment, but that is clearly an artefact of the interpolation on the very large empty region of the centromere, where the diagonal is somehow extended in a square. On the thinner lines, the interpolation seem to be more smooth, and barely noticable on the diagonal.\n\n\n\n\n\n\n\n\n\nFigure 15.6: Raw, balanced, and interpolated chrX interaction matrix in 500kb resolution. The interpolation is done to make the matrix more visually appealing, but it is not necessary for the analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.7: Raw, balanced, and interpolated chrX interaction matrix in 50kb resolution. The interpolation is done to make the matrix more visually appealing, but it is not necessary for the analysis.\n\n\n\n\n\n\n\nNaN histograms\nAs expected, most of the low quality bins are located on the edges of the chromosome arms, especially the region around the centromere (Warren et al. 2020), as they contain many repetitive sequences. The low-quality bins are filtered out by the balancing algorithm, those bins are NaN in the Hi-C matrix. The median position of the NaN values (Figure 15.8) ranges between \\(58\\) and \\(63.5\\), which is within the estimate of the centromeric region of rhemac10 (the UCSC browser has a continuously unannotated region at chrX:57,500,000-60,200,000). The fact that the medians lie within the centromeric region on all cell sources shows both that the majority of the bad bins are in the (peri)centromeric region and there are approximately equally many on each side.\n\n\n\n\n\n\n\n\n\nFigure 15.8: Histogram of NaN values in the E1 eigenvector for each cell type. Median position is marked with a red dashed line.\n\n\n\n\n\n\n\n\n\nCompartments (Eigenvectors)\nThe three viewframes (Full, Arms, 10Mb) used for the calculation of the eigenvectors captured different variability in the data (Figure 15.9), and as expected, the inferred compartments (colored red on the E1 tracks) are more abundant and smaller with smaller viewframes. To determine how well each of the E1 tracks capture the pattern in the interaction matrix, we can overlay the matrix with the E1 sign-change and visually determine if the squares reflect the E1 sign change (Figure 15.9).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) E1 eigenvector values for merged round spermatid samples at a) 100kb or b) 500kb resolution, as well as the interaction matrix. E1 was restricted to either Full-chromosome (top), Chromosome-arms (middle), or 10Mb windows (bottom)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 15.9\n\n\n\n\nI decide that without more finescaled knowledge than the position of the centromeres, the arbitrary size of the 10 Mb windowed E1 can not fully be justified. That is, we could arbitrarily calculate any windowed E1 track. Also, Wang et al. (2019) concludes only for pachytene spermatocyte to show local interactions in the 10Mb viewframe (what they refer to as refined A/B-compartments), and all the other stages of spermatogenesis were consistent with the conventional A/B compartments. The reasonable thing to do is therefore to continue the analysis, focusing on the arms-restricted eigendecomposition. Nevertheless, we also keep refined compartments in the analysis.\nAdditionally, as I created coolers with two different sets of parsing parameters we will compare the resulting matrices and their compartments (Figure 15.10). As expected, we observe more empty bins in the Hi-C matrix when comparing the initial run (mask) to the recommended parameters (5unique), but otherwise, the interaction pattern is indestinguishable. The effect on the E1 is more noticable, where the absolute magnitude of the E1 values is generally smaller. There is, however, a small region that changes sign (from A to B) on the 10Mb-windowed (‘refined’) E1 track (Figure 15.10;c+d). This region is surrounded by added empty bins, which could mean that too many low quality pairs in mask were introducing bias and swapped the sign of E1. It is supported by the fact that the sign change only occured in refined E1, and that the sign after filtering weak pairs (\\(mapq &lt; 30\\)) is consistent with the arms view. It supports my previous postulate that it is better to use a viewframe with explicit molecular meaning than one of an arbitrary window size. That said, the mapq threshold should really be determined taking both coverage and resolution into account. For our purposes, and with the arms view, the mapping- and parsing parameters do not seem to be too sensitive.\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(a) 5unique: chrX:start-end\n\n\n\n\n\n\n\n\n\n\n\n(b) mask: chrX:start-end\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n(c) 5unique: chrX:70Mb-78Mb\n\n\n\n\n\n\n\n\n\n\n\n(d) mask: chrX:70Mb-78Mb\n\n\n\n\n\n \n\n\n\n\nFigure 15.10: Round Spermatid (RS) at 100kb, comparing the impact of parsing parameters\n\n\n\n\n\nTo emphasize the findings, the sets of A-compartments were compared between the two parsing runs, showing almost identical compartment calls. Additionally, the set difference was 8 bins between PE and recPE for round spermatid 100kb and 5 bins for fibroblast for arms viewframe (Figure 15.11; a+b, respectively). We observe a high number of differences around 76Mb for the refined compartments (10Mb) of round spermatid, which is consistent with the sign-flip of E1 values discussed earlier. Anything else would be surprising, as it is the same data, but visualized in a different way.\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(a) RS: arms\n\n\n\n\n\n\n\n\n\n\n\n(b) Fib: arms\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n(c) RS: 10Mb\n\n\n\n\n\n\n\n\n\n\n\n(d) Fib: 10Mb\n\n\n\n\n\n \n\n\n\n\nFigure 15.11: Round Spermatid (RS) and Fibroblast (Fb) at 100kb, comparing the impact of parsing parameters on A-compartment calling at different viewframes; arms, 10Mb. PE: initial parse (masking complex walks); recPE: recommended parse (reporting the 5’most unique alignment of a complex walk).\n\n\n\n\n\nThe observed difference between the sets can for our data be attributed to chance, but we cannot draw general conclusions about the parameters in general. I argue that the quality and size of the Hi-C library will influence sensitive to parsing parameters. In that case, the most flexible approach is still to follow the recommendations from cooler to report more pairs as valid contacts, and then create coolers with different mapq filters if issues are encountered.\n\n\nCompartment Edges (transition zones)\nWe compare how the ECH90 regions fit when queried on top of the A-compartments and equivalently for the edges, for fibroblasts and round spermatids at 100kb resolution. When queried against the edges in stead, the the total set size is reduced to less than 50%. Interestingly, some of the intersections between A-compartments and ECH90 remain, and new ones appear as we move to the outside edge of the compartment (Figure 15.12). This indicates that most, but not all, of the intersection between ECH90 regions and the A-compartments are within 100kb of the compartment edge, and additional overlap is gained if we define a transition zone on the outside of the edge as well. To visualize this (outside) edge enrichment, we find the set difference of the ECH-intersection to compartments and edges, respectively (Figure 15.13), thus removing all the ‘inside’ edges. We observe that in almost all of the of the regions of \\(ECH \\cap Comp\\) are accompanied by an edge also intersecting ECH (\\(ECH \\cap Edge\\)), localized where the Diff track aligns (within 100kb) with both \\(CompInt\\) and \\(EdgeInt\\).\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(a) Fibroblast A-compartments\n\n\n\n\n\n\n\n\n\n\n\n(b) Round Spermatid A-compartments\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n(c) Fibroblast edges\n\n\n\n\n\n\n\n\n\n\n\n(d) Round Spermatid edges\n\n\n\n\n\n \n\n\n\n\nFigure 15.12: Visual representation of the genomic intervals of ECH90, A-compartments (a+b), edges (c+d), and their intersections. Shown fibroblast (a+c) and round spermatid (b+d) at 100kb resolution and arms viewframe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Round Spermatid\n\n\n\n\n\n\n\n\n\n\n\n(b) Fibroblast\n\n\n\n\n\n\n\nFigure 15.13: Visual representation of the enrichment of edges in the intersection of ECH90 and A-compartments. Shown round spermatid (a) and fibroblast (b) at 100kb resolution and arms viewframe. Note that the edge-regions are too small to be distinguished visually from the compartment on the graph, making it look like they overlap, even though the difference is reported.\n\n\n\n\nWe apply both proximity test and Jaccard test, to see how well the results could occur by chance. For completeness, the tests are included for all cell types, but we only use 100kb resolution arms viewframe. We observe that both fibroblast and round spermatid have \\(p &lt; 0.05\\) for both tests, meaning the two cell type have both more intersection with ECH regions than expected by chance (Jaccard) and none of the samples passed the proximity test, meaning the non-overlapping segments were not proximal than expected by chance. I argue that a significant Jaccard statistic should be interpreted as a significant amount of overlap between the two sets, i.e. compartment edges and ECH90 regions, and the proximity test (when performed on the edges) gives us information about the potential of expanding or moving the transition window. That is, if the non-overlapping regions are very proximal, a larger (or shifted) window to only capture the 200kb region outside of the edge might be favourable.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#testing-against-regions-of-selection-in-baboons",
    "href": "thesis/index.html#testing-against-regions-of-selection-in-baboons",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Testing against regions of selection in baboons",
    "text": "Testing against regions of selection in baboons\nThe data for this analysis was provided by Kasper Munch in bed-like format, mapped to panu_3.0 (PapAnu4) assembly. The intervals define genomic regions in a hybrid/migrating population of baboon where strong negative selection acts against minor parent ancestry (Sørensen et al. 2023). The segments had to be lifted to rheMac10 to be able to correlate the two sets of intervals. The original UCSC liftOver (Hinrichs 2006) is very strict and does not try to conserve segments in favor of accuracy e.g. inversions or small indels, which results in highly fragmented regions when lifted to another assembly, if the segments are not continouos on the new assembly. For our analysis, it is not the exact genomic position or order of sub-genic regions that are important, but rather, the start and end coordinates of each segment are quantified. To favor preservation of segments, we use segment_liftover (Gao, Huang, and Baudis 2018), resulting in much more similar segments to the original (Figure 15.14). As no chain file from panu_3.0 to Mmul_10 was available, we had to use panu_2.0 as intermediate.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) high-olive\n\n\n\n\n\n\n\n\n\n\n\n(b) high-hama\n\n\n\n\n\n\nFigure 15.14: Comparison of a) high-olive and b) high-hama intervals between Panu_3.0, segment_liftover, or UCSC liftOver coordinates when lifting from PapAnu4–&gt;PapAnu3–&gt;rheMac10.\n\n\n\n\n\nInitially, the compartment edges of round spermatid at 100kb resolution (RS100) were plotted against the lifted coordinates from a P. anubis-hamadryas hybrid population, where either all the sampled individuals have Papio anubis ancestry or 95% of the sampled individuals have Papio hamadryas ancestry. Their respective intersections were plotted undeneath. We expect less intersection for hamadryas than for anubis as the total set size is much smaller. The compartment edges and Papio anubis-derived regions(Figure 15.15; b) seem to be highly enriched in the first 25 Mbp, and thus it has a high degree of intersection with the compartment edges. Interestingly, the ECH90 set is nearly empty in that region, which could be useful for determining the mechanism for selecting against the P.hamadryas ancestral allele in the hybrid baboon population. The P.hamadryas-derived regions seem intersect the compartment edges more centered on the chromosome (Figure 15.15; a). The proximity test initially ruled out that the non-intersecting parts of the respective regions were this proximal by chance. However, after updating the method to exclude whole segments that partially overlaps (in stead of keeping the non-overlapping parts), there was no statistical significance. Additionally, the Jaccard test revealed that the intersection between the RS100 and both Hi-P.hama and Hi-P.anu can be explained by chance alone with no p-values below \\(0.05\\).\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(a) P. hamadryas + arms E1\n\n\n\n\n\n\n\n\n\n\n\n(b) P. anubis + arms E1\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n(c) P. hamadryas + 10Mb E1\n\n\n\n\n\n\n\n\n\n\n\n(d) P. anubis + 10Mb E1\n\n\n\n\n\n \n\n\n\n\nFigure 15.15: Comparing the A-compartment edges of round spermatid (RS) with regions in baboons from hybrid population where a) 95% of sampled individuals have Papio hamadryas ancestry or b) 100% of the samples have Papio anubis ancestry. The regions are extracted and lifted from PapAnu4 to rhemac10 using segment_liftover.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#aknowledgements",
    "href": "thesis/index.html#aknowledgements",
    "title": "Chromatin Compartments and Selection on X",
    "section": "Aknowledgements",
    "text": "Aknowledgements\nI would like to extend my sincere gratitude to my supervisor, Kasper Munch, for his guidance and support throughout this project. His sparring and scientific literacy have been invaluable in refining my ideas and shaping the direction of this work. I am especially thankful for Kasper’s enthusiasm, which has been a source of motivation during this process. His expertise and insights were instrumental in setting up the Quarto templates and providing support for the discussion. His constructive feedback on the manuscript has greatly improved its quality. I feel fortunate to have had the opportunity to learn from and work with such a knowledgeable and dedicated mentor.\nI would also like to thank my brother, Jakob, for his help with proofreading of the manuscript.\nI would also like to express my heartfelt gratitude to Clara for her unwavering support, patience, and encouragement throughout this process. Her understanding and care have been a constant source of strength.\nA special thank you to my son, Birk, for bringing joy and perspective into my life, forcing me to take some hours off.\n\nUse of Generative Artificial Intelligence\nAs per Aarhus University guidelines (IT n.d.), I hereby disclose my use of Generative Artificial Intelligence (GAI) tools during the preparation of this thesis. All usage was conducted critically and responsibly, ensuring that the final work remained my own and adhered to academic integrity standards. These tools supplemented my expertise and accelerated routine tasks, but all creative, analytical, and scientific contributions are my own.\n\nCopilot\nI used Copilot for code completion and debugging, as well as modifying existing code to reflect updated variables and experimental needs.\n\n\nChatGPT\nChatGPT provided syntax support for Bash, YAML, JSON, Mermaid diagrams, and Pandoc Templates, to accelerate my learning of new programming languages. It hallucinates a lot about Quarto.\n\n\nNotebookLM\nNotebookLM supported the re-identification of references for a small amount of statements where placeholders ([ref]) were initially used before setting up BibTex references. Also to look up contradicting statements from other sources. NotebookLM only ‘knows’ the sources you provide it.",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  },
  {
    "objectID": "thesis/index.html#footnotes",
    "href": "thesis/index.html#footnotes",
    "title": "Chromatin Compartments and Selection on X",
    "section": "",
    "text": "Bicciato and Ferrari (2022) mentions that this type of ligations had been used to model interaction between sister-chromatids post-replication in Drosophila.↩︎",
    "crumbs": [
      "Thesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chromatin Compartments and Selection on X</span>"
    ]
  }
]